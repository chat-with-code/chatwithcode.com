{"/about-us":{"title":"About Us","data":{"":"The Guild is a group of open source developers.We were formed in order to bring a different approach for sustainable open source development.We believe in the interaction between internal teams with real world challenges and open source.We are the team that links those together.One of our main guidelines of open source is solving real issues for real people.That's why we work with and help companies like Microsoft, KLM-AirFrance, Schneider-Electric, Wix\nand others.We do everything that's needed to improve developer productivity and product performance.That can include:\nRemove any blocker that might take away time from a developer - CI/CD pipelines, Complex Build\nsystems, developer toolings, making them active decision makers in the open source tools and\nlibraries they rely on, Connecting teams across different levels of their tech stack\nPerformance, security audits and fixes for API Gateways\n\nAll of that always follows with real code changes, otherwise, if it's just consultations, we do it\nfor free.\nWe do open source slow but well.\nWe want our open source libraries to be built for the long term, in a sustainable way, with\nextreme high quality, thanks to continuous improvements and the ability to always learn and\nrespond to the community's feedback, working closely on a daily basis with companies and individuals\nfrom the community, solving real issues for them.And we are managing to do so. If you check out our libraries, some have been around for many\nyears, they are always up to date, with low number of issues and are always actively\nmaintained.We also revived many libraries of the community (you can read more of that on our blog).That way of open source is not instead of other ways (venture capital startups, teams from large\ncorporations), it is complimentary.Another main guideline for us in open source is Individuality.Each library is under a person's name, not under\nThe Guild organization on GitHub.","the-benefits-of-that-approach#The Benefits of That Approach":"Bigger sense of responsibility on the maintainer\nThe individual maintainers get the credit they deserve\nResiliency of the code - if maintenance is not on par, it is far easier to fork and compete,\ncompared to a famous organization/company, making the code and the community more distributed and\nresilient\nIt helps our individuals members promote themselves, their own GitHub users, their own social\nmedia\nMaximizing the individual and personal growth of our members is more important than the group\n\nThe way we work and our structure also incentivises us to contribute to other solutions instead of\nworking on our own.We would rather contribute to an active project than to create our own.But, we have a very high standard to what it means to be an active open source project and\nunfortunately, finding libraries like that is hard.So we always try to help and support first.\nAlso, we rely on you, the community.","how-you-can-help#How You Can Help":"Spread the word about us - Tell people about our libraries and our services, create guides and\ntutorials\nAnswer and help others on GitHub Issues,\nDiscord, Stack Overflow,\nTwitter, Reddit\nContribute to our docs and also to graphql.org\nCreate failing tests and reproducible projects\nImprove the\nWhatsApp clone tutorial\nGo through our\nguide on how to contribute to our open source libraries\nSchedule a free meeting for architectural review - we love to learn from you, and hopefully we can\ngive valuable advice back\nHire us to work with you - we'll be that extra nice member on your team\nGet a training with us\nJoin us! - Are you maintaining a popular open source library and thinking of how to spend more\ntime doing just that?\nJust contact us directly and tell us your story"}},"/blog/a-new-year-for-schema-stitching":{"title":"A New Year for GraphQL Schema Stitching","data":{"":"If you'd told me eight months ago that I'd end up\nwriting a book on Schema Stitching, I\nwouldn't have believed it.\nThat's because eight months ago my team was trying to mature an old GraphQL prototype into a formal\nAPI product, and our dependence on Schema Stitching v4 (a\nfamously abandoned project of\nApollo) imposed numerous bugs, limitations, and performance bottlenecks on our work. I researched\ntransitioning to the newer Apollo Federation as a\nsolution to these woes, but the involved migration path proved too daunting for our immediate time\nconstraints.","not-the-old-schema-stitching#Not \"The Old\" Schema Stitching":"Something remarkable happened at this critical juncture for my team...GraphQL Tools (the repo of Schema Stitching\nlibraries) was brought back to life by The Guild and friends. The most pivotal new addition was\na small mention of \"type merging\", a feature\nthat introduced automated query planning for types distributed across services (very similar to\nApollo Federation). The new v5 library was still pretty raw, but it started a feedback loop that\nmatured the library dramatically in v6, and then again in v7 (and will again in v8!).During these development cycles, numerous missing Stitching features were identified and added:\nbatch execution\nfor consolidating sub-service requests,\ncomputed fields for\nencapsulating service concerns,\ninterface proxies for bridging\ninterfaces across services, and\nschema directives for configuring stitched\nschemas via SDL annotations. Also, the\nlibrary documentation was rewritten from\ntop-to-bottom for a new generation of users.Coming into 2021, Schema Stitching has been revitalized into an un-opinionated library capable of\nbuilding an opinionated framework like Apollo Federation. If you want out-of-the-box workflows,\nFederation is the tool for you. Otherwise, Stitching is the comparable alternative that keeps you in\ncontrol of your full system architecture.","the-handbook#The Handbook":"The tricky thing about the self-service nature of Schema Stitching is that its usage extends beyond\njust the scope of library documentation. To bridge this knowledge gap, the\nSchema Stitching Handbook was started as a\ncompanion guide that walks through building stitching libraries into practical applications. The\ncontent is split into a few major sections:\nFoundation chapters cover the setup and use of core stitching library features. These\nchapters provide code examples and detailed explanations of subjects covered in the\nofficial documentation.\nArchitecture chapters explore larger structural concerns around\ntesting,\nversioning,\nand\nreleasing\nstitched schemas. Stitching has no CLI or\nmanaged services, but\nyou may find that these tools are not prohibitively difficult to self-service.\nOther Integration chapters explore how\nother tools\nand\nprogramming languages\nfit into a stitched schema. Stitching is perfectly compatible with any valid GraphQL resource,\nand we're excited to catalog that here.\n\nThe Handbook is versioned as a living repo to provide a comprehensive guide that may evolve with the\nlibrary. We look to you, fellow developers, to contribute your own discoveries of how Schema\nStitching integrates with tools and languages that we haven't explored yet.","a-new-year#A New Year":"Whether you're planning a new API project, looking to migrate an existing one, or curious of\nalternatives for your current distributed GraphQL architecture, 2021 is the year to give Schema\nStitching a fresh look. Read the\nnew documentation,\nreview the handbook,\nwatch the video series,\nor join us for a conversation to learn about\nthe exciting progress that was made last year.\nGraphQL Tools repository\nGraphQL Schema Stitching Handbook\nSchema Stitching official documentation"}},"/blog/accountsjs-graphql-modules":{"title":"Authentication with accounts-js & GraphQL Modules","data":{"":"When starting a backend project, two of the biggest concerns will usually be the right structure of\nthe project and authentication. If you could skip thinking and planning about these two, starting a\nnew backend project can be much easier.\nIf you haven't checked out our blog post about authentication and authorization in GraphQL\nModules, please read that before!\nInternally, we use GraphQL-Modules and\naccounts-js to help us with those two decisions,\nGraphQL-Modules helps us solve our architectural problems in modular, schema-first approaches with\nthe power of GraphQL and accounts-js helps us create our authentication solutions by providing a\nsimple API together with client and server libraries that saves us a lot of the groundwork around\nauthentication.If you haven't heard about accounts-js before, it is a\nset of libraries to provide a full-stack authentication and accounts-management solutions for\nJavascript.It is really customizable; so you can write any plugins for your own authentication methods or use\nthe already existing email-password or the Facebook and Twitter OAuth integration packages.accounts-js has connector libraries for MongoDB and Redis, but you can write your own database\nhandler by implementing a simple interface.accounts-js provides a ready to use GraphQL API if you install their GraphQL library, and we are\nhappy to announce that the GraphQL library is now internally built using GraphQL-Modules!It doesn't affect people who are not using GraphQL Modules, but it helps the maintainers of\naccounts-js and simplifies the integration for GraphQL-Modules-based projects.","how-to-implement-server-side-using-accounts-js-graphql-modules-and-apollo-server#How to Implement Server-Side Using accounts-js, GraphQL Modules and Apollo Server":"First install required dependencies from npm or yarn:\n\nLet's assume that we're using MongoDB as our database, password-based authentication and\nApolloServer:\n\nAnd we can extend User type with custom fields in our schema, and add a mutation which is restricted\nto authenticated clients.\n\nFinally, let's define some resolvers for it:\n\nWhen you print the whole app's schema, you would see something like above:","how-to-implement-client-side-using-accounts-js-react-and-apollo-client#How to Implement Client-Side Using accounts-js, React and Apollo-Client":"Now we can create a simple frontend app by using Apollo-Client and accounts-js client for this\nbackend app. The example below shows some example code that works on these two.\n\nAs you can see from the example, it can be really easy to create an application that has\nauthentication in modular and future-proof approach.You can learn more about accounts-js from the\ndocs of this great library for more\nfeatures such as Two-Factor Authentication and Facebook and Twitter integration using OAuth.Also, you can learn more about GraphQL-Modules on the website and see\nhow you can add GraphQL Modules features into your system in a gradual and selective way.If you want strict types based on GraphQL Schema, for each module, GraphQL Code Generator has\nbuilt-in support for GraphQL-Modules based projects.\nSee the docs for more\ndetails.You can check out our example about this integration\nhttps://github.com/ardatan/graphql-modules-accountsjs-boilerplate.","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with accounts-js & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/add-reactivity-to-an-existing-source":{"title":"Add reactivity to an existing source using GraphQL Mesh","data":{"":"","introduction#Introduction":"Working on the\ncode generator for svelte plugin, I was\nlooking for a public graphQL endpoint having queries, mutations and subscriptions for nice examples.\nUnfortunately I didn't find anything out of the box, ready to use for my demos. So I decided to\nextend an existing source!","starting-point#Starting Point":"Across my researches I found one cool public endpoint regarding\nSpaceX. It has Queries and Mutations ready to use! So I\ndecided to pimp this endpoint, and bring a bit of reactivity with subscriptions.The idea is to publish the new user when it's inserted with this mutation:\n\n\nHow hard is to do this? Let's find out... Let's Pimp this GraphQL!","implementation#Implementation":"Multiple ways are possible!\nSpoiler alert\nThanks to graphql-mesh, it's dead easy! 🚀🚀🚀","1-create-a-new-repo#1. Create a New Repo":"","2-add-graphql-mesh-packages#2. Add graphql-mesh Packages":"","3-add-meshrcyaml-file-in-the-root-folder-with#3. Add .meshrc.yaml File in the Root Folder With":"Where I\ndeclare the graphQL source\nextend Subscription to listen to user added users\ncompose the existing Mutation.insert_users","4-add-srccompositioninsert_userjs-file-with-all-the-logic-for-this-new-mutation-composition#4. Add ./src/composition/insert_user.js File with All the Logic for This New Mutation Composition":"That's it!","wrap-up#Wrap Up":"Extending an endpoint with subscription is easy! Thx to tooling.\nYou can find the source on GitHub\nYou see all this in action directly in the\nplayground\n\nI'm now ready to work on the demo for\nSvelte Codegen! Stay tunned ;)@jycouet\nSpecial thanks to n1ru4l who helped me find the nicest way to do it\n;)"}},"/blog/announcing-free-single-sign-on-for-graphql-hive":{"title":"Announcing free SSO (Single Sign On) for GraphQL Hive","data":{"":"Today we are excited to announce that due to popular demand we now support connecting a GraphQL Hive\nOrganization to an OAuth Open ID Connect Provider (OIDC) for Single Sign On (SSO).\nGraphQL Hive is our schema registry solution for continuously\nevolving your GraphQL schema backed by performance insights and usage statistics. Whether you are\nworking in a small company with a single GraphQL service or a big multi-team company with multiple\n(federated or composed) GraphQL services, GraphQL Hive is the perfect tool to help you manage your\nGraphQL schema.\nGraphQL Hive gives you the flexibility of choosing your existing identity provider of choice for\nauthenticating users, such as Google Workspaces, Okta, Auth0, and many more.Users logging into GraphQL Hive via an OIDC provider will be automatically added and limited to\ninteracting within your organization.You can start using OIDC SSO on the GraphQL Hive Cloud version for any type of organization at no\nadditional cost starting today.Offering this feature for free is a big deal for us. We at The Guild believe that Single Sign On is\na core security requirement and not a luxury feature that you have to buy in.You can learn more about the broken relationship between SaaS vendors and SSO on the\nSSO Wall of Shame.In addition, OAuth Open ID Connect login is not only limited to the GraphQL Hive Cloud version, but\nis also available on self-hosted GraphQL Hive\nwhich we announced Last month.Huge thanks go out to the incredible helpful team at SuperTokens that\nhelped us a lot with questions and feedback on shipping this feature. GraphQL Hive is\nfully open source and also uses the SuperTokens Open\nSource project for user authentication.\nGet started with adding OAuth OIDC SSO to your GraphQL Hive organization\nGet started with with custom OIDC providers for self-hosted Hive"}},"/blog/announcing-graphql-hive-release":{"title":"Announcing GraphQL Hive, the complete GraphQL API manager","data":{"":"After months of development and collecting feedback from our customers using it in production, we\nare incredibly excited to share with you today the public launch of\nGraphQL Hive!","built-for-the-community-for-all-graphql-apis#Built for the Community, for All GraphQL APIs":"GraphQL Hive has been built with 3 main objectives in mind:\nHelp GraphQL developers to get to know their GraphQL APIs a little more with our schema\nregistry, performance monitoring, alerts, and integrations.\nSupport all kinds of GraphQL APIs, from Federation, and Stitching, to standalone APIs.\nOpen Source at the heart: GraphQL Hive is 100% open-source, and build in public with the\ncommunity.\nA plug and play SaaS solution: to give access to Hive to most people with a generous free\n“Hobby plan”\n\nWithout further ado, let's review together how GraphQL Hive will help you to get the best of your\nGraphQL APIs.","features-overview#Features Overview":"GraphQL Hive provides all the tools to get visibility of your GraphQL architecture at all stages,\nfrom standalone APIs to composed schemas (Federation, Stitching).From our experience working in the GraphQL field, we believe that the following set of features\nare essential for a good understanding and operating of GraphQL APIs, at any stage.","schema-registry#Schema Registry":"Using Hive requires publishing changes to your GraphQL API schema. Once published on the Schema\nRegistry, Hive will offer 3 useful features to manage your GraphQL API:Get warned about breaking changes. For every new version of the schema either committed in a\nPull Request or publish, Hive will run a set of checks and notify your team via Slack, GitHub, or\nwithin the Hive application.\n\nThe definition of a “breaking change” is data-driven (based on \"live operations monitoring\") and\nentirely configurable for each project:\n\nThe schema changes detection also applies in a Federation setup, when a given subgraph breaks the\ncomposed supergraph.Access the history of changes. On top of detecting potential breaking changes, Hive gives your\nteam access to the full history of changes, even on a complex composed schema (Federation,\nStitching).Hive can also be configured to post the detected schema changes to Slack, fostering collaboration\nbetween the front-end and back-end engineers.\n\nSupercharge your GraphQL development workflow. Finally, Hive provides a high-availability and\nmulti-zone CDN service based on Cloudflare, allowing you to access the registry, through a secured\nexternal service, that's always up regardless of Hive services.This secured URL, generated from the Hive UI, can be used to supercharge your GraphQL development\nworkflow, by:\nupdating your GraphQL Code Generator config to fetch the introspection from Hive CDN, instead\nof production, staging, or local version of your GraphQL API\nupdating your GraphQL Gateway to fetch the schema from Hive CDN instead of querying all\nservices\nupdating your GraphQL Mesh configuration to fetch a GraphQL Source schema from Hive CDN\n\nDoing so will avoid deployment issues and development issues (ex: getting introspection for codegen\nfrom the wrong development version of the schema).More examples are available in Hive documentation:\nhttps://docs.graphql-hive.com/features/registry-usage.The three aspects of Schema Registry covered above will help you a safer and smoother deployment\nof your GraphQL APIs, even when working with standalone or monolithic GraphQL APIs.","monitoring#Monitoring":"Once a Schema is deployed, it is important to be aware of how it is used and what is the\nexperience of its final users.GraphQL Hive helps you get a global overview of the usage of your GraphQL API with:\nError rates and repartition\nGlobal and queries performances (latency, RPM…)\nOperations count\nActive GraphQL clients\n\n\n\nAt a glance, the Hive operations dashboard helps you to understand:\nDoes your GraphQL API face unexpected traffic?\nDoes a new version of Schema result in a raise of errors?\nWhich queries are slow?\n\nBeing able to quickly answer these questions allows you to build better GraphQL APIs and better user\nexperiences.","integrations#Integrations":"Hive is well integrated with Slack and most CI/CD systems to get you up and running as smoothly\nas possible!As covered earlier, Hive can notify your team when schema changes occur, either via Slack or a\ncustom webhook:\n\nAlso, the Hive CLI allows integration of the schema checks mechanism to all CI/CD systems\n(GitHub, BitBucket, Azure, and others).To compare new schema with the latest one and detect breaking changes, run the following command:\n\nThe same applies for schema publishing and operations checks.If you are using GitHub, you can directly benefit from the Hive app that will automatically add\nstatus checks to your PRs!\n\nAnd we are just getting started, we are already planning more alerts/notifications types and more\nintegrations.","get-started-with-graphql-hive#Get Started with GraphQL Hive":"By far the easiest way to use GraphQL Hive is to get started with one of our hosted plans below.Our hobby plan is free and fits perfectly for most side projects. When you're ready to upgrade,\nwe have you covered with our Pro plan.All plans come with unlimited seats, high availability and all the features.You can now give more insight into your GraphQL API's performance by inviting all of your team to\nyour project.","pricing#Pricing":"As you can see, the pricing is based on real usage and not the number of seats.You can start for free with the \"Hobby\" plan and upgrade to \"Pro\" once you hit the limits.\nFeature / Plan\tHobby\tPro\tCustom\tBase price\t$ 0\t$ 10\t$ Talk to us\tUsers / Seats\tUnlimited\tUnlimited\tUnlimited\tSchema pushes\tUnlimited\tUnlimited\tUnlimited\tMonitoring\tUp to 1M\t$ 10 per 1M\tUnlimited\tData retention\t7 days\t90 days\t12 months\nIf you need more than the Pro plan, let us know, and we\ncan discuss your requirements.","graphql-hive-can-be-self-hosted#GraphQL Hive Can Be Self-Hosted":"As stated earlier, GraphQL Hive is completely open-source under the MIT\nlicense, meaning that you are free to host on your own infrastructure.You will find instructions in the GitHub repository\nand feel free to contact us for any questions or support.","join-us-in-building-the-future-of-hive#Join Us in Building the Future of Hive":"Like all The Guild projects, GraphQL Hive is built with the community.We can't wait to get you onboard and get your feedback, pull\nrequests, and feature requests on\nhttps://github.com/kamilkisiela/graphql-hive.See you in Hive! 🐝"}},"/blog/announcing-graphql-network-inspector":{"title":"Announcing GraphQL Network Inspector","data":{"":"GraphQL Network Inspector is a dedicated devtools extension which allows you to inspect and debug\nGraphQL queries and mutations from network traffic.The extension has seen great adoption since its initial release and now I'm excited to announce it's\nnew home as part of The Guild.You can check out the open source extension and try it out today.\nGraphQL Network Inspector","why-graphql-network-inspector#Why GraphQL Network Inspector?":"If you've ever worked with GraphQL on the client, you'll know that it can be a real pain to debug\nusing the standard network tab. The standard devtools are designed for REST APIs and don't provide\nclear visibility into the individual GraphQL queries and mutations being sent.With every request you'll see POST /graphql. This makes it difficult to distinguish requests\nwithout opening the request details and inspecting the body.GraphQL Network Inspector solves this problem by providing a dedicated tab for GraphQL requests and\ndisplaying each query in a readable format.","features-overview#Features Overview":"The great thing about a dedicated inspector is we can provide much more specific functionality\naround GraphQL. Here are some of the features we've added to the extension:","request-overview#Request Overview":"The request overview tab provides a simple overview of all queries and mutations. Here you can see\nqueries by name, distinguish between queries and mutations and even see total errors returned for\neach request.","request-details#Request Details":"Clicking into a request will show similar details to the standard inspector. But here we have a\nbetter breakdown for each element of the request including; headers, request query with variables\nand response.","copy-details-to-graphql-playground#Copy Details to GraphQL Playground":"The extension also provides convenient buttons to copy the request query and variables into GraphQL\nPlayground, great if you want to re-run the query.Under the request details tab, you'll see a button to copy the query and variables to the clipboard.You can also click individual headers to copy them as well.","convenient-features#Convenient Features":"Streamlining the debugging process is a key goal of the extension. On top of the features above\nwe've also introduces helpful extras such as full-text search and filtering.\n\nCheck out the extension today and don't forget to give\nGraphQL Network Inspector a star ⭐️ on\nGitHub.We'd love to hear your feedback and suggestions for the extension. How would you like to see it\nintegrate further with The Guild ecosystem? Let us know.Happy debugging!"}},"/blog/announcing-graphql-yoga-v2":{"title":"Announcing GraphQL Yoga 2.0!","data":{"":"Today we are incredibly excited to share with you the new GraphQL Yoga! This release was made\npossible with your contributions, issues, and feedback.The Guild took over the development of GraphQL Yoga from\nPrisma in early 2021, and with the growing community of tools in the GraphQL\nspace, most recently Envelop, we were able to rewrite GraphQL Yoga 2.0 from\nscratch with easy setup, performance, and developer experience at the core.GraphQL Yoga continues to boast a \"convention over configuration\" approach and the freedom to use\nyour favorite libraries, from HTTP to schema-building.You are no longer required to install dozens of dependencies to get features such as subscriptions,\nfile uploads, CORS, error masking, and more.Building a GraphQL Yoga server requires a single import and only a few lines of code to start\nserving an API. And you also get GraphiQL for making\ndevelopment even easier.","the-yoga-v2-experience#The Yoga V2 Experience":"","your-stack-and-habits#Your Stack and Habits":"The main goal of Yoga v2 is to allow you to leverage all the GraphQL ecosystem by being\ncompatible with most of the existing schema-design, HTTP server libraries, and deployment\nenvironments.Built on top of a modular and extendable GraphQL Server, Yoga v2 allows you to use your\npreferred schema design approach and HTTP server library.For example, Yoga v2 is fully compatible with Express and Nexus, with no additional packages:\n\nThe same applies to GraphQL Tools, Pothos, Nexus, TypeGraphQL, SDL first schema-design approaches,\ngraphql-js, Apollo Tools, Fastify, Koa, Next.js, SvelteKit, and Deno.Beyond the compatibility of schema-design and HTTP server libraries, Yoga v2 makes deploying a\nGraphQL API to any environment seamless (Vercel Functions, Cloudflare Workers, AWS Lambda and\nmore).Here, a GraphQL API built with GraphQL Modules, deployed on Cloudflare Workers:","productivity-at-your-fingertips#Productivity at Your Fingertips":"","batteries-included#Batteries-Included":"Yoga v2 comes with sensible defaults to make development faster, all with complete TypeScript\nsupport.Features common to modern GraphQL APIs such as file-uploads, subscription support, advanced\nerror handling, or CORS come built-in with Yoga:\n\nYoga v2 also provides APIs to handle logging, advanced Subscriptions use-cases (over WS,\nPub/Sub), Apollo Federation Support, and more.","easily-extend-your-api-with-envelop-plugins#Easily Extend Your API with Envelop Plugins":"GraphQL Yoga supports Envelop out of the box, which gives you greater\ncontrol, and the ability to hook into the GraphQL execution phases.Here, we are building a full-featured GraphQL API with security rules, a response cache and sentry\nerror reporting with only a few lines of code:\n\nThe Envelop Plugin currently proposes more than 35+ plugins covering\nmost of the standard GraphQL APIs features you need in production.Ultimately, you can develop custom Envelop plugins\nto create reusable behaviors that hook on to the GraphQL lifecycle.","production-ready#Production-Ready":"GraphQL Yoga v2 has been built in production for production usage.Built-in real-world conditions within our projects (e.g. GraphQL Mesh)\nand with some of our clients, performance was highly prioritised. The core of Yoga is\nas performant as possible, and we continuously keep track and improve it.Also, the Yoga V2 repository runs performance checks on every commit and Pull Request, so we can\nalways capture any performance regression.Last but not least, every commit is ensured to run on all deployment targets such as AWS Lambda or\nCloudflare workers through an End-To-End testing suite!We continue our effort of pushing GraphQL Yoga to more production environments with the imminent\nrelease of Redwood 1.0 that uses Yoga 2.0 as its default GraphQL server.","a-standards-compliant-graphql-server#A Standards-Compliant GraphQL Server":"In the same way that TypeScript aims to stay aligned with ECMAScript, GraphQL Yoga is based on\nseveral official and recognized specs:\nGraphQL-spec,\nGraphQL-over-HTTP: guarantees your GraphQL API to\nwork with all existing GraphQL clients (Apollo, Relay, urql, and more)\nGraphQL-Multipart-Request:\nenables great file upload support\nW3C Fetch API: we embrace the future of Node.js and provide the\nsame developer experience on all platforms","graphql-features-from-the-future#GraphQL Features from the Future":"Yoga v2 supports some experimental GraphQL features such as\n@defer and @stream, allowing you to get a\ntaste of the future of GraphQL (with compatible clients such as\nurql).Also, thanks to the Envelop plugin system, Yoga v2 can also act as \"Babel for GraphQL\", giving you\nthe option to use features that are not yet in the GraphQL spec but are very useful in production\ntoday, like @defer, @stream and\n@oneOf.","get-started-with-yoga-v2#Get Started with Yoga V2":"Yoga v2 provides the best GraphQL experience while giving you the freedom to use your preferred\nstack and tools.","get-started-from-scratch-with-our-new-tutorial#Get Started from Scratch with Our New Tutorial":"Want to try it? Give\nour brand-new tutorial a try! It will\nguide you in building a full-featured, modern API with GraphQL Yoga.Episode #36 of graphql.wtf is also great\nintroduction to GraphQL Yoga 2.0:","-or-migrate-your-existing-graphql-server-to-yoga#... or Migrate Your Existing GraphQL Server to Yoga":"All Yoga v2's features\nare well documented on the website, and we also have\nsome migration guides (from\nv1, Apollo Server and Express GraphQL).","whats-next#What's Next":"Yoga v2 is the biggest and most important project we released to date; still, it is just the\nbeginning of our GraphQL server vision.We can't wait to get your\nquestions, user feedback, and feature requests/PRs,\nand we already plan for new features such as an Enhanced Plugin System that will provide features\nsimilar to Envelop but at the request level.Don't hesitate to reach out to us on Twitter and support us by\nsharing this article!"}},"/blog/announcing-self-hosted-graphql-hive":{"title":"Announcing self-hosted GraphQL Hive","data":{"":"It has been five months since we launched GraphQL Hive and\none year since we first announced GraphQL Hive, and it has been a wild\nride since then!\nGraphQL Hive is our schema registry solution for continuously evolving your GraphQL schema backed\nby performance insights and usage statistics. Whether you are working in a small company with a\nsingle GraphQL service or a big multi-team company with multiple (federated or composed) GraphQL\nservices, GraphQL Hive is the perfect tool to help you manage your GraphQL schema.\nWe first were surprised but also excited about the amount of interest from companies of all sizes\nand industries and individuals from all over the world in GraphQL Hive. We are so grateful for all\nthe support, contributions and feedback we received so far from external contributors and are\nlooking forward to a bright future!Aside from the diverse range of companies that are already successfully using our hosted GraphQL\nHive version, a lot of companies have been asking us whether it is possible to host your own GraphQL\nHive instance!Since the beginning of the project, we had a different vision for SaaS and community editions of\nGraphQL Hive compared to traditional SaaS products. Instead of only open-sourcing a small portion of\nthe whole stack we always wanted to open-source the full stack and make it easy for anyone to host\ntheir own instance of GraphQL Hive.Today, we are happy to announce that we have reached this milestone and spinning up your first\nGraphQL Hive instance is as easy as running a single command! All you need is docker and\ndocker-compose installed on your machine.Head over to our GraphQL Hive documentation for getting started!"}},"/blog/apollo-angular-011":{"title":"Apollo Angular Version 0.11","data":{"":"","new-name-aot-support-typescript-improvements-and-angular-4-readiness#New Name, AoT Support, TypeScript Improvements, and Angular 4 Readiness":"We recently released version 0.11.0 of\napollo-angular and a lot of things have changed\nand improved since our last update blog!First, here is an overview list of the main changes:\nNew name\nSupport for Apollo Client 0.8+\nAoT support\nMultiple Apollo Client instances in a single app\nTypeScript improvements and TypeScript codegen\nApollo Client Developer Tools\nES6 Modules and Tree Shaking\nSupport for Angular 4\n\nSo let's dive into it!","new-name#New Name":"As you all know, the term “Angular 2” is\nno longer a thing,\nnow it's just “Angular”, without the version suffix (#justAngular). So we renamed the package to be\n“apollo-angular”. We really wanted “angular-apollo” to match up with react-apollo, but it was\nalready taken. That means that from now on the “angular2-apollo” package is deprecated.We've applied this rule to the service as well, so there is no “Angular2Apollo” anymore. It's just\nApollo. Simpler and more convenient. The migration process is very simple:","apollo-client-08#Apollo Client 0.8":"We've updated our dependency to apollo-client 0.8 which includes a lot of improvements in size and\nperformance. check out the full list\nhere.","ahead-of-time-compilation#Ahead-Of-Time Compilation":"One of the most interesting features of Angular is Ahead-of-Time compilation. Angular's compiler\nconverts the application, components, and templates to executable JavaScript code at build time. AoT\ncompilation improves the size of the app as well as the performance and stability thanks to\nstatic-code analysis at build time.\n\nTo support this feature, we had to change the way of providing ApolloClient to ApolloModule. Instead\nof using an instance of ApolloClient directly, it has to be wrapped with a function. Here's an\nexample:","multiple-clients#Multiple Clients":"We're happy to introduce a support for multiple clients. Yes, it's now possible to use many\ninstances of the ApolloClient inside of the ApolloModule, meaning you can call multiple GraphQL\nendpoints from your single client app.The use case for this feature came from some of our enterprise users. Some common use cases are when\nworking with a server endpoint as well as a 3rd party API, or in case you are calling multiple\nmicroservices GraphQL endpoints from on client app. While it's always better to have all of your\ndata in one GraphQL service to be able to get all of the data you need in one request, sometimes\nit's unavoidable to have to call multiple APIs.We decided to make it as an optional feature and to implement it in a way that doesn't break your\nexisting app. Let me explain how it works. First thing, you need to define a function to return a\nmap of clients:\n\nThen, you can use a new method of ApolloModule called forRoot to provide clients, so you can use\nit in your app:\n\nThe Apollo service has now two new methods: use() and default(). First one takes a key of a\nclient you want to use, second one returns the default client.\n\n\nIt's important to know that if you want to have a default client, you need to use default as a\nkey.","more-control#More Control":"Apollo-Client and Apollo-Angular both are written in TypeScript, but we still had room for\nimprovements for our users, here are some of them.Thanks to the recent change we were able\nto take advantage of TypeScript's feature called Generic Types. It's now possible to easily\ndefine an interface of the “data” property in methods like watchQuery, query, mutation and\nmany more.This gives you more control over the code, making it more predictable and easier to\nprevent bugs. Take a look at an example.\n\nIt's very helpful and convenient, especially when used with RxJS operators. You gain more control\nover the result modifications. But there are even more improvements!","lets-talk-about-observables#Let's Talk about Observables":"In Angular world, we commonly use RxJS. Unfortunately, Apollo's standard observable shim is not\ncompatible with RxJS, so to have the best developer experience, we created the\nApolloQueryObservable. They both behave the same, containing the same methods (like refetch for\nexample), except the RxJS support.We recently changed the logic of the ApolloQueryObservable's generic type. Here's an example to see\nhow to migrate:","it-is-human-nature-to-be-lazy#It Is Human Nature to Be Lazy":"We love automation, just to avoid keep repeating the same things on and on again. I have great news\nfor you!As we know, GraphQL is strongly typed, so we have created a tool to generate API code or type\nannotations based on a GraphQL schema and query documents. This tool is called\n“apollo-codegen”.Thanks to Robin Ricard's work, Apollo Codegen now supports TypeScript, so Angular developers no\nlonger have to define types for their queries manually.","better-developer-experience#Better Developer Experience":"We are happy to announce that Angular integration works great with the\nApollo Client Developer Tools.It's a Chrome DevTools extension for Apollo Client which has 3 main features:\nA built-in GraphiQL console that allows you to make queries against your GraphQL server using your\napp's network interface directly (no configuration necessary).\nA query watcher that shows you which queries are being watched by the current page, when those\nqueries are loading, and what variables those queries are using.\nA cache inspector that displays your client-side Redux store in an Apollo-Client-friendly way. You\ncan explore the state of the store through a tree-like interface, and search through the store for\nspecific field keys and values.\n\nTry the dev tools in your Angular Apollo app today!","es6-modules-and-tree-shaking#ES6 Modules and Tree Shaking":"App load time is an important part of the overall user experience. Earlier, I talked about AoT\ncompilation, which radically improves performance, but there is still room to speed things up.To make our app even smaller we can use a process called Tree Shaking. It basically follows the\ntrail of import and export statements by statically analyzing the code. This way we get rid of\nunused parts of the application.As you know, every angular package has a UMD bundle (to support CommonJS and AMD) and a\nseparate space for ES6 Modules. Thanks to recent changes in the\napollo-client and\napollo-client-rxjs, we do the same, so\nyou can use tree shaking in your app!","ready-for-the-future#Ready for the Future":"With the first stable version of Angular, the core team announced a predictable release schedule. It\nmeans that every 6 months there's going to be a new major version of the framework.We have good news!Angular 4.0.0 is now still in beta, but it's fully compatible with Apollo, so you don't have\nto worry about any breaking changes.","keep-improving#Keep Improving":"We are working hard to give Angular developers the best developer experience we can. We want to hear\nmore from you — what should we do next, what can we improve?And if you are really interested in GraphQL, Did you know\nApollo is hiring?"}},"/blog/build-realtime-graphql-backends-with-grafbase":{"title":"Build realtime GraphQL backends with Grafbase","data":{"":"The Guild has made working with realtime\nGraphQL Subscriptions and Live Queries\neasy over the last few years thanks to plugins that work out of the box with\nGraphQL Yoga.However, there are developers who don't want the hassle of building a backend, managing deployments,\nconfiguring continuous integration, juggling connection pooling, and more. Thankfully, there are\nsolutions designed to abstract all the hard work.Grafbase was built to manage all of the above. You get a distributed GraphQL\nAPI at the edge by creating a single grafbase/schema.graphql file in your project.Your schema contains models with special directives to relate data, set default values, validation,\nand more.\n\nIn 2021, Laurin Quast introduced a collection of packages to support\nthe use of GraphQL Live Queries on the server and client.Today, Grafbase is happy to announce it now supports GraphQL Live Queries!This means that all you need to do to start using GraphQL Live Queries is add @live to your query!\n\nThe @live directive will observe any changes to the data and send a message using\nServer-Sent Events with the\npatch to update the current query state.The event is in the format of\nJSON Patch:\n\nTogether with The Guild, Grafbase is also releasing 2 new packages (with more on the way) to further\nabstract the effort needed to implement Live Queries on the frontend.Starting with support for Apollo Client and\nURQL, you can add Live Queries with the following\npackages:\n@grafbase/apollo-link\n@grafbase/urql-exchange\n\nDevelopers not using either of those libraries can still use Live Queries with the native\nEventSource API.","try-it-now#Try It Now!":"You can try Live Queries by building your own backend in one simple command:\n\nOnce you've modelled your data using the schema you can\nrun your backend locally to build:","about-grafbase#About Grafbase":"Grafbase is the easiest way to build and deploy GraphQL backends. Go from idea to production in\nseconds, without spending time on infrastructure.\nBuild backends with GraphQL SDL as configuration\nSpin up instant preview environments with every PR\nBuild locally with the CLI — npx grafbase dev\nDeployed to the edge with no cold starts\nAdd granular permissions for users (and groups)\nBuild collaborative multiplayer apps faster with Live Queries"}},"/blog/caching-data-with-dataloader":{"title":"Caching data with DataLoader","data":{"":"","caching#Caching":"Caching is an essential part of designing scalable and performant GraphQL API.But, what is caching? Caching is the technical design of trying to avoid compute-intensive tasks by\nkeeping their results temporarily in a cache. A cache is a place in memory for important data, which\ncan be delivered to the client faster than the regular procedure.For example, for a GraphQL API, we might want to cache a field value that comes from a slow external\nAPI. The goal of caching is to improve performance where it’s needed the most.","how-is-caching-faster#How Is Caching Faster?":"Using a cache for compute-intensive data is faster for a few reasons:\nA cache is usually not stored in storage, but in memory, which is a much faster.\nA cache is smaller than a database, so there are a lot less values to filter through.\nWhile some cached data might be queried a lot of times, it will be fetched from the database only\none time, so there's less time lost for fetching multiple times.","how-do-we-use-caching#How Do We Use Caching?":"","caching-with-dataloader#Caching with dataloader":"My preferred platform for caching is dataloader, and in this tutorial I will explain how to use\ndataloader with Node.js and Typescript, to have caching in your server.\nTip: dataloader outside of GraphQLThe dataloader package was created specifically for GraphQL, but it can work with other Node.js\nprograms.","using-dataloader#Using DataLoader":"","1-install-dataloader-in-your-project#1. Install DataLoader in Your Project":"Install dataloader by running the following:npm install --save dataloader or yarn add dataloader","2-import-dataloader#2. Import dataloader":"To start, import dataloader and LRU (LRU is a cache algorithm that will put only the most X\nrequested items in the cache).","3-define-the-types-that-would-be-saved-to-our-cache#3. Define the Types That Would Be Saved to Our Cache":"The first type should be a way to represent the data, like a string with a name, and the other is\nthe data itself. For example, let's say we're trying to cache books. Our package name will be the\nbooks' id, so we can tell which book is which. Our package data will be the books' length, writer,\nprice etc...so in this case, our schema would look like this:\n\nand the corresponding data type would look like this:\n\nThe reason we write types is for type safety, let's say we have books and toys which have different\nvalues, we wouldn't want that somehow toys will be inserted into our books cache","4-create-the-dataloader-instance#4. Create the DataLoader Instance":"As you can see, we give the keys that the user asks for to the dataloader (1).I recommend setting the keys to be some kind of id for the following reason: Lets say that in your\napi, the user asks for data using its id, so the user will fetch with id:\"something\", you could\njust pass the id as the key, instead of changing it.The dataloader will first check if it has the keys on cache, and if so, it would return the data,\nwithout going through the database, saving you a lot of valuable time.After that (2), we give the dataloader a function for fetching the data, in case it doesn't have it\nin the cache. In this case, I have the function getData, and I'm using the keys to \"get data\" from\nmy database.In the end (3) we give it cacheMap and some value, the value represents how many queries dataloader\nwill cache, in this case, after a 100 values, it will delete the least used value (the one that\nwasn't queried for the longest time) to make space for the 101st value.From now, to query data, you just run","dataloader-with-graphql#DataLoader with GraphQL":"Dataloader was designed to work with GraphQL, to solve the\nn+1 problemThe N+1 problem is a common problem when designing GraphQL API. Looking at the Query below, we can\nsee that the GraphQL API will call 20 times the Book.author resolver:\n\nDepending on the resolver implementation, this query might trigger 20 python queries or API calls to\nresolve authors that might've wrote multiple books. Dataloader helps to solve this problem by\ncaching, deferring and grouping similar resolver calls.","how-to-use-the-dataloader-package-with-graphql#How to Use the DataLoader Package with GraphQL?":"To use the dataloader with GraphQL just pass it in the context!Now, your code should look somewhat like this:\n\nNow, in your resolvers, just call context.dataLoader.load(keys) and that's it! You now have\ncaching in your server!An example of a resolver implementation:\n\nfor further learning, check these out:The n+1 problem\nThe dataloader github page\nA great video about dataloader"}},"/blog/codegen-typescript-react-apollo":{"title":"GraphQL Code Generator for Typescript React Apollo","data":{"":"GraphQL Code Generator is a template based\ngenerator that lets you generate anything out of your GraphQL schemas and queries.So we've created a new template that generates React Apollo's Query, Mutation and\nSubscription components, as well as HOC components, all completely typed by\nTypeScript, so you won't have to do that work manually!","introducing-a-code-generator-for-react-apollo#Introducing a Code Generator for React Apollo":"Whether you use the new React Apollo API or you prefer to use HOC, there is really no need\nto write those wrapper components again and again!Based on a GraphQL static schema and a GraphQL query, the\nGraphQL Codegen - Typescript React Apollo Template\nwill generate a ready to use, fully typed components. All you need to do is to write your query,\nmutation or subscription and just use those components in your application.\n\nUsing React, TypeScript and GraphQL in a coordinated way, gives us new level of\nsimplicity and power for our developer experience:\nLess code to write — no need to create a network call, no need to create Typescript typings,\nno need to create a dedicated React Component\nStrongly typed out of the box — all types are being generated, no need to write any Typescript\ndefinitions and struggle to keep them updated\nFull developer experience of tools and IDEs — development time autocomplete and error\nchecking, not only across your frontend app but also with your API teams!","play-with-it#Play with It":"We prepared an example of how to use those auto generated components,\nit's available on CodeSandbox.","start-using-it#Start Using It":"All you need to do to use React Apollo template is to install two packages:\n\n\nMake sure you have graphql installed as well.\nNow let's create codegen.yml configuration file, pointing to our schema and documents files:\n\nNow let's set up a npm script in package.json to run graphql-codegen command:\n\nIt might seem like a lot but lets split it into smaller pieces and explain each one of them it will\nmake things easier.\nschema: — path of a file with schema or an URL\ndocuments - list of code files that contains your GraphQL queries\ngenerates: — list of output files, with a nested list of plugins we would like to use.\n\nThen, define a .graphql file with a document that you'd like to use in a component:\n\nNext, you need to run GraphQL Code Generator to generate Typescript types and React components:\n\n\nYou can also run yarn graphql-codegen directly.\nThen, you simply import the auto-generated React Hook, named after your GraphQL operation name and\nuse it in your component:\n\nYou can learn more about React Apollo API here.\nIf you are not using React Hooks, and you prefer to use React HOC or React Components for your data fetching, you can change the codegen configuration flags according to your needs:withHooks: true - will generate type-safe hooks.withComponent: true - will generate type-safe data components.withHOC: true - will generate type-safe High-Order-Components.\nWe believe GraphQL is a game changer in how you plan and create your frontend apps.The vision that guides us is that you should be able to sketch a list of data types your backend can\nprovide, sketch components and their data dependencies — and all the rest of the plumbing can be\ngenerated for you.Once you'll write an app like that, you will ask yourself why did you write all the other\nboilerplate code by yourself before.This is just one template out of many, check out more things you can generate with the\nGraphQL Code Generator and give us ideas about other templates\nyou would like to see implemented."}},"/blog/ci-ci-graphql-inspector":{"title":"Validate GraphQL Schema - Continuous Integration & Delivery Pipeline","data":{"":"GraphQL Inspector since day one supported any kind of Continuous Integration and Delivery Pipeline.\nNothing new here, except now it's more flexible and super lightweight.The new version of GraphQL Inspector comes with a CLI crafter specifically for CI/CD.We recently released a lot more interesting features. You can read about them in\n\"New GraphQL Inspector and upcoming features\" article.","cli-forci#CLI for CI?":"The regular CLI comes with everything built-in. Loads Schema, Operations and Fragments from any\nsource. It can extract GraphQL pieces from GraphQL files, code files (Vue, React, Angular and even\nGatsby). The CLI supports GraphQL Endpoints, Git repositories and also files on GitHub.It's heavy!Usually, in the CI/CD pipeline you want to compare a current schema with the one in production and\ndetect breaking changes. Which means, you don't need all the other commands and features of\nInspector CLI.","cli-designed-forcicd#CLI Designed for CI/CD":"That's why in new GraphQL Inspector, everything is a plugin.You want to compare schemas and detect breaking changes?\n\nYour production schema is accessible through an endpoint but newly proposed schema is defined\nin .graphql files?\n\nOk, everything is ready!","how-to-compareschemas#How to Compare Schemas?":"You can use the command below in your CI/CD pipeline:\n\nHere's how the result looks like. It shows a list of all changes and groups them by criticality\nlevel (Breaking, Dangerous or Safe).\n\nTo learn more about CLI for CI, please read\n\"Continuous Integration\" chapter in our\ndocumentation.","future-plans#Future Plans":"We're working on Azure and Bitbucket integrations plus a monitoring feature. Talk to us to\ntry it out.We want to make Azure and Bitbucket a first-class citizens in GraphQL Inspector and give you\nthe same experience as you get right now with GitHub.Monitoring will enable you to analyze the traffic of your GraphQL APIs and provide details\nneeded to improve performance. Collecting informations about the usage will let you safely remove\ndeprecated pieces of GraphQL Schema.\nIf you're interested, please reach out to us!","enjoy-graphql-inspector#Enjoy GraphQL Inspector!":"We have big plans for Inspector, and you're very welcome to join us in that journey.GraphQL Inspector is a tool created by developers, for developers and that's why we'd love to get\nyour feedback and shape GraphQL Inspector together!Oh... and it's Open Sourced!"}},"/blog/collecting-graphql-live-query-resource-identifier-with-graphql-tools":{"title":"Collecting GraphQL Live Query Resource Identifier with GraphQL Tools","data":{"":"Photo by Łukasz Nieścioruk on\nUnsplash\nNote: This article showcases technical details for implementing a Live Query engine with\ngraphql-tools. If you are new to Live Queries you might want to check out Subscriptions and Live\nQueries - Real Time with GraphQL\nfirst.\nGraphQL live queries can solve real-time updates in a more elegant way than GraphQL subscriptions.Instead of subscribing to events live queries primarily subscribe to data changes.Instead of updating the client store manually a live query updates the client store magically\nwithout redundant cache update logic on the client.You can learn more about the differences here.All those benefits, however, come with the drawback of the server having to become stateful, in\nparticular, being aware of all the data the client operation consumes and re-executing those query\noperations for a specific client once the underlying data changes.As I first started experimenting with GraphQL live queries the easiest solution was to simply\ntrigger live query re-executions based on the Query object type root fields. E.g. a query with a\nselection set selection on the Query.viewer field could be re-executed by emitting the\nQuery.viewer event through the live query store event emitter. However, the viewer could be a\ncompletely different record/resource for each client that consumes the given query operation.To be more clear here is the corresponding schema:\n\n\n\nLet's see how the implementation for this could look like:\n\nIf a specific user updates his login we shouldn't invalidate and re-execute any live query operation\nthat has a viewer selection set for any connected user who might not even be affected by that\nchange!At the same time, the user could also be referenced in another operation e.g. a list of all\navailable users (Query.onlineUsers). The Query.viewer event would not cover and schedule a\nre-execution for operations that select the user via that field.","there-must-be-a-better-solution-for-uniquely-identifying-the-selection-set-data#There Must Be a Better Solution for Uniquely Identifying the Selection Set Data":"As you probably noticed the user has an id field of the ID! (nonnull id) type. This is a\ncommonly used field for uniquely identifying a resource on the client-side. Apollo-client uses the\n__typename field in combination with the id field as the default resource cache key (User:1),\nRelay goes a step further and already assumes that the resource type is already encoded (e.g.\nbase64(\"User:1\") Note:\nYou are not forced to use base64 🤔) inside the id and\ntherefore only uses the id field.What if we could also use such an identifier on the server-side in our live query store\nimplementation?My current implementation just traversed the AST of the query operation and extracted the\nschema coordinates on the root query type. E.g.\nQuery.viewer for the viewer live query operation from above.However, in case we would want to identify the user via the id we must also add something like\nUser:1 to the set of resources the live query operation selects. This requires schema knowledge as\nthe live query store needs to know which type has an id field and if included in the selection set,\ngather the corresponding resource identifier.As mentioned above this allows more granular query invalidations.The first drawback I had in mind is that if an operation does not specify the id field on the\nselection set, the resource cannot be tracked by the live query store.However, most operations will probably select the id field as it is most likely used on the client\nfor the cache keys.Furthermore, it could be possible to simply transform the query in such a way that the id field is\nadded to the selection set (similar to how apollo-client is by default adding a __typename\nselection to each object type).For keeping things simple I decided to push the responsibility for selecting the id field to the\nclient that sends the live query operation. I also could not find a use-case in my existing\napplication where there was no id selection for a resource 👍.","implementing-the-resource-identifier-collector#Implementing the Resource Identifier Collector":"The next obstacle is to decide how the ids are extracted and I had two options in mind.","1-traversing-the-graphql-execution-result-tree#1. Traversing the GraphQL Execution Result Tree":"This simply seemed complicated to me as I would need to traverse the whole result while somehow\nguessing/checking the type of each leaf based on the operation AST and the schema. I quickly dropped\nthat idea.","2-manually-register-the-resource-identifier-by-calling-a-function-that-is-injected-via-the-context#2. Manually Register the Resource Identifier by Calling a Function That Is Injected via the Context":"The goal of my live query store implementation is to add live query support to any schema with\nminimal effort. Passing something along-side the context that a library user must call inside a\nquery resolver seemed wrong and all this should be an implementation detail the library user should\nnot care about.Imagine if we had to register a resource manually in each resolver that returns an object type.\n\nIt might seem quite simple for a single resolver, however, it can quickly clutter and lead to bugs\nif we have to manually do that for any resource in any resolver.Ideally a library user will just have to add a context.liveQueryStore.triggerUpdate(\"User:1\") line\nto the updateLogin mutation field resolver in order to magically schedule an operation\nre-execution, without the overhead of adding an additional function call to each resolver.\n\nSo, I thought more about how this could be implemented in a less verbose way.As any other field, the id field has a resolver (either the default resolver provided by GraphQL\nor a user-defined resolver), so if there was a way to wrap each id field resolver with a function\nthat could solve the issue. The wrapper could call the actual resolver, register the resource, and\nthen return the value. The user won't have to care about anything (besides adding the id field to\nthe selection set of the query).The best library for transforming and modifying GraphQL Schemas is\ngraphql-tools. Fortunately, it is now maintained by\nThe Guild, as apollo abandoned it and was maintained pretty poorly.So I dug a bit into the fancy documentation and found @graphql-tools/wrap.A quick excerpt from the documentation:\nSchema wrapping is a method of making modified copies of GraphQLSchema objects, without changing\nthe original schema implementation.\nLooks perfect, but since in this specific case I could potentially modify/map an existing schema, I\ndigged a bit further, chatted with @yaacovCR and learned about\nmapSchema from @graphql-tools/utils. It maps an existing schema into a new schema while applying\nsome rules (kind of similar how Array.map() works 🤔).Using mapSchema might be slightly faster as there will be no delegation to a second schema.So the final plan is the following: We map the existing schema and warp the resolver fields append\nthe resource identifiers to a Set.\n\nThe implementation for executing the operation is similar to the following:\n\nI had to wrap the \"user\" context in a context (context-ception 🤯) on which I also attached the\nfunction for adding the resource identifier to the resource identifier set. I got inspired for this\nby the apollo-server source code, as I knew it has a way for measuring resolver execution time,\nwhich must be done on a request/operation basis similar to the resource identifier collection. This\nmethod allows using a new function/context for each execution. Inside the field resolver, the\ncorrect user context is then passed into the actual (user) field resolver.Now after the operation has been executed against the schema the newIdentifier Set should contain\nthe identifiers of all the resources that were resolved during the operation execution.The live query store can now use that information for re-executing queries once a resource\nidentifier event is emitted 👌.","conclusion#Conclusion":"Identifying resources and invalidating queries based on a resource basis rather than a query root\nfield basis allows more efficient query re-executions and can avoid pushing unnecessary updates to\nclients.GraphQL Tools is a super handy library that can be used for solving a huge variety of problems. I am\nglad it got such a huge update and good documentation!The implementation probably won't cover all use-cases. What if a client is not authenticated and the\nQuery.viewer resolver returns null. There is no User:ID string available on the live query\nstore operation context once the user has authenticated. Either a Query.viewer update must be\nemitted through the live query store emitter (which will affect ANY client operation that selects\nthe viewer), the client must re-execute the operation after login or the live query store must\nsomehow be notified to re-execute all operations of the user that just authenticated.In case you are interested in the source code for the implementation\ncheck it out on GitHubThere is still more to discover and build in live query land!We still need to manually notify the live query store that a resource must be invalidated. An\nabstraction for doing this behind the scenes could vastly differ for different stacks.Maybe the ORM/database store layer could emit the events or a proxy could emit those events based on\ndatabase operations such as INSERT, DELETE, and UPDATE.Re-executing a query operation is nice and smart, but not the most efficient solution. What if we\ncould only re-execute certain resolvers? I already have some ideas in mind, and I will probably\nwrite about that as well!Check out this super cool talk about live queries @ Facebook!Check out this super cool talk about live queries @ Samsara!I also wrote an article about my Socket.io GraphQL Server Engine implementation!"}},"/blog/coolest-underrated-design-pattern-in-react":{"title":"The coolest, most underrated design pattern in React","data":{"":"There will be times when we would like to pass props and control the behavior of child elements. Let\nme explain. Let's take the following modal for example:\n\nAs you can see, the modal contains the following elements:\nA title.\nAn x button.\nSome text content.\nA dismiss button (“Close”).\nAn action button (“Save changes”).\n\nThese elements should be modifiable if we would like the modal to be properly re-usable. That means\nthat the user would have control over things like the displayed content, dispatched events, style,\netc, of each and every element. A naive solution would be accepting distinct props for each\nelement like so:\n\nThe problem with that approach is that it spams the props mechanism; it makes the component look\ninflated and less readable. Moreover, it limits the amount of props that can be passed to child\nelements, and prevents the user from having a full control over them. You can solve this problem\nhowever, by providing a series or generic props objects, where each one represents a different\nelement respectively:\n\nThis solution works, but then again, it doesn't solve the spamming issue, plus, we completely abuse\nthe syntactic sugar that JSX provides us with. Instead of using HTML style attribute assignments\n(attr=\"value\"), we're obligated to use JSONs.","bootstrap-for-the-rescue#Bootstrap for the Rescue":"In Bootstrap they took a very clever approach. Instead of defining props all over the place, they\ngave us the ability to directly manipulate the modal's children. Using dedicated components, we can\nachieve the intended functionality that Bootstrap was aiming for:\n\nGreat! There's definitely a progress right there. But we can even take it a step further.\n“A step further? What do you mean?” — A confused React developer\nEven though things are very declarative and clear with Bootstrap's approach, we're still obligated\nto compose the entire modal. This means that we cannot use the modal's children to fill-up the\nmissing pieces, as if part of the logic was already implemented. It's not always that we would like\nto write the modal's contents entirely from scratch, right? Sometimes we would like to use it like\nsome sort of template. Another point to consider, is that there's no filter or restrictions on the\nchildren's input. Sometimes we would like the user to use only certain elements, and thus make sure\nthat he doesn't mess things up. If so, what's the right approach that goes along with it?","introducing-the-design-pattern-that-has-it-all#Introducing the Design Pattern That Has It All":"Let's recap. Based on what we gathered so far, the new design pattern should have the following\ncharacteristics:\nNo spamming of the props mechanism.\nHas full control over child elements using props.children.\nHas a template already in place.\nHas restrictions on the input.\n\nNow that sounds promising. Let's have a look at an example. We will use the Bootstrap Modal\ncomponent as an anchor:\n\nAs you can see, the new modal component uses a hook called useChildProps(). This hook will go\nthrough `props.children` and will basically flatten nested props. In addition, it will validate\nthem against a provided white list, to make sure that the right element names were addressed. This\nis how its implementation should look like:\n\n\n\n\n“Wait a minute, can't it cause a confusion with native HTML tag names?” — The developer from\nbefore\nTrue, but that can also be said about any other React component. Ever since the introduction of\ncomponent based UI (e.g. Angular, React, Vue or even Web components), new tag names aren't so rare\nto come across by, therefore you shouldn't be afraid to use the new design pattern."}},"/404":{"title":"404: Page Not Found","data":{"":"It seems like the page you are looking for does not exist, or has been moved.Our team tracks all broken links, and we will try to fix them as soon as possible."}},"/blog/customizable-css-engine-in-javascript":{"title":"I wrote a customizable CSS engine in JavaScript","data":{"":"","custom-selectors-custom-rules-and-custom-events-you-determine-its-behavior#Custom Selectors, Custom Rules and Custom Events. You Determine Its Behavior":"For some things CSS is simply not enough, we need JavaScript. I'm sure that we all experienced it\nnot once, nor twice, the feeling of wanting to have a specific behavior or style that aren't\nsupported by CSS. An arbitrary example: selecting an element based on regular expression, playing a\ntransition dynamically to the element's changes in dimension, or sticky positioning (which is\narguably working in some browsers based on my personal experience). However, this is not why I wrote\nthe CSS engine.I wrote the engine to repeat the same thinking process that the original developers went through,\nand to understand the difficulties and challenges that they faced. Why? Because it helps you think.\nWith a custom implementation of CSS you can achieve exactly what I mentioned in the first paragraph\nand thus understand the mechanism a lot better.\ndisclaimer: I haven't looked into the native implementation of CSS. There's a lot you can take\nfrom my article (at least I hope), yet please take my words with a grain of salt.","first-thing-first--demo#First Thing First — Demo":"Here's an example of a stylesheet with a custom rule named boom:\n\nThis rule will change an element's contents to “BOOM!” and its border, background, and text color\nbased on the given parameters. Here's the rule in action:https://codepen.io/eytan-manor/pen/RXPPvoIf you'll look at the demo's source code\n(which I highly advice before you continue any further)\nyou'll see how I define custom properties to my stylesheet with the\nEvent,\nSelector\nand\nRule\nclasses. The engine does follow the native CSS path, although it's still in early stages and doesn't\nsupport many features and capabilities, such as:\nSeparation of concerns for styles and events. They can still be used and modified outside the\nstylesheet.\nRe-evaluation of style if stylesheet gets updated.\nSelector context specifiers e.g. > or\n+ (e.g. div + span)\nAny kind of query (@media,\n@keyframes,\n@import, etc).\n\nSince this is a customizable engine, with a little of creativity you can implement a lot of things,\nsuch as animations, URLs, selection and transformation functions, etc.Indeed, there's a lot going on under the hood and a lot to go through, so let's get into the\ninteresting bits.","keynotes-from-the-implementation#Keynotes from the Implementation":"","reading-the-stylesheet#Reading the Stylesheet":"Receiving information from a given CSS string is a challenge as for itself. Since I wanted to\nstrictly preserve the original CSS experience, I didn't settle for a JSON, but rather an actual\nsheet with a set of rules and selectors. To parse it, you first need to be familiar with the concept\nof an AST.AST stands for Abstract Syntax Tree, and it's made out of a hierarchy of nodes; each node represents\na different feature of the syntax. Essentially the AST is an in-memory representation of the code\nfrom which data can easily be retrieved. In this case, the retrieved data will be the selectors and\nthe rules underneath them. If you wanna know more about the AST, I recommend you to read my article\nabout building a Babel plug-in.The CSS is broken down into AST nodes like following:\n\nThe AST is now presented as a plain JSON. To make things even more convenient, I run it through a\nsecond iteration where it's gonna get wrapped with the classes defined in the registry of the\nstylesheet, e.g.\nBoomRule\nand\nClassNameSelector.\nA node will be wrapped if it matches the properties of the target class:\n\nWith a wrapped AST, not only we can get information about the given CSS string, but we can also call\nrelated methods directly from a specific node. So given a node of Selector type, we can call the\ntest\nmethod to see whether an element actually matches the selector or not.","detecting-changes-in-the-dom#Detecting Changes in the DOM":"The engine is heavily based on the\nMutationObserver to detect\nchanges in the DOM tree. The mutation observer will trigger a callback with details regards the\noccurred mutations (see\nMutationRecord) from the recent\nexecution loop. The problem with the MutationObserver is that it will create a mutation record for\neach mutation occurred without taking into an account the final result. That means that if a DOM\nnode was added, removed, added, removed, and then added, it will appear as if it was removed 2 times\nand added 3 times, rather than added just once.To overcome this issue, I've normalized the collection of mutation records to include only the\nmutations which are relevant, based on the logic that I just mentioned (see\nnormalizeMutations()).\n\nOne of the core behaviors of CSS is that once it's loaded, the style is immediately applied. The\ncatch here, is that the mutation observer callback will not be invoked unless real mutations\noccurred. One way to apply the loaded style is to force the mutations; remove all nodes and re-add\nthem to the observed element. However, this would be very inefficient.The other, more efficient way of solving this is to synthesize the mutations. Yes, go through each\nand every node in the DOM tree recursively and create a fake mutation JSON. Once it's done, the set\nof mutation records can be injected to the observation callback and the style should be applied\nbased defined customizations to the engine (see\nsynthesizeMutations()).\n\nOne thing to note is that we're likely to change the style attribute inside rule event handlers,\nwhich will unnecessarily re-trigger the mutation callback and might potentially cause an infinite\nmutation loop. To avoid that I used the\ntakeRecords()\nfunction to dispose the pending mutations from triggering.","triggering-custom-events#Triggering Custom Events":"Events management is a crucial part in the implementation because it will determine the efficiency\nof the engine. If events aren't disposed or reallocated exactly when needed, this will dramatically\naffect how fast will things work.With each mutation callback, elements are filtered based on the selectors found in the stylesheet\nAST. Once an element has been cherry-picked, event listeners will be added to it based on the set of\nrules that are defined under the CSS block that the target selector represents at the current\niteration.The engine uses a very naive approach where events are disposed and reallocated for a specific\nelement whenever there are incoming mutations of addition or attribute modification types. This way\nI make sure that even if a node was modified and a selector is not relevant anymore, only the right\nhandlers would run once a specific event has been triggered.\n\nIf you looked at the source code of the demo, you probably noticed that each rule has a disposal\nfunction. In case you didn't, here's a snapshot of a sample rule:\n\nThe disposal function will run each time the selector is not relevant anymore in which case the\nelement in question will stop listening to the event. So how did I make sure that the disposal\nfunction runs on each event disposal? Simple. I've splitted the logic into a dedicated module which\nis responsible for managing the events (see\nevents.js).The module will add and remove events for given event target as normally, but in addition to that,\nit will store the event handler alongside the disposal method with internal cache maps. Once an\nevent is removed, the corresponding disposal methods in the cache will be called as well.","how-can-it-be-better#How Can It Be Better?":"","disposing-and-reallocating-events-only-when-necessary#Disposing and Reallocating Events Only When Necessary":"Right now all registered events for a specific element are being disposed and re-allocated to make\nsure that only the right handlers will run; this way if a selector becomes irrelevant due to recent\nchanges to the element, it won't effect its style.This is a not all-too-bad yet naive approach. It works well, but it's inefficient, something which\nwill become very noticeable once the stylesheet will grow bigger and bigger. One thing that can be\ndone is to run the\ntest()\nfunction of a specific selector before event listeners are disposed. If there has been a change\nin the outcome of tests, only then proceed to disposing and reallocating the event listeners.\n\nThis can be taken a step further by observing which properties of the element has changed during the\napplication of specific rule, and store them all in-order. Once a selector becomes irrelevant and\nits rules don't apply anymore, the style would be re-evaluated only relatively to the style\nproperties which are not affected anymore. This is a very complex mechanism to implement but still\nachievable.","unleashing-the-full-potential-using-webassembly-and-webgl#Unleashing the Full Potential Using WebAssembly and WebGL":"One of the clear advantages of a native CSS engine over its JavaScript equivalent, is that it's\nwritten in a low level language such as C or C++. That can be compensated with the usage of\nWeb Assembly, where we can write our code with\nRust and compile it to a low-level language that can run on the browser. To\ntop things up, we can use WebGL or a\nlibrary such as GPU.JS to run vector calculations in parallel using all cores\nof the GPU.Needless to say that this is only relevant if you want to implement graphical manipulations such as\nelement shadows, text stroke or image filtering. It's better to keep things simple and use only the\nstyle API which is offered to us right out-of-the-box by the browser.","concept-rethink-event-handling-in-ui-frameworks#Concept: Rethink Event Handling in UI Frameworks":"Most modern UI frameworks such as React, Angular and\nVue are tightly coupling event registering and handing with the component\nitself. While this has proven itself to work (greatly) over the years, a customizable stylesheet (or\nevent sheet as you may call it) can be an alternative that can offer some benefits.\n\n\nThe sheet can be loaded and applied on any existing DOM element regardless of the used UI\nframework.\nThe sheet is heavily customizable and can easily share rules and behaviors between different DOM\nelements.\nThe sheet is very declarative and easy to go through. It's flat with no indentions of few levels\ndeep.\ndifferent sheets can be loaded on top of different customizations of selectors and rules.\nThe sheet is lightweight and can be loaded quickly.\n\nHave any counter claims? Prove me wrong! Or maybe prove me right :-) Constructive criticism with\nsolid arguments from any side of the divide will be more than welcome.☆ The source code is available on GitHub ☆\nNote: It's still just a concept. DO NOT use in production."}},"/blog/create-native-addon-using-c":{"title":"How to create a native add-on using C++","data":{"":"In this tutorial we're going to go through the basics on how to write a native add-on to NodeJS\nusing C++, one of the platform's most powerful capabilities of which most web/JS developers now a\ndays are not even familiar with.For somewhat there is a vacuum which got created around C++ in the recent years, people are so\nscared from a low-level back-end programming, why should they even deal with memory allocation\ndilemmas when there are all these interpretation languages like Python, Ruby, and JavaScript who can\ndo that for us? Well folks, once you will realize that all these single web-page application\nthird-party libraries and frameworks are all recycled and repetitive, and you will start doing some\nreal shit by optimizing some heavy-ass machine algorithms, you will realize that performance is\ncritic, a title which doesn't really suit NodeJS, with all the love and respect. So why do I even\nbother making this tutorial? Because people are unaware of many features in the programming world,\nand the beauty of algorithmics. And why am I even approaching NodeJS developers? Because they have\nthe biggest, most-popular community of all, they have a lot to learn, but they are very open-minded,\nand that's the most important thing. You don't have to be a C++ developer not at all, but if I can\nat least catch a small part of your attention I will be overwhelmed.We will create a very small and simple module which calculates the distance between two dots, it can\ndo it either synchronously or asynchronously. The algorithm for calculating the distance between a\ngiven pointA and pointB in a 2D\nCartesian coordinate system looks like\nthis:\n\nProbably not too complicated, kicks me back to the glamorous days in high-school. If put in\nJavaScript it should take around 10 seconds right? Well in a native NodeJS add-on it should be a bit\nlonger. Of-course when it comes to small logics you shouldn't make too much effort, because it will\nconsume more power only converting all JS objects into C++ native structures. But imagine you would\nlike to run a blob-detection algorithm and you would\nlike to calculate the center of mass of multiple\nblobs, in C++ it would be much faster, especially when using\nshaders. Anyway that's not the point of this tutorial, the\npoint is that you will be provided with the necessary tools so next time if you would like to write\nsome heavy logic, you will know how to do it.We will start with a brief introduction for Google's\nv8 engine and some practical examples on\nhow to use it, this will help us to get start, and then we will write our add-on. Let's begin then\nshall we?","introduction-to-v8#Introduction to V8":"The v8 JavaScript Engine is an open source JavaScript engine developed by The\nChromium Project for the\nGoogle Chrome web browser. It is intended to be used both in a browser\nand as a standalone high-performance engine that can be integrated into independent projects like\nCouchbase, MongoDB and Node.js.\nThere lots of benchmarks out there but I will not bore you with diagrams, we all know that this\nengine has proven itself to be worthy, and it is being used world-widely and probably for a good\nreason.\n“Ambition is a dream with a v8 engine” -Elvis Presley.\nIf you're a JavaScript developer you must be familiar with the event-loop and the scoping system of\nv8, so it's a good thing that you understand the concept, but you never got to actually look at its\nsource code and explicitly use it. A detailed documentation for v8's different API versions is\navailable here. I assume that you don't bother reading any of my\nreferences that I provide along this tutorial (As a lazy blog-reader myself), I will post here that\nfirst thing you're going to see once you enter v8's documentation web-site:\n\nThroughout history v8 have changed a lot, and it wore many forms. As a result, add-ons are not\nusable across different versions of the platform since each one supports a different API, which will\nbreak our process during run-time. In NodeJS team they came up with a very convenient solution\ncalled Nan. Nan stands for “Native Abstractions for NodeJS” and is\nbasically a header file filled with macro and utility goodness for making add-on development for\nNodeJS easier across all versions of v8, without inspecting NODE_MODULE_VERSION macro all the\ntime. In this tutorial I'm going to refer both of them as if they are bundled in a single framework.Eventually JavaScript is just a rehash of v8, everything you know so far is still valid, but it uses\na different idiom. To prevent some misconceptions, here are some important points regards\nJavaScript's equivalents which I think you should follow:","scopes-and-variables#Scopes and Variables":"In v8 a scope is referred as Isolate (v8::Isolate) and a variable is referred as Local\n(v8::Local). A local is a pointer to an object. All v8 objects are accessed using locals, they are\nnecessary because of the way the v8 garbage collector works. An isolate can be thought of as a\ncontainer for any number of locals. When you've finished with your locals, instead of deleting each\none individually you can simply delete their scope.JavaScript\n\n\n\nC++","asynchronous-callbacks#Asynchronous Callbacks":"Asynchronous logic can be implemented using the AsyncWorker (Nan::AsyncWorker) and invoked by\nAsyncQueueWorker (Nan::AsyncQueueWorker). Thanks to these two you can have much of the annoying\nasynchronous queuing and handling taken care of for you. It can even store arbitrary V8 objects for\nyou and have them persist while the asynchronous work is in progress.JavaScript\n\nC++","modules-registration-and-methods-definition#Modules Registration and Methods Definition":"v8 and Nan provide us with some handy macros (NODE_MODULE, NAN_MODULE_INIT, NAN_METHOD and\nNODE_SET_METHOD) which will help us register a new NodeJS module and define its methods. This\nmight be confusing for some, since we can't see the function's signature it would appear as if\nvariables are just being magically created in the stack, but once the macros are being pre-processed\nthey will just turn into ordinary functions. In the example below I commented the original signature\nso you can have more clew on what's going on.JavaScript\n\nC++\n\nAs you can see when dealing with v8 explicitly is a time-consuming process which requires you to do\nlots of extra-work. With that said, keep in mind that only a small portion of your code is going to\ninteract with the engine since the core logic should be written using native C++ and other\nthird-party libraries. You always need to find the right balance. Always make sure that your add-on\ndoesn't require too much data to be passed otherwise the conversion process is gonna be hard and\ninefficient, and think twice before you choose this approach for the sake of simplicity. Overall the\nestimated optimization should be around 150% and up, depends on the task, first check your\nJavaScript code snippet, check for unnecessary logic and optimize it, and if you're really sure that\nit is fully optimized, and you're still striving for more performance, only then move to C++.So far I went through the very basics which will help you create this bridge between the two\nplatforms. The v8 lacks of detailed documentation, tutorials and examples.\nNan however is a bit more documented IMHO, so when I approach the\nAPI documentation I would start from there, and if I didn't find anything useful I would look at\nv8's latest API docs. It's not a hard material to learn but it's\ndifferent, so it might be a bit challenging for some, but remember, practice practice practice.Speaking of practice, let's move on to the next step where we going to implement our first add-on\nfor distance calculation between two points.","creating-the-add-on#Creating the Add-On":"In this step we will base our development process on the TDD methodology, so you will have a chance\nto look at the final target API that we desire. We will start by writing a test file:","add-test-file#Add Test File":"Added .npmignore\n\nAdded test.js\n\nAnd the following NPM script should execute it:","add-npm-test-script#Add npm Test Script":"Changed package.json\n\nLike I said in the introduction, it's a simple module which can calculate the distance between 2\ngiven points. calculate.sync can do it synchronously and calculate.async can do it\nasynchronously. Now that you got the idea we will start configuring our add-on.The first thing you'll need to do is to make sure that you have node-gyp installed:\n\nnode-gyp is also dependent on many other packages, so before you go any further please take a look\nat the official installation instructions in their\nREADME.md file.Assuming that you have installed everything properly, we will now need to create a binding.gyp\nfile:","create-bindinggyp-file#Create binding.gyp File":"Added binding.gyp\n\nGYP stands for 'Generate Your Project' and was created by the Chromium team as a configuration file\nfor building native projects. The configuration show above should be a good template for any future\nadd-on you're looking to develop. Let's take a deeper look at it:\ntarget_name - Specifies the output dir of our add-on, in which case it should be\nbuild/Release/distance\nsources - Should include all the cpp files that are associated with you add-on.\ninclude_dirs - Additional dirs that should be included when building the add-on. If you'll run\nthe given script in the terminal you'll get the node-module path for Nan, a library which we're\ninterested in during the build process.\n\nMore information about GYP configuration can be found\nhere.Be sure to also add the specified flag to the package.json which basically says 'Hey, I have a GYP\nfile which should be taken into consideration as well':","create-bindinggyp-file-1#Create binding.gyp File":"Changed package.json\n\nNow we will add the following NPM scripts so whenever we run npm run build our project will be\nbuilt:","add-npm-build-scripts#Add npm Build Scripts":"Changed .gitignore\n\nChanged package.json\n\nThe only thing left to do before jumping into implementation would be installing Nan:\n\nThe basis for build process is set. We will create the entry file for our add-on:","create-add-on-entry-file#Create Add-On Entry File":"Added src/distance.cc\n\nEvery add-on should start with these two macro calls. They are both compiled into a piece of code\nwhich will register our module with ease. The NODE_MODULE macro template accepts the name of the\ntarget as the first argument (That one we set as target_name in the GYP file, remember?) and the\ninitialization method for our module. The NAN_MODULE_INITgenerates a function with the given name.\nIt accepts target as the first argument which is equivalent to Node.js' exports. Now we will\ncreate our first method stub for a synchronous distance calculation:","create-calculatesync-method-stub#Create CalculateSync Method Stub":"Changed src/distance.cc\n\nWe exported the CalculateSync by using the NAN_EXPORT macro, and we used NAN_METHOD to define\na new node-valid function. It accepts info as the first argument, and it is the same as\nJavaScript's arguments vector. We already know which arguments this function should accept, that's\nwhy I followed TDD methodology from the first place:","destructure-arguments-vector#Destructure Arguments Vector":"Changed src/distance.cc\n\nWe use the To() function to convert the first argument into the desired type, and then we call the\nmethod ToLocalChecked(). This method is simply going to convert the result into v8's Local, unless\nthe argument is undefined, in which case an error is going to be thrown. I like to prefix JS object\nwith a js_ so I know with what kind variable I'm dealing with. We should have two points\ncontaining x and y fields. Let's try to extract them out of the arguments vector and convert\nthem into native C++ structures:","convert-js-objects-to-native-c-structures#Convert JS Objects to Native C++ Structures":"Changed src/distance.cc\n\nThen again we convert the To() function to convert the result into the desired data-type, only\nthis time it's a primitive, so we use FromJust() instead of ToLocalChecked(). Note that v8 only\nuses double precision rather than a floating point. We can fetch properties from a given JS object\nwith ease using the Get() method. Pay attention to use the -> rather than a period because\nremember, a Local is actually a pointer! It is not the actual object.Now all is left to do is defining the return value. Keep in mind that the value should be returned\nthrough v8's current scope, not natively, so using the return keyword would be useless. The return\nvalue can actually be defined through the provided info argument, like this:","add-return-value-to-calculatesync-method#Add Return Value to CalculateSync Method":"Changed src/distance.cc\n\nAnd of-course it requires us to add the core distance calculation method:","add-core-distance-calculation-method#Add Core Distance Calculation Method":"Changed src/distance.cc\n\n\n\nThis is it for the synchronous calculation. Now we will add an async version of it. We will start by\ncreating a method with everything we learned so far until the point where we have to return the\nresult:","create-calculateasync-method-with-basic-deconstructuring#Create CalculateAsync Method with Basic Deconstructuring":"Changed src/distance.cc\n\nHere's the different part. We don't wanna simply return the value, we want to make the calculations\nin parallel with the event loop, and once we're finished we will interact with it once again. In our\nmodel there are two threads. The first thread is the event loop thread, and the second thread will\nbe a worker thread managed by Nan, the library supports asynchronous I/O in NodeJS. Let's start\nimplementing and I will give some more explanations as we go further:","queue-distance-worker#Queue Distance Worker":"Changed src/distance.cc\n\n\n\n\n\nHere we fetch the third argument which is the callback. We wrap it with Nan's Callback, which will\nmake sure it is not garbage collected once the scope is being deleted, we want it to keep living\nuntil it's not relevant. At the bottom of the method, instead of returning a value explicitly, we\nqueue our DistanceWorker into the workers queue. On that note, let's implement the DistanceWorker:","create-distanceworker-with-a-constructor-and-a-deconstructor#Create DistanceWorker with a Constructor and a Deconstructor":"Changed src/distance.cc\n\nAsyncWorker is an abstract class that you can subclass to have much of the annoying asynchronous\nqueuing and handling taken care of for you. It can even store arbitrary v8 objects for you and have\nthem persist while the asynchronous work is in progress. The execute() method is being executed\ninside the worker-thread. It is not safe to access V8, or V8 data structures there, so everything we\nneed for input and output should go on 'this'. The HandleOKCallback() method is executed when the\nasync work is complete. This function will be run inside the main event loop, so it is safe to use\nv8 again. Let's implement the core distance calculation on the worker thread:","execute-distance-calculation#Execute Distance Calculation":"Changed src/distance.cc\n\n\n\nAnd handle a successful invocation once the calculation is finished:","handle-successful-invokation#Handle Successful Invokation":"Changed src/distance.cc\n\n\n\nNormally, when defining a NodeJS method (NAN_METHOD macro) a scope will be created for us\nautomatically. In this function's context there is no scope exist, so we will have to create it\nusing the HandleScope deceleration (The current scope is stored globally so even though we don't\nuse it explicitly, v8 and Nan know what to do). We also created an arguments vector as the return\nvalue, following Node.js' conventions, the first argument would be the error and the second argument\nwould be the result.This is it! Finally, we will transform the add-on into a nicer looking node-module:","transform-add-on-into-a-nicer-looking-node-module#Transform Add-On into a Nicer Looking Node Module":"Added index.js\n\nAnd now, let's run our small test to see that it works, using the following command:\n\nIf everything went well, you should have the following messages printed to the terminal:","whats-next#What's Next?":"You've just learned the very basics of how to use C++ within NodeJS. There's a lot more to learn\nwhen it comes to building an add-on, and I'm not just talking about learning v8 and Nan's API. Think\nabout the possibilities, the C++ community have been developed for years and there are so much great\nlibraries out there that are not necessarily relevant to NodeJS due to its efficiency, like\nBoost, OpenCV, CGAL and many more.\nCheck out the full project of this tutorial:\nhttps://github.com/DAB0mB/node-distance-addon\nCheck out this awesome framework for creating tutorials by Urigo, which helped me to make this\nnicely structured tutorial: https://github.com/Urigo/tortilla"}},"/blog/git-rebase-not-interactive":{"title":"git rebase (not) --interactive","data":{"":"tl;dr: How to build a Node.JS script to re-write history. pre-requisites: Familiarity with\ngit rebase --interactive.Once upon a time, there was a\nWhatsapp clone tutorial was born.\nSince then, it has been through different incantations, but they all shared a common principle — the\ntutorial used git as a version control.What's special about this tutorial is its commits' history — every commit represents a step in the\ntutorial; this way it's very easy to navigate through it and reference a specific part of it.For the end user it was all cakes and ale, but maintenance was hell. To put things simple, imagine\nyou had the following git-log:\n\nNow let's say that you would like to remove step 2. The only solution for that would be using a\ngit-rebase --interactive starting step 2 and save the following file:\n\nThis means that the editor process would have to be opened and closed 98 times (100 - 3 included),\neach time it does so we would manually have to change step n to step (n + 1). Do you understand now\nwhy it was a maintenance hell? I'll save the explanation for myself.The obvious question is — what if a script could do that for me? Followed by — how can I implement\nsuch a script?Following that, I have wandered across git's documentation and Stack Overflow and have found an\nanswer. Here's the method which starts the editing process written in git-rebase--interactive.sh,\na file in git's implementation:\n\nAs you can see (or not), git looks for the editor's file path in a global var named\nGIT_SEQUENCE_EDITOR and executes it with all the given arguments. Without getting into more of the\nimplementation, knowing nano and vim which are the most commonly used git-editors, the first\nargument that their process accepts the edited file's path, which makes total sense.BUT! Why does the GIT_SEQUENCE_EDITOR environment variable has to reference an actual text editor?\nWhat if we set that to reference Node.js' executable? Aha! JACKPOT!Now, hypothetically instead of opening nano or vim and editing the file manually we can run\nwhatever manipulation we want on the file using a script and then once the process exists with no\nerrors (code 0) git will just proceed with the rebase as usual.Using this principle, here's a cool script that will remove a range of commits from the middle of\nthe commits-stack:\n\nUsing the code snippet above we can take an initial step towards solving the problem presented at\nthe beginning of this article by simply running $ git-remove.js where anchor represents a git\nobject and amount represents the amount of commits that we would like to remove.Sure, we still need to figure out which step we would like to remove by its index, and we need to\ntake care of automatic rewording, but at least now you have the idea behind such method where you\ncan solve problems like these as well as far more complex ones, with a little of creativity."}},"/blog/fetch-for-servers":{"title":"JavaScript runs everywhere, so should your servers - here is how","data":{"":"","tldr#TL;DR":"We made GraphQL Yoga 2.0 platform-agnostic, so it is able to run anywhere JavaScript can run\n(Cloudflare Workers, Deno, Next.js. AWS Lambdas etc.) thanks to the new Fetch API standard\nWe've created Ponyfills so it will work the same on older versions of Node that don't\nhave Fetch API elements globally available\nWe've made a new general library out of it so that\nany other framework or app could achieve the same\nLet's help other frameworks in the ecosystem to migrate to this new library and standard\n\nAt the beginning of the year, we launched GraphQL Yoga 2.0 - a\nserver framework for GraphQL APIs.While planning version 2.0 of Yoga, we were thinking about all the things that changed in the\necosystem and what developers using JavaScript expect from their server frameworks now and in\nthe future.One of the most powerful trend in the JS ecosystem was the proliferation of new environments and\nplatforms that can run JS (Lambdas, Cloudflare Workers, Deno, Bun etc.). So we set up to build a\nsingle GraphQL server framework that could run on any of these platforms.What we’ve found in the process was fascinating, and we believe would change how any JS HTTP\nframeworks are being built, without any relation to GraphQLWhile Node.js is the most popular environment, multiple platforms can run JavaScript, usually,\nhaving their own way of creating servers, and using different APIs.On the other hand, the JavaScript client-side has mostly migrated over the years to a common set of\nstandards (fetch), independently of the underlying platform.This is where we realized that WHATWG Fetch API that uses\nRequest,\nResponse, and ReadableStream could\nalso be used on the server side to provide a unified API to run JavaScript HTTP servers everywhere.","why-fetch-api-standard#Why Fetch API Standard?":"When you send a request from the client, fetch(...requestArgs) uses\nRequest object under the hood that\ncontains all the details (headers, method, etc.) and the data stream you need for that\ncommunication. Then you take the\nResponse object that contains the\nconnection stream, and process it as you want with .json(), .arrayBuffer(), .formData() or\njust access the stream itself by .body() as ReadableStreamOn the server side, you can take\nRequest object and process it with the\nsame methods without dealing with the internals of your platform.Streaming responses like SSE uses ReadableStream, and for Multipart requests (e.g. file uploads)\nuses FormData, which is exactly the same forwarded from the browser or any other client using\nFetch API.You can see how easy to handle file uploads;\n\nSee more in our code;\nhttps://github.com/dotansimha/graphql-yoga/blob/master/packages/common/src/plugins/requestParser/POSTMultipart.python#L18Streaming responses like\nServer Sent Events\nexample:\n\nSee more in our code;\nhttps://github.com/dotansimha/graphql-yoga/blob/master/packages/common/src/plugins/resultProcessor/push.python#L42","what-about-nodejs#What about Node.js?":"Even though many new platforms support the Fetch API Standard, which means we can have a single\nsolution for all, currently, in the older LTS versions of Node.js, we don’t have an implementation\nof the Fetch API built in.Furthermore, Node.js doesn't use Web standard streams and the Fetch API in its http and https\nmodules.That’s why we created the @whatwg-node/fetch package\n(previously known as cross-undici-fetch ) that fills in the gaps of different fetch\nimplementations in all the LTS Node.js versions. Under the hood, @whatwg-node/fetch utilizes\nundici if available or otherwise falls back to using node-fetch, which you are probably already\nfamiliar with.\nIn case @whatwg-node/fetch is imported in an\nenvironment that already has Fetch API built in like Cloudflare Workers, no ponyfills are added to\nyour built application bundle.","ponyfill-vs-polyfill#Ponyfill vs Polyfill":"Polyfill patches the native parts of an environment while ponyfill just exports the “patched” stuff\nwithout touching the environment’s internals. We prefer pony filling because it prevents us from\nbreaking other libraries and environmental functionalities.","is-it-possible-to-have-a-library-that-creates-a-cross-platform-server#Is It Possible to Have a Library That Creates a Cross-Platform Server?":"When rebuilding GraphQL Yoga from scratch, cross-platform support was one of the most important\nfeatures we wanted to implement. We wanted to create a GraphQL server library that can be integrated\nwith different Node.js server frameworks and other JS environments like CF Workers and Deno with a\nfew additional lines of code.After a few iterations, it was clear to us that this is certainly possible and finally shipped this\nas part of GraphQL Yoga v2.GraphQL Yoga instance itself can be used directly as a request listener that you pass to Express’s\napp.use, Node’s native http.createServer, Next.js functions and other non-Node.js environments;\nwe just pass GraphQL Yoga as an event listener for CF Workers’\nself.addEventListener('fetch', yoga).As we already mentioned in the “Why Fetch API?” part, the server library itself doesn't need to care\nabout the platform’s connection-specific details like Node’s IncomingMessage and ServerResponse\nor Next.js’s NextApi.Request objects. You are now able to focus on your server implementation\ndetails by consuming a “universal standard”\nRequest and returning “another\nstandard” ResponseAs we realized how well this works out for our users, we decided that we need to bring this to the\nnext level and extract that logic into a standalone library called\n@whatwg-node/server .You simply provide your request handler that has a single\nRequest parameter and expects you to\nreturn a Response instance. The\ngenerated request handler instance can be integrated with regular Node HTTP servers, Fastify, Koa,\nDeno, CF Workers, Next.js, etc with a few lines of code.","how-does-it-look-in-real-life-usage-today#How Does It Look in Real-Life Usage Today?":"You can check the GraphQL Yoga repository to see how we use this library;https://github.com/dotansimha/graphql-yoga/blob/no-more-node/packages/graphql-yoga/src/server.python#L628And the simplicity of the integrations in our examples;https://github.com/dotansimha/graphql-yoga/tree/no-more-node/examplesFinally, how small the code is when we want to process the request and the response objects;https://github.com/dotansimha/graphql-yoga/tree/no-more-node/packages/graphql-yoga/src/plugins\nThere is literally nothing platform-specific in GraphQL Yoga, and this allows us to focus on\ncreating a good GraphQL Server implementation for the entire GraphQL JS ecosystem.","nodejs-server-frameworks-routers--middlewares#Node.js Server Frameworks, Routers & Middlewares":"Node.js solved issues years before the web standards could. However, we think that many server-side\nideas inspired by Node.js can now easily be managed with JavaScript with Fetch, Web Streams and\nother web standards in the JavaScript ecosystem.There are many mature libraries such as Fastify, Koa, Express, and Hapi that are implemented only\nfor Node.js without using the Fetch API Standard. The experience with those libraries in the current\nera of Node.js taught us a lot about how the server can be designed but maybe it is time to reduce\nthe environment-specific APIs in the JS ecosystem.The major reason for using a server framework is usually “Routing” then “Middlewares” so the\nquestion is “Why cannot we just have that with Fetch API?”You can basically achieve routing like below, however it looks a bit unsafe.\n\nThere is another library called itty-router which can be used for Routing with Fetch API. You can\nsee how simple it is to achieve “Routing” in a platform-independent way.","what-nodejs-frameworks-are-you-using-today#What Node.js Frameworks Are You Using Today?":"Maybe it is worthwhile to open a new issue on their repo and see if we could all help them to become\nplatform-agnostic, while still supporting older versions of Node, thanks to this new library.Please try it out and give us feedback on the repo!"}},"/blog/graphql-as-a-best-practice-for-modern-angular-apps":{"title":"GraphQL as a best practice for modern Angular apps?","data":{"":"In this post, I'll make the case for why Angular needs a best practice for communicating with the\nserver, and why GraphQL should be that best practice.","best-practices#Best Practices":"The Angular community is establishing best practices so that we all can benefit from making our apps\nmore performant, easier to maintain, and more modern.Some current best practices include composing everything into\nComponents, using one-way data binding, lazy loading,\nhaving an immutable global state management (Redux & ng-rx), and more…That is all great, and means that if we will follow those best practices our apps will behave better\nand will look more modern……until we get to data fetching from the server.","data-fetching#Data Fetching":"Today, whether we are developing in a large company, consulting, or writing our own app, when we\nfetch data from the server we are often left with old practices that don't address the needs of a\nmodern app.Also, we are kind of powerless and unable to decide how the data will be supplied to our apps by the\nserver, even though the way we fetch the data to our app is at least as meaningful to the way our\napp behaves as how we present it.We should come up with best practices for data fetching that is more in line with the modern way\nwe write our apps. These should take into consideration the following needs: data documentation,\nnetwork latency, server side rendering and faster initial loading, real time communication patterns,\nlatency compensation, and optimistic UI.","rest#REST":"REST is the current protocol we go around when we're talking about app data fetching. REST has its\nbenefits, but it was evolved in a time when the web was very different from today, when everything\nwas about static HTML and forms and not about apps.Here are the areas where REST is currently lacking:\nself documentation — when you send a request to a REST endpoint, there is nothing in the\nprotocol that tells you what you are going to get (and not everyone has the resources to create a\nnice, updated documentation like Twitter)\nREST doesn't support real time data fetching\ntough choices when designing your REST endpoint, which I'll elaborate on below\n\nOver-fetching — When one endpoint serves all the data, each Component calls it again and again.\nThis means it serves more fields than the component needed and we call it many times, creating\nmore load on the serverUnder-fetching — When many endpoints serve multiple resources and fields. This creates many\nround trips for one Component as well as complex joins on the client.","rethinking-data-fetching#Rethinking Data Fetching":"So it looks like we need to rethink data fetching, just like we rethought web apps.Luckily, Facebook ran into the same problem in 2012 when they needed to rethink the way they fetch\ndata as they wrote their mobile apps on top of their existing stack.They developed a solution, and open sourced it as GraphQL.","graphql#GraphQL":"GraphQL is the new data communication protocol for modern apps.The server communicates what data it can provide and the client specifies what data it needs in a\nsimple, graph-like structure, in one round trip, no matter how deep, how complex, or how\nmany resources the data contains.\n\nThis means: one request to get exactly the information the app needs, when it needs it. No\nover-fetching and under-fetching.With that, each component needs to specify its data dependencies and a client library will merge\nthem into one request. There's no need for a shared service with prepared fetching functions.GraphQL is also not a storage engine! You can connect it to an existing REST endpoint or python and\nNoSql databases.","shared-best-practices-between-frameworks#Shared Best Practices between Frameworks":"For all the reasons above, GraphQL is already the best practice for fetching data with React. Also,\nall the Facebook apps and clients use GraphQL.If the Angular community embraces GraphQL as a best practice, it would open the door to sharing more\ntools and knowledge with the React community.To start learning about GraphQL, take a look at these sources:\nWhy GraphQL is the future\nThe basics of GraphQL in 5 minutes\nReplacing Discourse REST API with GraphQL\nAngular-Apollo Docs and\nGitHub Repo\nBuilding faster modern apps with Angular and GraphQL"}},"/blog/graphql-authentication-with-envelop-and-auth0":{"title":"GraphQL Authentication with Envelop and Auth0","data":{"":"Authentication in the process of identifying who is trying to access our API. Building our own\nsolution can be hard and cause severe security issue if done wrong. In recent years third-party\nauthentication providers became quite popular. One of those is Auth0, which comes with an\nexceptional free plan allowing up to 7.000 active users and unlimited logins, making it one of the\nbest available solutions for getting started.In this guide we will go through all the steps required for integrating authentication into an\nexisting envelop setup using the @envelop/auth0 package.","prerequisites#Prerequisites":"Ideally, you already have your basic envelop setup with your http framework of choice. This guide we\nwill be based on the\ngraphql-helix fastify example,\nbut the code can be easily transferred to any other example as listed on our\nIntegrations and Examples documentation. In case you are\nhitting any roadblocks feel free to reach out to us via the chat box on this page! The full code of\nthe end-result is also available in our examples\ngraphql-helix-auth0 fastify example.","installing-dependencies#Installing Dependencies":"We start by installing the package into our envelop setup with your favorite Package manager.","adding-the-auth0-plugin-to-the-envelop-setup#Adding the Auth0 Plugin to the Envelop Setup":"Let's break down the code. There are several configuration options we need to pass to the plugin.domain The domain of the Auth0 server we need to communicate with for authenticating a user.\nWe will fill this out in the next step.audience The audience is the identifier of the API and is forwarded to Auth0 in order to\nspecify for which API we are trying to authenticate our user for. E.g. if our API is hosted on\nhttp://localhost:3000/graphql, we would pass that value. We will fill this out in the next step.extendContextField Once a user got successfully authenticated the authentication information\nis added on the context object under this field. In our resolvers we can then access the\nauthentication information via context.auth?.sub.","setting-up-the-auth0-api#Setting up the Auth0 API":"In order to properly configure the useAuth0 plugin we need the domain and audience values. We\nwill retrieve them by setting and configuring Auth0 from scratch!If didn't already sign up for Auth0, you should do it now on\nAuth0 Sign Up. Since you can sign up with your GitHub or Google Account\nit should be super fast!After logging in navigate to the Auth0 dashboard and from\nthere to the APIs page, where we will click the Create API button.\n\nChoose any name for the API, we are going with Envelop Demo for this example. The Identifier\nfield should be set to the URL of our GraphQL API. We are hosting our API on localhost and set it to\nthe host and port on which our fastify helix server is served, which is\nhttp://localhost:3000/graphql. For production, you should instead set it to the URL of the\nproduction server.\n\nWe can ignore the Signing Algorithm option and go with the pre-set value. Once everything is filled\nout properly we can click the Create button.Now we already have one of the missing config options we needed audience , which is equal to the\nURL we just entered http://localhost:3000/graphql.\n\nThe domain value is a bit hidden, but we can find it on the detail page of the API we just\ncreated, on the Test tab.\n\nIt will vary depending on your account name and region, but in general it follows this pattern\n\nThis is our domain configuration value.Let's quickly add this information to our envelop setup.\n\nWe now have all the information needed for configuring the envelop plugin. However, we did not yet\nsetup an application that is required for users to authenticate in the browser.But before doing so, let's verify that the plugin is doing what it should do.","expose-authentication-information-via-graphql-schema#Expose Authentication Information via GraphQL Schema":"Before we start our server we should add some types and fields to our schema in order to query for\nthe authentication information. The complete code should look like this:\n\nThen we can start our server. The helix fastify server can be started via yarn start.\n\nNext, we are going to execute a query on the GraphiQL instance exposed on\nhttp:localhost:3000/graphql.\n\n\n\nAs expected the value of the authInfo field is null, as we are not passing any authentication\nheaders along with our request.","generating-an-auth0-access-token#Generating an Auth0 Access Token":"In order to retrieve an access token, we first need to set up an Auth0 application and an\nauthentication route. For the sake of this guide and in order to reduce complexity we will simply\nadd an route to our fastify http server that renders some HTML with a <script> tag that invokes\nthe Auth0 JavaScript SDK (referenced via a CDN) and then appends the authentication token to the\ndocument body. It should still give you a feeling how you can integrate the Auth0 SDK with your\nfavorite Frontend Framework. If you are using Next.js you should check out\nnextjs-auth0.Let's go back into the Auth0 interface on the Applications page.\n\nPress the Create application button, enter a name of your choice (e.g.\nEnvelop Example Single Page Web) and select the Single Page Web Applications application type.\nConfirm by pressing the Create button.\n\nWe will be redirected to the Application detail page.The first important information we need from there is the Application Client ID. We need that\nstring for configuring the Auth0 SDKOn that page we also need to switch to the Settings tab as we will have to adjust our application\nURL settings. Our application is hosted on http://localhost:3000. We will have to set the\nAllowed Callback URLs, Allowed Logout URLs and Allowed Web Origins setting to that value\n(http://localhost:3000).Don't forget to save the changes with the Save Changes button at the end of the page.Next we add the new route in our fastify setup:\n\nAs mentioned before it is not that fancy. After restarting the server and opening\nhttp://localhost:3000/ URL we should see a blank page and an Auth0 LogIn pop-up.\n\nAfter a successful login the authentication token is added to the blank page.\n\nLet's copy that one and move back to our GraphiQL instance.","sending-an-authenticated-request#Sending an Authenticated Request":"In the Request Headers tab we can specify our Authorization header in the following format:\n\nThen after re-executing the operation we see that the result now contains our authentication\ninformation!","next-steps#Next Steps":"Congratulations on successfully implementing authentication for your GraphQL API with Envelop and\nAuth0!The full code of this guide can be found in our\nEnvelop examples.More information about advanced configuration options can be found on the\nuseAuth0 PluginHub page.In the GraphQL schema of this guide we only re-expose the auth0 authentication information. For a\ntrue registration flow the user information should be persisted via a register mutation or\nsimilar, so additional information such as first and last name is stored within a database.A full user object could be loaded when building the context via the\nuseExtendContext plugin.\n\nLearn more about all the other features you can easily add to your GraphQL setup over on the\nEnvelop Docs.We are continuously adding new plugins that allow solving hard problems with ease!Another new plugin that is being cooked up in the lab is the operation complexity plugin, which\nallows (rate-)limiting of operations sent to your server based on a score calculated from the\nselection set. If you are building a public GraphQL API you don't want to miss out on this! Help us\nto shape the plugin by dropping feedback over the\nDraft PR for the Operation Complexity Plugin or\ncontact us via the Chat below. We are curious about your feedback und use-cases!"}},"/500":{"title":"500 - Internal Server Error","data":{"":""}},"/blog/graphql-code-generator-011":{"title":"GraphQL Code Generator v0.11","data":{"":"This blog post refers to an outdated version, please check http://graphql-code-generator.com/ for\nthe latest docs!","generate-react-and-angular-apollo-components-resolver-signatures-and-much-more#Generate React and Angular Apollo Components, Resolver Signatures and Much More!":"We are very excited to announce a new release for graphql-code-generator!If you haven't checkout graphql-code-generator before, please\ncheck out the following introductory blog posts:\nGraphQL Code-Generator\nWhat's new in GraphQL Code Generator 0.9.0\n\nv0.11 holds a lot of improvements, new features and a couple of new templates, mostly in\nTypescript — for frontend and backend!Here is the gist of it:\nNew React and Angular templates to greatly simplify the usage of Apollo Client and Typescript\nand auto-generate a lot of the current boilerplate\nGenerate types for resolvers\nMajor overall to support generation of custom scalar types\nSupport for GraphQL-Yoga with graphql-import\nWatch mode\nMajor refactoring and improvements to the Typescript Mongo template\n\nBut the best part of all — on this release we saw a major increase in contributions and\ncontributors! This is a strong sign for the growth of the ecosystem around graphql-code-generator.\nThank you so much everyone, we are humbled by your help. keep it coming!\nEven though we haven't decided to declare 1.0 yet, we use this library on each one of our projects\nand our clients projects.Each PR merged creates an alpha release to npm which we then test out and upgrade all of those\napplications.Only then we release a full npm version, so you can be assured that by time of the release, it has\nalready been tested by major Enterprise applications who deploy daily into production, on top of all\nthe unit tests on the project!So all the new features that are being mention on this post, are already being used by us\nextensively.OK, let's start with the new features for the client side Typescript users:","react-templates#React Templates":"react-apollo recently introduced\na new default API with\nQuery, Mutation and Subscription components.Whether you use the new API or prefer HOC and you use Typescript, there is no need to write those\nwrapper components again and again!With the new\nTypeScript React Apollo Template,\nyou don't need to anymore!All you need to do is to write your GraphQL Query, Mutation or Subscription, and the codegen will\ngenerate fully typed react-apollo components and HOC for each one.That makes using React Apollo with Typescript so much simpler!You can read more about it in the following blog post:\n\nThank you Arda TANRIKULU for that amazing contribution!","angular-templates#Angular Templates":"But why just React? Angular should get the same benefits!Apollo-angular also recently added added the\nQuery, Mutation and Subscription services.But why writing them by yourself?With the new\nTypeScript Angular Apollo Template,\nall you need to do is to write your GraphQL Query, Mutation or Subscription, and the codegen will\ngenerate a fully functioning, fully typed Angular service for each of those!As this was a contribution by Kamil Kisiela, the creator and\nmaintainer of the apollo-angular library, we believe we can endorse it from now on as the best way\nof using apollo-angular!You can read more about it in the following blog post:\n\nThank you very much Kamil Kisiela, the creator and maintainer of\napollo-angular for that amazing contribution,\nfrom the apollo-angular and the graphql-code-generator side!Moving on to the new backend features.","generate-types-for-resolvers#Generate Types for Resolvers":"The TypeScript template is now able to generate Typescript types not only for a schema and documents\nbut also for GraphQL Resolvers. And It's enabled by default!We think this was another missing piece of making your code even more strongly typed, from end to\nend.The template now generates a Typescript type for each GraphQL type with resolvers for all of its\nfields but it is also possible to extract a type of a single field.\n\nAs you can see the usage is straightforward, but we recommend to explore the source code of a\ngenerated file.","custom-scalars-improvements#Custom Scalars Improvements":"Prior to this version, scalars were declared with any which means we didn't take enough advantage\nof TypeScript here. This was an another opportunity to strengthen up your code. We're happy to tell\nyou it's now possible to customize a scalar and provide a type instead of having it as any.We also introduced a new option called prepend to add a code at the beginning of a generated\nfile, it completes the custom scalars feature.","unified-naming-strategy#Unified Naming Strategy":"camelCase, PascalCase, snake_case, lowercase, UPPERCASE, CONSTANT_CASE, there's a lot of ways for\npeople to name their types in GraphQL schema. It was a wild west, until now.We decided to unify the naming strategy in codegen and pick just one. We chose PascalCase. And now,\neverything generated by codegen follows that rule.Maybe at some point in the future, graphql-code-generator will allow to set your own naming\nstrategy. Contributions are welcome so don't feel afraid, we will help you!Keep on mind that it's a breaking change, TypeScript might warn about non-existing type, if so then\nchange it to be PascalCased.","watch-mode#Watch-Mode":"Now the GraphQL Code Generator detects changes in your schema and type definitions, and generates\ntypings automatically after you edit these files.The only thing you need to do is add -w parameter to the command line.Thank you Arda TANRIKULU and\nFredyC for that great contribution!","support-for-graphql-yoga-with-graphql-import#Support for GraphQL-Yoga with graphql-import":"Thanks to\nDavid Yahalomi's\ngreat contribution, GraphQL Code Generator now understands the graphql-import syntax being used by\nGraphQL Yoga.","mongodb-schema-template#MongoDB Schema Template":"We are also working on improving\nthe MongoDB Typescript schema template.We are using this template in many of our apps in production, it saves us a lot of boilerplate and\npotential bugs, and it's also easier to maintain and keep track of the MongoDB schema objects.Basically, this template lets you generate TypeScript typings for the shape of your MongoDB objects\nbased on your GraphQL schema.For example, using the following schema:\n\nYou will get a generated TypeScript interface:\n\nThen, you can use it with MongoDB driver for NodeJS:\n\nNow your MongoDB collection is typed, and it's easier to find bugs during development.We understand that a lot of edge cases might occur because of the differences between GraphQL schema\nand the lack of schema in MongoDB, so we added @map directive that lets you do custom mapping of\nfields:\n\nWill output:\n\nThere is also the need to handle the difference between embedded types and linked types, so you can\nuse @entity(embbeded: true) and @embbeded to declare link and embedded entities:\n\nWill output:\n\nAnother issue is to add fields that are relevant only for the MongoDB schema, and not relevant to\nyour GraphQL schema (such as security token and login hashes), so you can define it in your GraphQL\nSchema:\n\nWe also addressed GraphQL Interface, and now you can use @abstractEntity to override your\ninterfaces, and if you are using GraphQL Unions, you can add a custom @discriminatorField to your\nunion, and it will add the field to your MongoDB schema.We are also thinking about adding more templates for entities schemas in the future, such as\nJSON schema.\nWe are planning to release the new version of that template next week and write a dedicated blog\npost on it with more details.\nAlso, that template can be a great start for others to add the same generated features to other data\nsources like python and NoSQL databases, DB ORMs and more!Other honorable mentions on this release:\nSupport for AWS AppSync\nGenerate introspection file\nHuge performance improvements\nthanks to prevostc\nAdded implementingTypes for interfaces\n\nWatch the complete breakdown of the releases and features here:\n(https://github.com/dotansimha/graphql-code-generator/releases)[https://github.com/dotansimha/graphql-code-generator/releases]As usual, we keep all of our dependencies up to date with each release thanks to renovate. This\nrelease updates everything to latest as usual, including TypeScript 3.0.We believe it is a good open source practice and helps not just us and our users but it also helps\nour open source dependencies authors to get early feedback on any issue that might happen.\nFriends help friends test early! ;)\nWe encourage that practice on for any open source library and any application!","what-other-ideas-do-you-have-for-generating-things#What Other Ideas Do You Have for Generating Things?":"If you have any ideas or custom needs, that's exactly where the graphql-code-generator shines, let\nus know about your needs, and we would be happy to support you!This version wouldn't be possible without the great help of sgoll,\nDavid Yahalomi,\nArda TANRIKULU,\nKamil Kisiela, degroote22,\njycouet, FredyC,\nprevostc, arvind-chandrashekar-ck,\nCactucs.Also want to contribute? here are some ideas for future contributions (but any ideas would be\nwelcomed!), we would love to support and help any new contributor who want to give it a try!\nSupport for graphql-config\nAdditional examples of generator templates written in JS\nFlow template\n\nDon't forget — if you created your own template and think it could benefit others,\nlink it on our readme here.Star and follow us on GitHub and Twitter, we have a lot more coming soon!"}},"/blog/graphql-authz":{"title":"GraphQL AuthZ - GraphQL Authorization layer","data":{"":"Today we are excited to introduce GraphQL AuthZ - a new open-source library for adding authorization\nlayers in different GraphQL architectures.","intro#Intro":"GraphQL AuthZ is a flexible modern way of adding an authorization layer on top of your existing\nGraphQL microservices or monolith backend systems.It plays well with both code-first and schema-first (SDL) development, supports different ways of\nattaching authorization rules, has zero dependencies in the core package (aside from a peer\ndependency on graphql-js), and keeps the schema clean from any authorization logic!Also, GraphQL AuthZ has integration examples for all major GraphQL frameworks and libraries. Let's\ndig a little deeper and break down the core features and how they can help you improve your GraphQL\ndeveloper experience.","how-does-it-work#How Does It Work?":"GraphQL AuthZ wraps the graphql.js execution phase and runs logic for enforcing defined\nauthorization rules before and after this phase. The key function from graphql-js that is\nresponsible for running the execution logic is named execute.This simplified pseudo-code describes how the GraphQL AuthZ hooks into the process by wrapping the\nexecute function.\n\nBy wrapping existing functionality we gain the following key benefits.\nCompatibility with modern GraphQL technologies providing ways to wrap the graphql.js execute\nfunction. Here are a few working examples for\nEnvelop,\nGraphQL Helix,\nApollo Server,\nand\nexpress-graphql.\nThe executable GraphQL schema does not contain any authorization logic allowing more flexible\nre-usage for other use-cases\nAuthorization rules can be added on top of an existing remote GraphQL schema. GraphQL AuthZ can be\nadded as a layer on your GraphQL gateway that composes smaller subgraphs into one big graph.\nSeparation of the authorization logic into two phases\nThe pre-execution phase for static authorization rules based on the context and incoming\noperation\nThe post-execution phase for flexible authorization rules based on the execution result","failing-early-in-the-pre-execution-phase#Failing Early in the Pre-Execution Phase":"With GraphQL AuthZ it's possible to execute authorization logic before any of the resolvers have\nbeen executed. This empowers you to fail the request in the early stage, send back an error and\nreduce server workload.This technique works the best for authorization logic that is not dependent on remote data sources.\nFor example, checking if the user is authenticated or has some certain role or permission.\n\nHowever, if you need the flexibility for fetching data from a remote source such as a database\nbefore you can determine whether an operation should be executed, you still have the power to\nleverage those data sources with async code.This technique is a perfect fit for mutation fields, as you want to avoid executing the mutation\noperation if the user has insufficient permissions e.g. he does not own a specific resource.","using-the-graphql-schema-as-a-data-source#Using the GraphQL Schema as a Data Source":"By pursuing the GraphQL AuthZ approach your executable schema does not contain any authorization\nlogic. This simplifies using the executable schema as a data source. For example, instead of calling\na remote database using an interface attached to our context object directly, the graphql function\nfrom graphql.js package could be called, with the executable schema as an argument along with\ngraphql operation. By doing this, the authorization layer is not dependent on the underlying\ndatabase(s), its architecture, and ORM(s). It is dependent only on the GraphQL schema which is a\ndependency of the GraphQL authorization layer by design.\n\nAuthorization logic could require any kind of data fetched from different databases or\n(micro)services. Some data points could even be resolved by third-party microservices or APIs that\nare not part of the composed graph.By using the GraphQL schema as the data source, authorization rules don't need to be aware of\ncomplex implementation details or directly connect to different databases or microservices.This makes GraphQL AuthZ extremely powerful, especially for subgraphs in a microservice architecture\nwith centralized gateway-level authorization.All the subschemas could live without any authorization logic and a federated or stitched gateway\ncan leverage GraphQL AuthZ for actually applying global authorization logic for the whole graph\nwhile leveraging the graph for fetching the data required for doing so, without having to be aware\nof GraphQL resolver implementation details.","reduce-remote-procedure-calls-with-post-execution-rules#Reduce Remote Procedure Calls with Post-Execution Rules":"In addition to the pre-execution rules, GraphQL AuthZ also allows you to write post-execution rules.Fetching remote data from within authorization rules is powerful but it adds overhead and requires\nadditional network roundtrips. In most cases, the data required for performing authorization logic\nis closely related to entities fetched via the GraphQL operation selection set. You can avoid this\nby performing authorization logic based on the execution result in the post-execution phase.In your post-execution rules, you can specify a selection set for fetching additional data, related\nto the rule target, that is required for running the rule.For example, if your rule is attached to some object field it could require additional information\nabout sibling fields with their relations.\n\nBy using this technique we reduce remote procedure calls to individual data sources by executing\nauthorization logic on top of GraphQL execution result that is enriched with the additional data\nspecified by the authorization rules. Since related data is often stored in the same place it can be\nfetched from a data source in one roundtrip (via the GraphQL schema) instead of performing one\nremote procedure call for the authorization and one call for the actual data populating.","microservices#Microservices":"With GraphQL AuthZ it is possible to implement a centralized gateway authorization layer as well as\nmicroservice level authorization. You can choose between storing the whole authorization schema in a\nholistic way on a stitched or federated gateway or having dedicated authorization schemas for each\nsubgraph/schema specified by your services. It is even possible to mix both approaches!\n“Shifting this configuration out of the gateway makes subschemas autonomous, and allows them to\npush their own configuration up to the gateway—enabling more sophisticated schema releases.” —\nschema stitching handbook\nThe @graphql-authz/directive package provides a GraphQL directive that can be used to annotate\ntypes and fields within your subschemas SDL and a configuration transformer that can be used on the\ngateway to convert the subschema directives into explicit authorization settings.\n\nOn top of that directives can as well be used in monolith architecture.If you are not pursuing a schema-first (SDL) development flow and are more a fan of the code-first\napproach (which does not let you specify directives without framework-specific voodoo magic), the\nauthorization schema can also be described as a plain JSON object. Allowing you to specify the rules\nthat should be executed on your object types, interfaces, and fields.","comparing-graphql-authz-with-graphql-shield#Comparing GraphQL AuthZ with GraphQL Shield":"GraphQL Shield is a great tool for creating\nauthorization layers that has vast adoption from the community. In fact, GraphQL AuthZ is highly\ninspired by GraphQL Shield! However, GraphQL Shield uses a different approach compared to GraphQL\nAuthZ for applying authorization rules.The main difference is GraphQL Shield uses field middleware by wrapping all the resolver functions\nwithin your GraphQL schema for executing authorization logic during the data-resolving phase, while\nGraphQL AuthZ wraps the entire execute logic.The benefits of the wrapping approach are described in previous paragraphs, however, there are also\nsome drawbacks. For example, with GraphQL AuthZ post-execution rules there is no ability to fail the\nrequest early because post-execution rules are executed after all resolvers are executed. GraphQL\nShield, on the other hand, can fail the request during the execution phase which happens before the\npost-execution phase but later than the pre-execution phase. On the other hand, post-execution rules\nhave the benefit of accessing the resolved value of the field they are specified on and,\nfurthermore, even the sibling fields that are specified via the rules selection set.The middleware approach of GraphQL shield is missing these possibilities because authorization logic\nis executed in the context of field resolvers and has access only to the parent object which is the\nvalue returned from the parent field resolver. At that stage, the wrapped field resolvers have not\nbeen executed yet.Another feature in GraphQL Shield is the built-in contextual caching mechanism for rules. At the\nmoment, GraphQL AuthZ has no built-in caching, but you can implement it yourself within the GraphQL\nAuthZ rules, or in the future caching could even become a built-in feature. (pull requests are more\nthan welcome)","which-approach-to-choose#Which Approach to Choose?":"Let's wrap up all the use-cases mentioned above and also give a library recommendation.\nIf you have very few places that should be covered by authorization, and you don't plan to\nincrease such places, you can just add authorization logic right inside resolvers to not\novercomplicate things.\nIf all of your authorization logic doesn't depend on the data and shouldn't perform complex\ncalculations, you can use\noperation-field-permissions\nEnvelop plugin.\nIf your authorization logic contains some calculations which are the same for many fields of your\nschema, you can use GraphQL Shield to leverage the\nbuilt-in contextual caching mechanism.\nIf your authorization logic heavily depends on the data, or you want to use schema directives to\nattach auth rules, you can use GraphQL AuthZ to\nleverage the 'GraphQL schema as a data source' pattern and post-execution rules.","conclusion#Conclusion":"GraphQL AuthZ is a new approach for applying GraphQL native authorization. We are happy that we can\nfinally share this library with the community and keen to learn about the ways it might be used\nwithin your next project! Don't hesitate to contact us for questions or to evaluate whether this\nlibrary might be a fit for your architecture.Please check out the GraphQL AuthZ repository on GitHub\nfor learning more. You can find a tutorial on how to set it up in different ways and with different\ntechnologies.The repository also contains the following, ready to run, examples:\nApollo Server (schema-first, directives)\nApollo Server (code-first, extensions)\nexpress-graphql (schema-first, directives)\nGraphQL Helix (schema-first, authSchema)\nEnvelop (schema-first, directives)\nTypeGraphQL (code-first, extensions)\nNestJS (code-first, directives)\nSchema Stitching (gateway, directives)\nApollo Federation (gateway, authSchema)"}},"/blog/graphql-code-generator":{"title":"Introducing GraphQL Code Generator","data":{"":"","tldr#TL;DR":"https://github.com/dotansimha/graphql-code-generator\nThe GraphQL codegen library can generate\nany code for any language — including type definitions, data models, query builder, resolvers,\nORM code, complete full stack platforms!! and any specific code for your needs\nI wrote the code generator based on my experience with other robust code generators (such as\nSwagger codegen).\nYou can create your own custom GraphQL codegen templates in 10 minutes, that fit exactly\nyour needs — you can even generate an entire application based on your GraphQL schema!\nTemplate-based implementation is simpler and easier to maintain, and I think that eventually\nsingle engine with multiple templates will match all use-cases (for example, writing the Flow\ntemplate took only 10 minutes)\nReal life use-cases always needs customizations (for example, Shopify wrote their own codegen\nthat they need to maintain because the other codegen tools weren't flexible enough. If they would\nuse this tool, they would just need to create a new template — which is simpler and easier to\nmaintain)\nShare templates with the community — move the community forward by having an eco-system of\ntemplates that probably match most of the use-cases, learning from the Swagger codegen community\n\n\n\nThe source code of the video examples are available here\nThis blog post refers to an outdated version, please check http://graphql-code-generator.com for\nthe latest docs!","do-more-than-just-generating#Do More than Just Generating":"About a year ago, I started writing code and apps using GraphQL.Doing that, while coming from a production and Enterprise background, I looked for the tools\navailable on the GraphQL ecosystem and compared it to the tools I used back then.There were a few code generators out there, but immediately I was missing a tool that is similar to\nthe Swagger code generator. Also, the possibilities GraphQL gives us are much greater than Swagger\nso I knew there was a big opportunity here.So I started writing the code-generator for GraphQL, and I used my years of experience with Swagger\ncode generator as inspiration.The magic behind every good code generator, is the ability to change and extend the results quickly,\nwhile maintaining a simple (yet flexible) data structure based on your GraphQL schema and documents.Code generators are also good for wrapping your data layer with a consistent code — for example, you\ncan generate a function that executes the GraphQL document through your network interface, fetches\nthe data and returns the response wrapped in a custom structure.","use-cases#Use Cases":"Typings — So yes, of course you can generate Typescript and Flow typings, Swift, Java and C#.But the thing is, that it's much easier to add or change those generators, in fast, creating the\nFlow codegen took 10 minutes!And that means that you don't need to rely on us to create the generator that you need — you can\ncreate your own custom generator in a matter of minutes and share it with the whole community!Generate your backend — From your GraphQL definitions, you can generate your backend code! You\ncan generate your resolvers, your data models, query builders, mutations, filters and more! Now\nmaybe you can understand what the GraphQL Backend as a service platforms are doing… exactly that! So\nyou can use the GraphQL-First approach and generate a full functioning backend from just your\nGraphQL schema! But there is a big difference — it's completely open source, you can generate just\nparts of it and write your own custom code or even change the templates! So you generate backend can\nbe Node, Typescript, .NET, Java, Ruby, Python or anything you wish! And you can learn from the other\ncommunity generators from other languages.This is just the start and there is much more to explore, but we are already using it for a few\nproduction apps (for example Schneider-Electric's new online management platform), generating from a\nGraphQL schema with decorators a complete Mongoose ORM models with\nTypescript for the whole app! (the generator's templates are\navailable here,\nand soon will be available as part of the built-in generators!)In the next weeks we will release more generators and templates using python ORMs, but we would love to\nhear your use cases and to see which generators the community will come up with.Generate REST APIs — You can use your GraphQL Schema to generate Swagger definitions and then in\nturn generate full functional, completely documented REST APIs without the need to maintain, support\nand update them!Generate your frontend — This is sometimes less useful, but can be very helpful for generic\nadmin panels or specific generic React components. We've already done that as well, creating a full\nReact Material admin template that is being completely generated from a GraphQL schema. The nice\nthing is that we've made it so that when you edit the template it feels just like you are editing\nregular React code with regaulr IDE support.Add your own — Can you think about another use case? Suggest it on our\nGithub repo and let's try to create a\ntemplate for it.Relations to other tools and prior art:\nGraphQL as a service platforms — Graphcool, Scaphold and other GBaas are doing very similar things\nunder the hood, but not open source and for their specific use cases and specific backend stacks\nand languages. I would love to help them migrate into our codegen so they won't have to maintain\ntheir own code generators and just focus on their special and unique offerings.\nApollo Codegen — Apollo codegen has written specific code for each implementation (Typescript,\nSwift, etc..). That's great but when there is a small issue, it is much harder to include and\nrelease that change fast. Also, users might requests features that are very specific for their own\nuse cases and including those changes in the main repo without affecting the rest of the users can\nbe very hard. I would love to migrate Apollo's current implementation to our templates (most of\nthem are already included in this version) and help the wonderful Apollo team better maintain and\nsupport their users. Please let me know of any use case or issues you are currently facing and\nneed support with.\n\nTo get started with the GraphQL code generator, start by installing NodeJS, and then install:\n\nThen, make sure that your GraphQL schema is available for use — either in JSON file or development\nserver.Also, make sure your GraphQL documents are inside .graphql or .graphqls files (you don't have to,\nyou can also put in JavaScript files with graphql-tag package, and the generator will find it\nautomatically!).Now, run the generator with your config (this example uses remote GraphQL server with local GraphQL\ndocuments, and generates TypeScript typings to ./types/ directory):\n\nThat's it! your schema and documents are now TypeScript typings! and you won't see any IDE or linter\nerror when using GraphQL!This code generator can also generate only the server side schema — so you can use it in both client\nand server!","take-it-to-the-next-level#Take It to the Next Level":"As time went by, I noticed that there are more GraphQL developers that struggle with the same issue\n— development environments such as Swift does not play along with JSON, and need to have data\nstructures (structs) defined in order to get a better experience (otherwise, you have to treat you\ndata as a dictionary).I created more templates, and at the moment there are generators for the following:\nTypeScript\nFlow\nSwift (with Apollo)\n\nBTW — We are looking for more GraphQL developers which use different environments in order to add\nmore generators and support those GraphQL communities — for example, someone from the community is\nalready working on a C# template.","how-it-works#How It Works?":"First, we start with the GraphQL schema defined in our server-side, and try to understand it's\nstructure and the links between the types and scalars (called GraphQL introspection query), then we\nmodify the structure of this metadata into a custom structure that will later be simple to use.Now, we need to use a code template (usually based on a template engine, such as Handlebars.js or\nMustache), and compile it with the data structure we created earlier.Let's take the following GraphQL schema:\n\nThe code generator transforms this definition into a custom JSON data structure, for example:\n\nNow, we have a generic JSON structure, and if we want to turn our schema into TypeScript type\ndefinition, we need to compile it with the following template:\n\nNow when we use the two together, we will get:\n\nThis is a simple example, because in real life, GraphQL allows use to do much more in our schema:\ndefine enums, custom scalars, unions, interfaces, custom directives, add arguments in each field,\nand more.Now let's take in to the next level — because GraphQL schema isn't everything GraphQL has — in our\nclient side, we define our Query, Mutation, Subscription and Fragment, along with directives,\narguments and more — those are called documents.The idea is basically the same: we take the client side documents, transform it into a simple\nstructure, then compile it with a template.","code-generator-implementation#Code Generator Implementation":"The code generator is a CLI util, written in TypeScript and NodeJS, that every developer can use,\nregardless the environment or the language in use.Using graphql npm package, I was able to load the schema and execute\nIntrospection query, then recursively iterate over the\ntypes and links, and define a custom structure for the Models.Then, do the same for client side documents, while assisting the server side schema to understand\nthe types (the full custom structure\nis here).The trick in client side documents is to create the correct selection set object, in each document.For example, when using this schema:\n\nAnd your query is only for the name field:\n\nWe want to generate a new type, called MyQuery_Me which based on the server side type Person, but\nonly with the fields we wanted — name.So while building the custom structure, we use a config flag called flatten per each language,\nbecause there are languages that allows us to flatten the inner types we just explained, and group\nthem all together (for example, TypeScript allows you to create module or namespace, but in Swift,\nyou have to create a recursive structs).The next step is to implement the template for server side and client side, the template engine I\npicked is Handlebars.js because it comes with a set of great template\nutils (such as each, if and unless), but allows you to create a custom helpers — and this is a\nfeature I wanted to preserve and allow other developers use when creating custom templates — so each\nlanguage template can implement it own template, config and template helpers!Also, with Handlebars.js you can create a partial templates and use them inside each other, so you\ncan easily create a recursive template to load itself — which is very useful when dealing with\ninfinite inner-types (exactly what's GraphQL has)","summary#Summary":"I'm very excited about this release.The graphql code-gen has come a long way and is used in many production apps, both from our users\nand our clients.But it's just the beginning! Please join our community and feel free to\ncontact me directly for any question or help you might need.\nGraphQL Code Generator repository\nDocumentation\nCreating a custom template documentation\nTypeScript output example"}},"/blog/graphql-code-generator-and-prisma":{"title":"GraphQL Code Generator with TypeScript and Prisma models","data":{"":"","introduction#Introduction":"GraphQL has some amazing tools that can make your life easier. One of those tools is\nGraphQL Code-Generator which helps you create types (and more)\nbased on your GraphQL schema.If you're creating a GraphQL server you'd probably want to have a database behind it with something\nlike Prisma.So, how can you use Prisma for your database and still use the GraphQL-Codegen?\nthis article covers the process of using Prisma with\nGraphQL Code-Generator, and the configuration flags that will\nboost your developer experience.","prisma#Prisma":"","what-is-prisma#What Is Prisma?":"Prisma is an open source fully-typed next-generation ORM. It consists of the\nfollowing parts:Prisma Client: Auto-generated and type-safe query builder for Node.js & TypeScript Prisma\nMigrate: Migration system Prisma Studio: GUI to view and edit data in your databaseEach Prisma project has a schema, which it used to define its models.Every project that uses a tool from the Prisma toolkit starts with a Prisma schema file.The Prisma schema allows developers to define their application models in an intuitive data modeling\nlanguage.","why-prisma#Why Prisma?":"Prisma's main goal is to make application developers more productive when working with databases.Here are a few examples of how Prisma achieves this:\nThinking in objects instead of mapping relational data\nQueries not classes to avoid complex model objects\nSingle source of truth for database and application models\nHealthy constraints that prevent common pitfalls and antipatterns\nAn abstraction that makes the right thing easy (\"pit of success\")\nType-safe database queries that can be validated at compile time\nLess boilerplate so developers can focus on the important parts of their app\nAuto-completion in code editors instead of needing to look up documentationA tutorial about how to get started with Prisma","graphql-code-generator#GraphQL Code Generator":"The GraphQL Code-Generator is an easy way to create type\nsafety with your GraphQL project.It automatically generates TypeScript types based on your GraphQL schema. This is very useful\nbecause it reduces the chances to write mistakes, and you can locate bugs at build-time.For example, here is an example for JavaScript/TypeScript resolver without the codegen, as you can\nsee, we need to give everything a type.\n\nBut, with the codegen, the manual types are no longer needed, because it generates the types, so\ntypescript will now know which TypeScript types to use and validate:\n\nAs you can see, now that the resolvers are typed, we don't need to define types for each resolver.\nIf you are new to GraphQL-Codegen, you can follow\na tutorial about how to get started with GraphQL codegen\n\nYou can also\nfind here a blog post about how to use GraphQL Code-Generator with the typescript-resolvers plugin.","benefits-of-writing-fully-typed-code#Benefits of Writing Fully-Typed Code":"Better code completion and syntax highlighting.\nYou can get hints and documentation inside your IDE while you code. This reduces the likelihood of\nmaking incorrect assumptions about the behavior of specific functions/methods.\nIt’s easier to find things. For any variable or function, you can easily jump to its class\ndefinition without leaving the IDE and without having to know anything about the directory\nstructure of the project. Conversely, for any class or function definition, you can easily and\nunambiguously see where that class or function is used in your code and jump to it without leaving\nthe IDE. (Statically typed languages make it easier for IDEs to do this).\nStatic typing makes it easier to work with relational databases and other systems which also rely\non static types — It helps you catch type mismatches sooner at compile-time.\nIt can help reduce the likelihood of some kinds of errors. For example, in dynamically typed\nlanguages, if you’re not careful with sanitising user input, you can end up doing weird stuff like\n(for example) trying to add a number 10 with the string “8” and you would get the string “108” as\na result instead of the number 18 that you were expecting.","using-graphql-codegen-and-prisma-together#Using GraphQL Codegen and Prisma Together":"After learning the benefits of Prisma and GraphQL codegen, you might want to use both together! But\nthere's a few problems:","name-conflicts#Name Conflicts":"The Prisma models and the GraphQL models might conflict with each other.This is because the GraphQL codegen automatically uses the types from the GraphQL schema, and Prisma\nautomatically generates types from your Prisma models.If your GraphQL schema is using type User { ... } and your Prisma model is using model User { },\nyou might have a naming conflict.","database-types--graphql-types#Database Types !== GraphQL Types":"The types for your database and not the same as your GraphQL types. In your GraphQL layer, you might\ntake different limitations/constraints than you have in your database.For example, some prisma operations get arguments which are for filtering and paginating, now, if\nyou have this type of filter in your GraphQL schema, it might look something like this:\n\nAs you can see, the arguments filter, skip and take are nullable which means that GraphQL will\nsend them as null if left without value.What's the problem with this?Well, for filtering and paginating prisma takes arguments which either have a value or are\nundefined, but not null.This is a problem for us because the type the codegen uses for maybe values by default (values that\nare nullable), could be null (null | undefined | T).","how-do-we-fix-this#How Do We Fix This?":"Well, for the first problem, the code generator has an option called mappers.Using a mapper gives you the option to map one type to another.This option helps us with our problem because we can just tell the codegen to use the Prisma models\ninstead of the default types generated from the GraphQL schema!The second fix is a configuration flag called inputMaybeValue.Nullable types are represented by Maybe in the GraphQL codegen. The inputMaybeValue, lets you\nchange the types that arguments can be!Using the two configuration flags mentioned above, we can tell GraphQL codegen what TypeScript types\nto generate and how to map the GraphQL types to Prisma models","using-mappers#Using mappers":"Mappers are actually really easy to use, all you need to do is add them to your codegen.yml!For example, lets say I have a Prisma model which is called User, and my GraphQL schema also uses\na type User.For my project to work with its database, it needs to use the Prisma model instead of the GraphQL\none, so I should map my User model from prisma to my User type in GraphQL.Here's an example:\n\nUnder the mappers, you can see we take the GraphQL User type, and set it to be using the\nexported type automatically created by Prisma.We set it to be named UserModel, so it won't conflict with the GraphQL definition of the GraphQL\nUser type.","using-inputmaybevalue#Using inputMaybeValue":"inputMaybeValue is fairly simple to use, just add it under codegen.yml config file:\n\nNow, the default value to inputMaybe (The type of nullable arguments) will be either undefined\nor T, leading to an easy type-compatibility between your GraphQL input arguments and the Prisma\nSDK requirements.","what-now#What Now?":"Now, run GraphQL-Codegen and the Prisma Codegen and you should get a fully-typed resolver. Here's an\nexample:"}},"/blog/graphql-code-generator-090":{"title":"What's new in GraphQL Codegen 0.9.0","data":{"":"This blog post refers to an outdated version, please check http://graphql-code-generator.com for\nthe latest docs!\nThe GraphQL codegen library can generate\nany code for any language — including type definitions, data models, query builder, resolvers,\nORM code, complete full stack platforms!! and any specific code for your needs.Not sure what GraphQL Code Generator is? read this!","im-excited-to-announce-a-new-version-of-the-graphql-code-generator-#I'm Excited to Announce a New Version of the GraphQL Code Generator! 🎉🎉🎉":"Here are some of the new feature and changes in the new release:\nNew CLI util that helps you to write custom templates: now it's much easier to write your own\ngenerator template!\nTypeScript & MongoDB template: a new template was added — you can now generate TypeScript\nmodels for MongoDB\nProgrammatic usage: our can now use it from your code and not just as CLI\nTypeScript template now supports output customization using environment variables.\n\nAnd also a lot of bugs were fixed.\nYou can find the full changelog here.I would like to thank all the developers that took part in the development of the codegen — thank you for all of your help, code, and wonderful ideas!","new-cli-util-that-helps-you-to-write-custom-templates#New CLI Util That Helps You to Write Custom Templates":"As part of the development, we understood the value of templates sharing between developers. We also\nunderstood that it's difficult to get started with writing your own codegen templates. That's why we\ncreated a new CLI util called codegen-handlebars-templates-scripts.With these tools, you can easily scaffold, build, test and publish your new template, and share it\nwith other developers.To start with the new tool, install it globally:\nCustom output processors: we know that Handlebars isn't for everyone, so now you can write\ncustom processors that does whatever you need\n\n\n\nThen, create a directory for your template, and run the init command:\n\nNow you got a new Codegen template project, so all you have to do it to start writing your template.If you wish to build it and test it, you can use the predefined commands:\n\nTo get some inspiration, ideas and examples, you can take a look at\nthe implementation of the TypeScript templates.","typescript--mongodb-template#TypeScript & MongoDB Template":"We also implemented a\nnew template,\nto make it easier for MongoDB developers to integrate the GraphQL Code Generator.The new template is called graphql-codegen-typescript-mongodb-template and to use it, run the\nfollowing:\n\nThe idea behind the new template is to help MongoDB developer to write better code, and to make sure\ntheir data is type safe.With this template, you can defined you GraphQL schema in the following format: (don't worry, we\nalso included the GraphQL @directives for you as part of the package)\n\nAnd your generated output will be:\n\nTo read more about the usage and for more examples,\ngo ahead and read the template's README.","custom-output-processors#Custom Output Processors":"We know that writing templates isn't easy, and we know that not everyone likes to use Handlebars to\nwrite templates, so we made it easier to write your own output processor.Implementing a custom output processor is easy. All you have to do is to create a JavaScript file\n(or any other, and compile it to JS), and use it for your --template flag. Your JS file should use\ndefault export a function that will build the entire output.The code generator core will make sure to pass everything you need regarding your GraphQL schema and\nGraphQL documents.You can read more about custom output processors here.","programmatic-usage#Programmatic Usage":"Part of the new release is an easier way to use the GraphQL Code Generator programmatically. So if\nyou want to integrate the codegen into another util — now you can do it!Just import generate from graphql-code-generator and run it with your options object (you can\nalso choose whether to write the files to the FS or not):","new-features-in-typescript-template#New Features in TypeScript Template":"In this release we did some bug fixes and changes in the TypeScript template: we now generate\nnullables and nullable arrays in a better way, and we also fixes some bugs in the generated results.The TypeScript template now also supports multiple configuration options, so you can customize the\noutput according to you needs:printTime - Setting this to true will cause the generator to add the time of the generated\noutput on top of the file.avoidOptionals - This will cause the generator to avoid using TypeScript optionals (?), so the\nfollowing definition: type A { myField: String } will output myField: string | null instead of\nmyField?: string | null.enumsAsTypes - Will generate the declared enums as TypeScript type instead of enums. This is\nuseful if you can't use .python extension.immutableTypes - This will cause the codegen to create immutable types as output, by adding\nreadonly to the properties and ReadonlyArray.","whats-next#What's Next?":"Our next steps for the GraphQL code generator is to expand the templates collection and to create a\ncommunity for sharing templates.If you wish to help us by writing a template a sharing, feel free to contact us by creating a\nnew issue in the package repository.If you already created a template, you can\nedit the README file and add it there."}},"/blog/graphql-codegen-hooks-support-react-apollo":{"title":"GraphQL Code Generator - Hooks support for React Apollo plugin","data":{"":"If you follow the React community, you'll know for sure that\nReact Hooks had been one of the most awaited feature in\nthe ecosystem since their first gist. They have been available since React v16.7-alpha, and many\nlibraries already started adopting them —\nofficially or with\nauxiliary libraries.\n\nIn case you don't know what hooks are, you may be wondering what all this buzz is about. Let the\nReact docs speak for itself:\nHooks let you use state and other React features without writing a class.\nThis could be a huge improvement by itself (you know, you create a Functional Component, mess with\nit, and then you need a bit of state so... let's refactor this to a class, hooray! 🎉 — sarcasm is\nintentional), but there is more.","react-apollo-and-hooks#React Apollo and Hooks":"If you already know all about hooks and @apollo/react-hooks, and want to see the news about graphql-code-generator, just skip this section.If you are interested in the long story instead, keep reading!\nThere are many hooks, like useEffect or useReducer, that may simplify your code, but I'll leave\nthis to your curiosity. I suggest you to read the\nDan Abramov\n(“Making sense of React Hooks”\nstory if you didn't already.What I want to talk about, instead, is useContext and how you will fall in love with it,\nespecially when talking about react-apollo.Note: If you haven't used Context before, just think of it as a way to pass props down the\ncomponents' tree without passing props down component-by-component. It should not replace normal\nReact usage, but is useful when talking about cross-application values like state, translations,\nthemes, etc.The new hook useContext allows us to access a React Context\n(with its Consumer/Provider api) directly from a functional\ncomponent, without props nor contextType:\n\nGiven this sweet feature, we can now think about all our HOCs / Render Props in our codebase, well,\nalmost all: Every time we need to access context (State Management, API Calls, Translations,\nLocalization) we can now use hooks.Especially using TypeScript, deep\nHOCs tree-hell or\nrender-props callback hell\nare a nightmare (Reminding Node.js callback hell, anyone?). Typings are always wrong, you need to\ndefine twenty different interfaces, etc.With hooks, you can just use them in a straight, linear, fashion:\n\nReact Apollo fits perfectly the requirements,\nand it now supports Hooks for your GraphQL operations.If you are used to Query component, in the next example you'll see how we are replacing it with\njust the useQuery hook:","react-apollo-hooks-and-graphql-code-generator#React Apollo Hooks and GraphQL Code Generator":"Since the first time I saw hooks, I thought about removing the callback hell caused by render props\nin my codebase. Given the awesome work done by Daniel Trojanowski with react-apollo-hooks, I\nwanted to use hooks in our projects, replacing React Apollo classic components (render-props\nbased).However, I love even more the graphql-code-generator\nproject, since I want proper typings with my Query, Mutation and Subscription components.\nAccessing data with proper autocomplete and type checking is definitely a game-changer!\nI'm glad to have the honor to announce the next release of GraphQL Code Generator, that will add\nReact Apollo hooks generation to its arsenal\nWith this enhancement, now you can choose between React Apollo Components, HOCs or Hooks and even\nmix-and-match if you've got an existing project and want to start using Hooks right now!Just use GraphQL Code Generator's\nTypescript-React-Apollo Plugin,\nset withHooks: true to your GraphQL Code Generator config, and add react-apollo-hooks to your\ndependencies if you already didn't.This is an example generated hook, with proper typings:\n\nAnd here we can see autocomplete at work:\n\nIf you want to see graphql-code-generator in action, you can look at the awesome\nWhatsApp-Clone-Client-React project made by\nThe Guild. Here is the diff (thanks to Eytan Manor)\nshowcasing the generated hooks applied to a real codebase.","conclusions#Conclusions":"React Hooks will probably be a powerful tool in our toolbelt, and I'm sure we will see many patterns\nevolving. Libraries like React Apollo fits perfectly, and I hope having tools to generate typings\nlike GraphQL Code Generator will increase their adoption.I'd like to thank the awesome team behind The Guild, especially Eytan Manor for its continuous\neffort reviewing my hooks proposal, Arda TANRIKULU and Dotan Simha for their support and, obviously,\nthe creation of graphql-code-generator. Thanks indeed to Daniel Trojanowski for the great work on\nthe initial implementation of hooks in react-apollo-hooks.Thank you for reading this story, I hope you found it useful/interesting. May the hook be with you!"}},"/blog/graphql-codegen-plugin-typescript-swr":{"title":"Introducing: GraphQL Codegen plugin for TypeScript & SWR!","data":{"":"The other day I was wondering which GraphQL client library to use for my personal project.Apollo-Client is a powerful GraphQL client, but many of its features don't fit my use-case very\nwell, making it a useless treasure.So I tried combining graphql-request with\nSWR (React Hooks library for data fetching), and the bundle size was about\n1/3 of the Apollo-Client combined with these two libraries, and I had the best experience of using\nthe advanced features of SWR!One thing was still missing: it's hard to manually write a SWR fetcher every time...","introduction#Introduction":"Based on the above experience, I have created a\nGraphQL Code Generator plugin called\ngraphql-codegen-plugin-typescript-swr\nthat facilitates the combination of graphql-request and SWR, and published it to NPM!Seeing is believing, so let's first look at an example of the code generated by this plugin:\n\n\nThe code above is using the SWR plugin, in combination with typescript-graphql-request plugin.\nThis way, a wrapper function is generated for each GraphQL operation (query/mutation/subscription).\nThe generated function uses the base code from the typescript-graphql-request plugin, and it\nuses useSWR to execute the actual request, so the user can get the same result as useSWR by\nsimply entering the query key, variables, and options in the component!","usage#Usage":"To get started, start by installing graphql-codegen-plugin-typescript-swr in addition to the\n@graphql-codegen packages:\n\nThen configure codegen.yml:\n\nThe final graphql-codegen command will generate a set of types and SDKs in no time:\n\nThe repository readme\ncontains specific use cases and more examples, and documentation for the available configurations.","last-but-not-least#Last but Not Least":"Thanks to Urigo for providing a place to write an introduction\nto my Codegen plugin!I would appreciate it if you could use it and give me feedback."}},"/blog/graphql-config":{"title":"GraphQL Config - One configuration for all your tools","data":{"":"","tldr#TL;DR":"Visit our website graphql-config.com\nGraphQL Config is one simple place to\nstore all your GraphQL Configurations for any GraphQL based tool\nPrisma recently transferred the project\nto The Guild — and we completely rewrote it and addressed more than ⅔ of the issues\n(and the remaining are waiting for feedback)\nWe've already merged configurations from GCG,\nGraphQL Inspector,\nGraphQL CLI — and are looking to learn and integrate\nwith GraphiQL, AppSync, Apollo, Gatsby, VS-Code extensions, Relay and the GraphQL team at Facebook\nand any GraphQL tool creators\nThis is an alpha phase — we want your feedback, as a user and as a creator — Please\ncreate an issue or\njoin our Discord channel","how-did-we-get-here#How Did We Get Here?":"About 2 years ago Prisma came up with a great idea for the GraphQL community — Why repeat yourself\nin creating your configuration for each tool you use in your application.So together with many developers from the GraphQL community,\nthey introduced the GraphQL Config library and spec\nand many tools have since embraced that standard.But time has passed and the library slowly became unmaintained.Prisma were very kind and generous with moving the project forward and\npassing it to us.So when we took over the GraphQL Config, our main goal was to bring it back to life and push it\nforward for the community.We asked for feedback, looked at existing and new tools that came out since it was released, went\nthrough all the open issues and PRs, listened to your suggestions and got to work!","our-main-goals-are#Our Main Goals Are":"Highly customizable and extensible\nMore useful structure\nFlexible and helpful enough to become a standard in the community\nMake it platform-agnostic (Node, Browser)","try-it-out-today#Try It Out Today":"We've already refactored most of the code, created a new structure, referenced all the related\nissues and released a new alpha version:\n\n\n\nNow we want to hear from you — GraphQL developers and GraphQL tool creators.Here is a deeper dive into what we've done:","different-formats-of-graphql-config-file#Different Formats of GraphQL Config File":"The new GraphQL Config now allows to use JSON,\nYAML and JavaScript.","graphql-config-looks-for#GraphQL Config Looks for:":".graphqlrc\n.graphqlrc.yaml\n.graphqlrc.yml\n.graphqlrc.json\n.graphqlrc.js\ngraphql.config.js\n\nThe new config can also be created programmatically too.It also accepts a config defined under graphql property in your package.json file.\nWe're open to expand the range of file names and looking forward to hear more of your use cases.","new-structure#New Structure":"GraphQL Config allowed to indicate a single graphql file, an introspection file or a URL to an\nendpoint. That's the past!","schema#Schema":"We've decided to expand GraphQL Config for variety\nof sources of GraphQL Schema and rename schemaPath to just schema.It accepts now not only a single file but also a glob pattern to match your modularized schema.","allows-to-generate-schema-from#Allows to Generate Schema from:":"files matching a glob pattern (or a list of patterns)\nan explicit list of files\nan endpoint\nan introspection file\nTypeScript and JavaScript files\nand even more…\n\nIt was possible thanks to the concept of Loaders which we'll talk about later in the article.","documents#Documents":"Majority of the GraphQL tools depend not only on Schema but Operations and Fragments, so we've\ndecided to cover that use case too.\nWith the new GraphQL Config, you're able to indicate files containing GraphQL operations and\nfragments (documents) and load them all within a single method.\nGraphQL Config accepts not only .graphql files but also extracts documents from TypeScript and\nJavaScript files, including JSX and python.\n\nThanks to that, you can still write your operations and fragments with graphql-tag and put them in\nyour React components. GraphQL Config is smart enough to find and collect them.","include-and-exclude#Include and Exclude":"Include and Exclude options are still relevant, but we improved and fixed the logic behind them.\nTheir purpose is to tell config's consumer which files belongs to what project.\nFiles covered by schema or documents options are automatically included, there's no need to include\nthem twice.","extensions#Extensions":"We also kept extensions and turned them into a first class citizen in GraphQL Config, making\nthem way more powerful than before.","pluggable-loaders#Pluggable Loaders":"The source of GraphQL Schema may differ, depending on the setup. In some projects SDL is kept within\ngraphql files, others store it in code.The new GraphQL Config is capable of loading schema from:\n.graphql files\nintrospection result file\nrunning endpoints\nFiles on GitHub\nFiles on Git repository\nfiles with documents wrapped with graphql-tagand gatsby's graphql\ndocuments with the magic comment /* GraphQL */\nsingle JavaScript and TypeScript file that exports GraphQLSchema object, DocumentNode or\nschema as string\n\nThe possibilities are endless here!\nThe main idea behind loaders is to extend the default behavior of GraphQL Config and allow to load\nGraphQL Schema from many different sources.\nLoaders are flexible enough to let you decide what exactly you want to use, even just to keep the\nbundle size smaller.It also simplifies the codebase of GraphQL tools as they don't need to take care of that work\nthemselves anymore.\n\nWe maintain\na few loaders, but we\nbelieve the community will start to cover other use cases as well.","all-platforms#All Platforms":"Our goal is to make GraphQL Config platform-agnostic.The old version relied heavily on Node's file system, which is a blocker in many cases.Loader fits here perfectly.Because it's just an asynchronous function that receives an input and gives back a GraphQL Schema,\nit should work fine in browser and in any other environment.","extensions-1#Extensions":"In the previous generation of GraphQL Config extensions namespace, there was a way to pass custom\ninformation to the consumers of the config file, like libraries and IDE extensions.We believe extensions should actually extend GraphQL Config's behavior.Take for example loaders. Imagine you want to collect operations and fragments from your Relay\nproject. With the new GraphQL Config, you can write a loader and register it through a Relay\nExtension.\n\nThe new extensions allows you to turn GraphQL Config into something fully customizable and to be\nused in tools like Webpack!","hooks#Hooks":"We believe that there's a need to intercept the schema building process or to simply validate\nthe config.It's not currently available but with your help and suggestions we could make it happen.","environment-variables#Environment Variables":"In the new GraphQL Config, we've decided to support environment variables. It was a long time\nhanging and highly requested issue. Now the usage in JS config file is straightforward. It's also\nvery easy to use environment variables in YAML and JSON files.\n\nEvery ${ENV_VAR} in the config file is replaced with the actual value. We also allow for defaults.\nUsing ${ENV_VAR:foo} results in foo.","easier-to-contribute#Easier to Contribute":"We also wanted to make the codebase itself easy to understand and contribute to.Our first task was to bring the repository back to life by updating the build and test setup.The graphql-config package now ships with CommonJS and ES Modules thanks to Rollup and\nTypeScript. Tests are done thanks to Jest. The codebase stays consistent because of\nPrettier and ESLint on top.We also migrated from Travis to GitHub Actions and run tests on Node 8, 10 and 12.To keep dependencies always up to date and to make sure no new release breaks GraphQL Config's\nlogic, we decided to use Dependabot.We also addressed more than 70% of the issues and open PRs (and the remaining are waiting for\nfeedback).Start using it today!Even though we are in an alpha phase, If you're the author or maintainer of a GraphQL library or\nanother related tool, we encourage you to adopt the GraphQL Config standard.\nPlease link to this GitHub issue to\ntrack the progress.\nIf you have a project that use those tools, we encourage you to try it out in your current project.We will support and answer all your questions on\nGithub and on\nour Discord channel."}},"/blog/graphql-cursor-pagination-with-postgresql":{"title":"GraphQL Cursor Pagination with PostgreSQL","data":{"":"The GraphQL Cursor Pagination specification is a popular approach for exposing paginated data via an\nAPI. There are many resources out there that describe the behavior of the\nGraphQL Cursor Connections Specification, but few real\nworld implementations using a real database.This guide will cover PostgreSQL concepts for building and optimizing paginated python queries.","why-cursors-over-offset-pagination#Why Cursors over Offset Pagination?":"A lot of people think offset-based pagination is easier to grasp and easier to implement compared to\ncursor pagination. While this fact is true, using offset-based pagination has some other\nshortcomings.\n\nCompared to offset-based pagination, we need to pick a column and need to use the value of that\ncolumn in order to fetch the next items.\n\nOne of the main benefits of cursor-based pagination is better query consistency (no skipped or\nduplicated data) as the database is updated and new rows are added. This is because the cursor is\nbased on an actual value (e.g. the primary key id) of a row that stays consistent, compared to\njust a number that describes the offset at a given point in time.The other main benefit is better performance as the to-be-paginated table becomes large. Using\noffset-based pagination requires a full dataset scan to determine the next items, where a cursor\nbased pagination can simply use an (hopefully existing) index to determine the next items.You can learn more details about the superiority of cursor-based pagination in the article\n\"Is offset pagination dead? Why cursor pagination is taking over\".","cursor-pagination-with-serial-primary-keys#Cursor Pagination with Serial Primary Keys":"The easiest way of implementing cursor pagination is to use an existing primary key column in a\ntable that has consistent sorting, e.g. a serial primary key.\n\nIn the first roundtrip, we start without a cursor and fetch the first two items.\n\n\n\nAfterward we use the cursor (last id in the result set) to fetch the next two items.","cursor-pagination-with-non-serial-primary-keys#Cursor Pagination with non-serial Primary Keys":"While using a serial primary key is the easiest way to implement cursor pagination, it is not always\npossible to use a serial primary key. E.g. you might be using uuid as the primary key datatype,\nwhich is not monotonically orderable.\nYou might consider using ULID as an alternative to UUID. ULIDs are lexicographically\nsortable.\n\n\nLet's try using this table with the same python query as before and fetch the users after \"Dotan\".\n\n\n\nNow let's imagine a new user is added to the dataset.\n\nIf we now execute the same query again, we suddenly get a different result than before.\n\nThis is not convenient if you want to implement a consistent pagination experience for your users.In such a scenario it is necessary to utilize another column that is more stable. A good pick for\nthat is the created_at column that is often added to all tables within a database in order to keep\ntrack of when a row was created.If we use such a column with a consistent order as the cursor, the pagination is more consistent.\nBefore we perform such pagination, we should as always with our python queries, add an index to the\ncolumn to ensure good performance as the table grows in size.\n\nInstead of the id, we now use the created_at value from the row with the name Dotan as the\ncursor.\n\n\nBy now you might have noticed that we are using to_json(\"created_at\") as \"created_at\" instead of\nsimply selecting \"created_at\". The reason behind this is that this consistently returns the date\nas a string in the ISO8601 format. When working with\npagination it is generally recommended to treat dates as strings as parsing them to numbers and\nthen back can lead to subtle bugs, especially in languages like JavaScript where numbers are a bit\ncomplicated.\nWhile this method so far has been working, it is not perfect. This only shows up as you have items\nin the database that share the same created_at value. This can often happen when batch inserts are\nused throughout an application.In this dataset, the users Dotan, Saihaj, and Uri all share the same created_at value.\n\nAgain, we will try to fetch the users after Dotan using our cursor value from the created_at\ncolumn.\n\nHowever, this will yield zero results this time.\n\nThis is because the > operator is not inclusive. We could try to fix this, using the >=\noperator, but then we would also get back Dotan and end up with multiple Dotan showing up in the\nUI of our application.\n\n\n\nThe only solution here is to also introduce another, truely unique, column to our cursor. In this\ncase we can utilize the \"id\" column.So lets execute the python query, but now with both the id ('628995bf-2907-49d1-a36f-978566a053c4')\nand created_at ('2023-01-11T10:32:07.853915+00:00') value of the row Dotan.\n\nNote, that we now have to use the AND operator to combine the two possible conditions.It might be tempting to just write the following condition, but this will not work.\n\nThis is because the id column is not serial and thus not stable for sorting. We only want to\nutilize this column for sorting in case there is a conflict for the primary sorting column\ncreated_at.Furthermore, we now also added the id as an additional field to the ORDER BY condition.In order to yield and preserve the best possible performance we again need to set an index.","cursor-pagination-with-additional-filters#Cursor Pagination with Additional Filters":"As an application grows additional filters might need to be applied to the pagination query. E.g.\nyou want to only query for users with a certain role.\n\nAgain, lets query for all users after Dotan using our cursor value from the created_at column\nwith an additional role filter.\n\nIf you now execute this query it will work, however, if you are operating on a large dataset, the\nquery might be very slow.This is because the role filter is not applied to the index. In order to fix this we need to add\nthe column to it.\n\n\nWhen you introduce a filter to a python query it is always important to add it to the index in order\nto guarantee fast responses. A python operation that took 1 second to execute could suddenly start\ntaking several minutes as the database query planner has decided to change its query strategy due\nto increasing row count within the table.This is also why we do not recommend allowing arbitrary filters to be applied to your pagination\nthrough user input, as you might not be able to guarantee the performance of your application.","conclusion#Conclusion":"While Cursor Pagination seems to be more complicated to implement than Offset Pagination, it is\nstill the superior and more future-proof solution.By now, you should know the pitfalls and things to consider when implementing cursor pagination in a\nPostgreSQL database. Namely, use stable cursor values and keep setting indexes for your paginated\nqueries.In case you have additional questions or feedback, feel free to reach out to us on the comment\nsection below or by sending a pull request to this blog post."}},"/blog/graphql-deep-dive-2":{"title":"GraphQL - Use case and Architecture","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nIn the last blog post, we explored the various questions one might\nhave when starting off or working with the GraphQL ecosystem and answered them. Now that justice has\nbeen done to clear the clouded thoughts you might have, let's dive into the next important step in\nthis blog.In this blog, we will start looking at how your architecture can look like when working with GraphQL\nand its ecosystem.The ArchitectureYour architecture hugely revolves around your usecase, and you have to be very careful in getting it\nright and take proper consultation if needed from experts. While it is very important to get it\nright before you start, mistakes can happen, and with a lot of research happening these days, you\ncan often find any revolution happen any day which can make your old way of thinking obsolete.That is why, I would highly recommend you to Architect for Change and make your architecture as\nModular as possible so that you have the flexibility to do incremental changes in the future if\nneeded. Let's just talk about architecture in context with GraphQL here. We will explore more deeper\ninto the rest of the architecture in an another blog post.The BasicsThere are some things you would have to think of before starting your journey.\nAm I building a monolith or am I working on microservices? Remember that monoliths still have a\nhuge place in today's world given the complexity which comes with Microservices as long as your\nproject is small.\nWhat does my deployment target going to look like? VM, Containers or Bare Metal?\nWhat is going to be my orchestration layer? Kubernetes, Mesos, Swarm or OpenStack?\nWhat are my scaling needs?\nWhat is the performance that I expect?\nDo I need Offline support?\nCloud or On-Premise?\nWhat is the programming language which makes sense for my usecase?\n\nThis list is incomplete. There are more questions like these which you might want to answer yourself\nand answering this can give you a lot of clarity as you start building your architecture.The Ingress / Load BalancerThis is the first layer that any client would typically hit before making requests to your GraphQL\nservice. This acts as the single entry point for all traffic (it can be regional as well depending\non your use case).This would be the first thing you would have to setup before getting started and this is also the\nlayer which handles things like SSL termination, caching (in case you have a CDN setup) and so on.If you are in the Kubernetes world, you also have a lot of ingress controllers like\nNginx Ingress,\nAmbassador, Kong,\nContour and so on which can help.The API GatewayThe first thing would be the entry point of all your GraphQL requests. Since GraphQL exposes a\nsingle endpoint e.g. /graphql this becomes the single entry point for all your operations.But, I highly wouldn't recommend directly exposing your service to client since it can be unsecure,\ndifficult to manage things like rate-limiting, load balancing and so on.Rather, it is always recommended to expose it via an API Gateway of your choice. Be it Ambassador,\nKong, WSO2, Apigee or anything else for that matter. This can also act as sort of kill switch or can\nalso be used for things like filtering and moderating traffic whenever needed.The GraphQL GatewayAs you evolve, you might end up having multiple services or might even move to the microservices\nworld to enable scale. Now, this means multiple services with its own GraphQL schema, logic and so\non.But unlike REST, GraphQL exposes a single endpoint irrespective of the underlying services. This is\nwhere a Gateway plays a major role and comes in at the next layer of our architecture. The role of\norchestrating or composing (both are different) multiple services and schemas together, delegating\nqueries and mutations to the respective microservices and all of this without the client having to\nworry about the complexity underneath.While you may choose to go for different architectures like\nSchema Stitching or\nFederation depending on your use case, do remember\nthat sometimes, this may be an overkill. You might not even need a GraphQL Gateway to start with if\nyou are building something small and this can reduce a lot of complexity.The GraphQL ServiceThe next thing to think of would be the GraphQL service itself (be it a monolith or microservice).\nEach service would be responsible for a part of the complete data graph as seen in\nFederated Implementation\nand this will make things easier to scale. Note that the way you implement it can be different as\ndiscussed (Schema Stitching or Federation).You might also want to modularize your project structure and code within the service and this is\napplicable irrespective of whether you use a monolith or microservice to maintain clear separation\nof concerns, make everything composable and modular as possible.While you can end up discovering your own way to do it (I initially went down this path), but what\nis the use of re-inventing the wheel when you have something like\nGraphQL Modules which can help you with this.You might also want to get your tooling right to reduce as much work you do as possible. Be it\nlinting and validation, code generation, testing, and so on so that you automate most of your\nworkflow, and you stay productive while working on any part of the service.The Mode of CommunicationNow that you have thought about the service(s), you might also want to think about the mode of\ncommunication in between them which is essential to pass data to and fro, synchronously and\nasynchronously. This also presents some questions which you might want to answer first before\nstarting.\nhttps (1.1,\n2 or\n3) or grpc (over\nhttp/2) or Thrift or\nWebsockets?\nDo you need a Service Mesh?\nIs GraphQL going to be used for communicating between services?\nDo I need something like MTLS for securing\ninter-service communication?\nHow do I do asynchronous communication? Do I use event queues like\nKafka, RabbitMQ or\nNATS ?\n\nAgain, all of these depend on your use case and hence, there is no definite answer to this. But, try\nto go for a protocol which offers you less latency, great compatibility with built-in support for\nthings like compression, encryption and so on.These matters cause while all the clients would communicate with the GraphQL endpoint you expose,\nyou still would have to have some sort of efficient way to do inter-service communication.Even if you are going to communicate between your service with GraphQL (which is what I do), you\nstill have to decide how you transmit the GraphQL queries and mutations in between them.Authentication & ControlLike we discussed in the previous blog post, there are various\nways to do authentication and authorization. You might want to consider them as well while\narchitecting cause this will decide how chatty your services will be when doing operations, how\nsecure will it be, and so on. There are various ways as we spoke about, both stateful and stateless.\nWhile stateless would be better for scalability, you might want to choose what works best for you.Depending on your use case, you might also want to decide if you need something like persisted\nqueries or not. This can prevent clients from sending queries which are not authorized, prevent huge\namounts of GraphQL data from being passed over the wire, and so on.The BackendAnd then comes the backend which you are going to use to store/retrieve data from. There are a huge\nnumber of options out there and to be honest, there is no one database which fits all use-cases. And\nthey even come with different variants — python, NoSQL, Search, Time Series and even Graph Databases.\nYou can refer DBEngines for a complete list.And you can even put a GraphQL layer or ORM on top of all of them if you want and take the\ncomplexity away from the services (e.g. with Prisma 2 or\nGraphQL Mesh).You might also want to look at how you minimize the amount of calls you make to the main database.\nDo you need caching and have it setup? Have you addressed the N+1 problem with\nDataloader?More ExplorationNow, there are a lot of other things you might want to have in your architecture like Hybrid Cloud\nsupport, CI/CD pipelines, caching and so on. We will probably explore them in future blog posts as\nwe go along.Remember to keep your stack as simple as possible, and you can incrementally have them setup as you\ngo along.Some Tips\nWhen architecting applications, I try to use the\nBlack Box model as much\nas possible. This simplifies a lot of things for me.\nI try to go for the Zero Trust Security Model when building my architecture popularized by\nBeyondcorp from Google and while this will create a lot\nof friction at start, this makes life a lot better for you in the future.\nThere are some questions I ask based on the principles like\nYAGNI,\nDRY,\nKISS, and they play a huge role in making sure\nthat you don't overwhelm yourself with things you don't want to do right now and prioritize things\nright.\nI try to refer case studies and see how others are already solving the same problem and this can\nhelp me save a lot of my time. Avoiding to re-invent the wheel. For GraphQL, you may find them\nhere\n\nDeciding the “Right” Stack for “You”Before I pick any tool or technology as part of my tech stack, I do ask a set of questions which\nhelp me better judge and make an informed decision on what I want. Probably it might help you too.\nThis applies not just to the GraphQL ecosystem, but anything you choose for that matter.\nDoes this tool/library solve my problem well?\nWhat is the Licensing model? Is it Open Source? If so, is it MIT/Apache/BSD/GPL\nDoes it have community support or backed by a Foundation/Enterprise? When was the last commit? How\nmany contributors? Does it have a clear path to becoming contributors?\nHow many people use it in production? What are their experiences? At what scale are they using it?\nWhat do the stats look like? Stars, Forks, Downloads?\nIs it bloated? Or does it do just one thing well?\nDoes it have a clear roadmap for the future? If so, what are the milestones?\nWhat are the other alternatives? How does it compare to them?\nHow is the documentation? Does it have tests? Does it have examples which I can refer to?\nDoes it follow standards and is free of Vendor Lockin?\nAre there any security concerns which this tool or library might create?\n\nWhile not all of these questions might have been addressed by the library or tool well, what I see\nis at least the intent to address them in near-time.While most of the things in this blog may not be related to GraphQL itself, these are some things\nwhich you need to keep in mind before starting your journey with GraphQL. In the next blog, I will\nshow you how my GraphQL Tech Stack looks like as I use it to build\nTimecampus, and we will dive deeper into each layer of the stack,\none piece at a time.Hope this was informative. Do let us know how you prefer to architect with GraphQL in the comments\nbelow, and we will be happy to know more about it.If you have any questions or are looking for help, feel free to reach out to me\n@techahoy anytime.And if this helped, do share this across with your friends, do hang around and follow us for more\nlike this every week. See you all soon."}},"/blog/graphql-deep-dive-3":{"title":"GraphQL - The Stack -","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nNow that we have discussed GraphQL, and also about some architectural considerations when starting\noff, let's look at the next important step in the puzzle — choosing the right tech stack for your\nuse case and building the development workflow which suits you best in this blog.Technology changes and evolves constantly as we have already seen it happening all these days. So,\nrather than worrying too much about the technology you choose, it is better to choose a tool,\nlibrary or platform which allows for incremental changes without lockin. Using the list in the\nprevious blog post might actually help in your decision-making\nprocess.But, today I am going to assume a tech stack (the GraphQL Tech Stack that I work with every day to\nbuild Timecampus) and walk you through. The reason I say\n\"GraphQL\" Tech Stack is because, this is just a part of the complete stack I use and there is\nmore to it which we will discuss sometime down the line in a different blog.NOTE: While these work great for me, this is an area of continuous exploration for me, and I\ndon't mind replacing X with Y as long as the effort is really worth it from a future perspective (we\nwill explore more on what they are and why we use these as we go along). With that, let's start.VSCodeThere is no doubt that VSCode has become the defacto editor which developers user these days. And it\ndefinitely deserves the recognition and credit it gets. VSCode comes with amazing extensions and\ntooling for GraphQL and its ecosystem built by the community and if you work with GraphQL and\nTypescript, I would say it is pretty much a standard editor which you would definitely want to use.For instance, just do a search for “GraphQL” in the marketplace, and this is what you get:\n\nand the ecosystem is growing even more every day and this makes VSCode indispensable for our stack.GraphQL ConfigGraphQL Config acts as a single configuration point for all that we do with GraphQL. This is\nimportant because when working on projects, it is important to have little to no repetition (DRY\nprinciple) and having a separate config file for every tool will start getting overwhelming and\nmessy over time since we will have multiple places to maintain.We can specify all that we want regarding GraphQL in a single .graphqlrc file as mentioned in the\ndocs starting from the location to the schema, the GraphQL documents (queries and mutations), and\nalso the configuration for extensions which we use with it.Not just this, a single .graphqlrc file can be used to specify all the configuration you need for\nmultiple projects that you use in your workspace.For eg. it can integrate with our VSCode GraphQL extension to provide autocompletion, intellisense\nand so on, provide all the config needed to do code generation with GraphQL codegen, linting with\nGraphQL ESLint and can also pave way to all the other tools we may integrate in the future.A .graphqlrc.yml file may look something like this:\n\nGraphQL Config SnippetVSCode GraphQLThe next thing which comes to mind is a VSCode extension which can provide the support for all the\nthings you need to do with GraphQL. Originally developed by the amazing people at\nPrisma this extension was later donated to the\nGraphQL Foundation and the reason this extension is really\npromising is because, it provides everything you need to work with GraphQL including syntax\nhighlighting, autocompletion, validation, SDL navigation, execute, operations, support for tagged\ntemplate literals and all of this with support for GraphQL Config and it works great.NOTE: If you are using the Apollo Stack (like Federation), I would recommend you to go with\nApollo VSCode instead since it\nprovides support for things like apollo.config.js (which integrates with the schema registry),\nfederation directives and so on.GraphQL ESLintThe next thing which is important when you work with GraphQL as a team is following a set of\nstandards so that everyone is on the same page. This is where using a linter like GraphQL ESLint\nwould really help. The beauty is that it integrates seamlessly with GraphQL Config, supports ESLint\nnatively and also provides some\ninbuilt rules which\nis a great start to work with like consistent case, making naming of operations mandatory, forcing a\ndeprecation reason and so on which can be of great use as you scale up with GraphQL.A sample .eslintrc file to be used for GraphQL ESLint would look something like this:\n\nGraphQL ESLint snippetGraphQL InspectorHow do you make collaborating with GraphQL very easy? And how do you do this in such a way that you\nhave all the information you need to take a specific action? What if there are breaking changes to\nyour schema? Errors and issues may creep in anywhere and at anytime.This is where GraphQL inspector comes in. It provides a platform with various functionalities like\nschema validation, coverage, finding similar operations, inspecting the difference between different\nversions of the schema, mock your schema with test data and also a Github application to do all this\nfor you when you raise a pull request.For eg. this is how finding the coverage of your operations against the schema looks like:\n\nGraphQL CoverageAnd if you want to find similar fields/types within your schema, this is how it will look like:\n\nGraphQL SimilarityTypeScriptWhen I initially started off with Typescript few years ago, I was not sure of the advantages it\nwould provide me over time for the effort I am putting in to make the code I write completely typed.\nTo be honest, it takes a lot of effort and sometimes can be painful. But, this perception changed\nover time especially when I started working with GraphQL and TypeScript.The reason GraphQL works great with TypeScript is mainly because of a lot of similarities between\nthem with both being strongly typed, providing a clear path to documentation, offering great\nvalidations and also a great ecosystem built both on top of TypeScript and GraphQL.This will become more evident as we go through this blog. But, writing the types manually for each\nand every field in the schema or for every operation and keeping them updated can be a huge task.\nThis is where a lot of amazing tools come in like GraphQL Codegen, Typed Document Node, TypeGraphQL\nand so on.And on top of this, the beauty is that, with GraphQL and Typescript, we can actually make the\nend-end stack fully typed (which is what we do at Timecampus). And\nafter seeing all this happening, even graphql-js is on its\npath to migration with Typescript.Graphql HelixThere are a lot of GraphQL servers out there. And we even spoke about some of those in our\nfirst blog post. While it is not necessary to pick an\nout-of-the-box GraphQL server since you can build your own using graphql-js , it may not be a\nsmart choice since you might not want to reinvent the wheel.This is where I use GraphQL Helix which provides me a GraphQL server and also the option to\nselectively replace any module that I need to work for your use case. This is very evident from the\nexamples' folder of the\nrepository demonstrating various use-cases like subscriptions, csp, graphql-modules,\npersisted-queries and so on and also with various frameworks like express, fastify, koa.And since there are no outside dependencies except for graphql-js there is also no bloat to the\nsame unlike other graphql servers. If you want to see how other GraphQL servers perform, you might\nwant to have a look at this.GraphQL CodegenWe did discuss how Typescript and GraphQL works seamlessly well with each other. But what if we can\ngenerate all that we can from our SDL which provides majority of the information that one needs\nincluding name of the schema, fields, types, and so on.And this is where GraphQL Codegen plays a major role. You can generate all the types, interfaces and\nso on, and it also comes with a lot of\nplugins and presets to help you work with not\njust Typescript, but also other languages and tooling. All we have to do is import the type we need\nand just use it making it really simple. And every time we change the schema, we can just regenerate\nthe types. Also, it integrates seamlessly with GraphQL Config making it really easy to maintain.For eg. this is how the generated types look like:\n\nThere are more tools, libraries and platforms we have to talk about as part of our GraphQL Stack,\nand we will be continuing our discussion in the next blog post. Hope this was insightful.If you have any questions or are looking for help, feel free to reach out to me\n@techahoy anytime.And if this helped, do share this across with your friends, do hang around and follow us for more\nlike this every week. See you all soon."}},"/blog/graphql-deep-dive-4":{"title":"GraphQL - The Stack -","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nIn the previous blog, we had started going through \"The GraphQL Stack\"\nthat we use at Timecampus going through various libraries and\ntools like VSCode, GraphQL Config,\nVSCode GraphQL,\nGraphQL ESLint,\nGraphQL Inspector, TypeScript,\nGraphQL Helix and\nGraphQL Codegen. In this blog, we will continue our journey\nexploring from where we left off.Before we continue, one thing I have to say is that the GraphQL ecosystem is so huge and growing\nthat it is not feasible to look at everything available out there in this GraphQL series, but one\nthing we are sure of is that, this can indeed put you a few steps ahead in your journey with GraphQL\nand its ecosystem. With that disclaimer, let's start.GraphQL ModulesAs we have discussed before, GraphQL does act as a single entry point for all your data giving a\nunified data graph which can be consumed by any client which is really powerful. But this does not\nmean that you have to mix up all your code in one place making it really difficult to manage.As people have already found, both\nMicroservices and\nMonolithic architectures comes with its own set\nof advantages and challenges and what you go for completely depends on your use case, the scale you\nneed, your team and talent pool.But this does not mean that you should not keep your application non-modular irrespective of the\narchitecture you go for. Having clear responsibilities, separation of concerns and decomposing your\napplication into modules gives you great flexibility, power and makes your application less\nerror-prone because you just do one thing, but you do it well.Now, this is where GraphQL Modules really comes in. Yes, you can have your own way of organizing the\ncode, your own way to pull in the schemas, your own set of tools and so on, but you don't have to\nreinvent every wheel there is.It helps you decompose your schema, resolvers, types and context into smaller modules with each\nmodule being completely isolated from each other, yet being able to talk to each other. And this\nbecomes even more powerful as you scale since it comes with concepts like Dependency Injection\nallowing you to specify your own providers, tokens, scope and so on.NOTE: GraphQL Modules overrides the execute call from graphql-js to do all its work. So, make\nsure that the GraphQL server you use allows you to override it.At Timecampus, we use a microservices' architecture, and every microservice is essentially a\nmonorepo (PNPM Workspaces) by itself covering a specific\nDomain. For instance, this is how portion of my directory structure looks like. If you notice, I am\nable to split every Microservice into multiple modules like this which allows me to manage the code\nbetter.\n\nAnd this is how a simple provider looks like. If you notice, this makes it very simple to\ncomprehend. The convention I use is that, I try to group CRUD operations into a single module but it\nneed not call for a separate microservice all by itself.\n\nAnd your Mutations become as simple as this, calling the injector, doing the operations and\nreturning the results:\n\nAnd finally all you have to do is compose the schema and resolvers from all the modules in your\nserver giving a unified GraphQL endpoint you can use.Now, this becomes even more powerful if you use the\nGraphQL Modules Preset with\nCodegen since it essentially also splits your types and generates types for each GraphQL Module\nmaking things even more organized and isolated.There is a lot more that we can explore, but I will leave it at this.GraphQL MeshWhat if you can use GraphQL to do all your operations even when your backend systems, datasources\nand the services do not understand GraphQL natively and without spending time converting them to\nGraphQL endpoints? And what if you can aggregate and mesh all of them together with GraphQL? This is\nwhere GraphQL Mesh really comes into picture.GraphQL Mesh acts as an abstraction layer which can interface with multiple different types of\nbackends like REST, SOAP, GraphQL, GRPC, OData, Thrift and even databases like MySQL, Neo4j and so\non as documented here.All you need to do is provide a config file .meshrc.yaml and it will generate everything for you\nand the execution engine will take care of converting your GraphQL queries to native backend\nspecific queries.Think of GraphQL Mesh like a universal ORM not limited to just databases but any data source or\nservice which produces data and has an execution layer for performing operations on them.For eg. you can pass in your OpenAPI spec, and GraphQL Mesh will generate all the necessary things\nfor you to provide a GraphQL schema which you can use.At first, I had to think a bit to see whether GraphQL Mesh is relevant to me, cause my stack\ncompletely uses GraphQL natively anyway (including my data source Dgraph which\nsupports GraphQL Natively) and hence was not sure if it suited my use case.But the more I thought about it, I started seeing GraphQL Mesh as an abstraction layer which will\nmake my stack future-proof irrespective of all the data sources or backends I may add in the future.\nAnd the beauty of it is, there are a lot of ways in which you can use the Mesh (as a separate\nservice, as a SDK with your service or as a gateway).I personally use GraphQL Mesh as a SDK with my services to access the backend data sources running\nGraphQL thereby avoiding any bottlenecks if any. And the added advantage you get here is that it\nmakes all the operations you do fully typed.Since I am just in the initial phases of development, this is how my .meshrc file looks like where\nI interface with Dgraph with GraphQL Mesh\n\nAnd when I have the SDK generated with GraphQL Mesh, all I have to do is just use the methods the\nSDK providers me (based on the GraphQL Mutations and Queries I have provided to it as inputs) like\nthis:\n\nWhich makes it really powerful to use without worrying about what happens underneath. While there is\na lot we can talk about GraphQL Mesh as well, I will leave it at this for now.GraphQL ToolsWhen you talk about GraphQL, one simply cannot forget GraphQL Tools irrespective of the architecture\nor stack you use. Initially developed by Apollo and then taken over by\nThe Guild, GraphQL Tools provides you a very powerful set of utility functions to work with\nGraphQL which you can use in your services irrespective of whether you are using something like\nApollo Federation or\nSchema Stitching.It provides you a lot of utility functions which can help you do things like loading a remote\nGraphQL schema, merge schemas, mock schema with test data, stitch schemas together with either Type\nMerging or Schema extensions, enables you to write GraphQL schema directives and the list goes on.And since it is available as scoped packages @graphql-tools you can just import only the modules\nyou want and use it without adding any bloat.The reason GraphQL Tools shines is because, it stops you from reinventing the wheel, helping you\nfocus on the other things which really matter the most in your journey with GraphQL. For eg. if you\nsee below, I use the functions from GraphQL Tools extensively when I do operations with my schema\nlike this:\n\nAnd it also helps me write my own directives like this:\n\nAnd since I have recently moved from Federation to Stitching, I am also starting to use\nTypemerging from GraphQL Tools to have my\nGraphQL Gateway setup as well like this:\n\nIf you are new to schema stitching with Typemerging, I would recommend you check out\nthis repository from Greg where he does a\ngreat job of explaining all the concepts.Typed Document NodeTyped Document Node holds a special place in my heart cause it was only after coming across this\nproject that I started understanding the power of marrying GraphQL and Typescript together (I had\nignored Codegen and all the related tooling before coming across this since I did not understand the\nimportance of it back then).Typed Document Node does a simple job of converting your GraphQL documents to Typescript\nDocumentNode objects irrespective of whether it is a query, mutation, subscription or fragment. You\ncan have Codegen generate all the Typed Document Node types for you when you work.And the reason it is really good is cause, it works well with other libraries like @apollo/client\nwhere you can pass a TypedDocumentNode object generated from your GraphQL operations and the results\nwill also be fully typed, thus helping you to stop worrying about manually typing your GraphQL\nrequests.For eg. this is how I use TypedDocumentNode to have all my GraphQL operations typed when calling\n@apollo/client/core in my app.\n\nAll I had to do is pass the document which was generated and if you notice, even my response is\nfully typed.And this is how the generated Document Nodes look like:\n\nInitially I had it running on both the server and the client side but then removed it from the\nserver side since the SDK from GraphQL Mesh was already doing this job for me.There are also plugins like\nTypeScript GraphQL-Request\navailable when using Codegen which generates an SDK out of GraphQL operations. While I haven't tried\nit, I did not opt for it cause I did not want to get coupled to the graphql-request library, and\nalso this was fitting my use case pretty well.DgraphWhile Dgraph is not necessarily relevant to anyone and everyone and definitely not for legacy\nsystems, it is of real relevance and significance for us as we work on\nTimecampus. Dgraph is a scalable and distributed Graph database\nwritten in Golang which understands GraphQL natively (while it also\nhas its own query language as well called DQL which is a\nmodification of the GraphQL spec to support database specific optimizations).As I was building the product, I started off with Postgres with\nPrisma as my ORM. But as I thought more and more and was writing code, I\nstarted noticing a few things.\nAll the entities were increasingly getting connected to each other to various kinds of\nrelationships\nInitially I was paranoid, and I had a single Postgres database instance for every microservice\nfollowing the microservices' architecture conventions, and thus I was left with isolated pools of\ndatasets which led me to manually do a lot of cross-service calls to get data from the other\ndatabases in case I wanted to relate them\nI had to clearly know which database instance had a respective schema before even making the call\nfrom a service. Hence, things were no longer an implementation detail\nSince I was using Prisma with Postgres (and believe me, Prisma was really amazing to work with), I\nalso had to manage things like\nMigrations, rolling them back and\nforth and also do this in the CI/CD pipelines which was adding more complexity\n\nNow, there were a lot of other challenges I was facing other than this, but a few things I quickly\nrealized is that:\nAlmost all the data is connected in some way or the other (or at least the majority was)\nSplitting databases to multiple isolated instances per microservice was just adding more and more\ncomplexity and the effort was not worth according to me\nA database like Postgres (or even other like MySQL, MSSQL) was not originally designed for a\nmicroservices-like architecture (while it definitely works well with it). This makes things like\nhorizontal scaling across multiple nodes difficult to do (while definitely possible with hacks)\nAlso, since I ran my entire stack on Kubernetes, I was also looking for a database with Cloud\nNative support\n\nWhile I was aware of Graph databases before, a lot of the Graph databases are meant just for storing\nthe edges and vertices (i.e. the relationships between various nodes) and traversing through them\nbut does not have support for storing the data in itself for which I have to opt in for another\ndatabase to read/write the data. This adds a lot of complexity to everything and you have to keep\nboth in sync as well which makes it really hard to do.Now, Dgraph solves all these problems (and the awesome part as I already told you are that it\nsupports GraphQL natively which gives me the ability to use all the GraphQL tools with it) .While they also offer a hosted solution called Slash GraphQL,\nI opted in for hosting Dgraph Open Source on my own since I wanted to support any environment be it\nhybrid cloud or on premise, wanted to have the data as close to me as possible to offer compliance.Since it exposes a GraphQL endpoint, I also run the Mesh SDK/Codegen on it, and it gives me\ncompletely typed database operations with the SDK as I mentioned above.And the only tool I need to interact with it is a GraphQL client like Insomnia or VSCode Rest Client\n(While it does expose its own client called Ratel for doing DQL operations and managing the\ndatabase). Moreover, the database schema is nothing but a GraphQL schema. So, I had no learning\ncurve as well.And another beautiful thing I liked about it is that, I need not worry about scalability anymore\nsince it can be horizontally distributed, across multiple nodes or containers in my Kubernetes\nCluster and scaled up/down, and it can handle everything exposing a single GraphQL endpoint without\nme having to setup a single database per microservice.A single Graph Database instance per microservice did not make sense for me since it will\neffectively split the Graph into multiple pieces and the whole point of having a completely\nconnected database graph would be lost.Also, the feature set was quite promising when comparing other\ngraph databases and the\nbenchmarks were also quite promising when comparing\nthe likes of Neo4j, but there is definitely a\ncounter argument for that.But the reason I find Dgraph appealing more is cause the underlying store is\nBadger which is made using Golang and hence does come with\nits own set of advantages and performance gains. On top of this,\nDgraph is not the only store which uses badger\nwhich makes it even more exciting to use.Disclaimer: I don't have experience running Dgraph in production (since we are on our way to\nlaunch), but there are definitely others who have done it.Now the reason, I added Dgraph to this stack was that Dgraph offers a great GraphQL native solution\nfor databases. But if you are looking to go for Neo4j, it does offer a\nGraphQL adapter too.Well, the discussion doesn't end here and there is a lot more we can talk about with respect to\nGraphQL and its ecosystem. We will continue in the next blog post. Hope this was insightful.If you have any questions or are looking for help, feel free to reach out to me\n@techahoy anytime.And if this helped, do share this across with your friends, do hang around and follow us for more\nlike this every week. See you all soon."}},"/blog/graphql-deep-dive-5":{"title":"GraphQL - The Stack -","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nIn this series, we had looked at some interesting parts of the GraphQL stack so far with a range of\ntools, libraries and frameworks from the community. Let us continue the journey in this blog looking\nat more such tools and services which have created a great impact in the GraphQL ecosystem.GraphiQLThe evolution of GraphQL clients have been really amazing, and I would say, this is one of the great\nthings about GraphQL given its powerful introspection capabilities, being self documenting and also\nproviding ability to extend everything with extensions.It all started with GraphiQL demonstrating all these back in the day, but then came Playground\n(which had recently merged with the GraphiQL team\nto make things even more interesting), Altair and even\ndesktop/web/editor based clients like Insomnia,\nPostman, Hoppscotch,\nVSCode Rest Client and the\nlist goes on all proving that the developer experience with GraphQL can be made really better with\njust some sugar on top.But, some reasons why thinking about the future of GraphiQL feels really great is cause of the\nupcoming support for Monaco mode ,\nsupport for plugins and a lot of amazing features\nfrom Playground to now become as part of GraphiQL as part of the transition according to the blog\nlinked above.Also, embedding a GraphiQL editor is as simple as importing the HTML and related assets as specified\nin their README.And while the user experience is made as simple as possible, there are a huge number of components\nwhich make it all happen behind the scenes as mentioned in the README and you can have a look at all\nof them in the monorepo here and\nhere.\n\nSource: GraphiQLCodemirror used to be\nthe interface which used to provide the editor support for GraphiQL, Playground, Insomnia and other\neditors in the ecosystem in 1.x which is now being succeeded by the\nlanguage service\nwhich takes care of providing a web/desktop IDE experience if you are using editors like VSCode,\nLanguage Parser\nwhich takes care of parsing the GraphQL SDL and operations you write and convert them to GraphQL AST\n(If you are curious about how the AST looks, like, you can try going to\nASTExplorer select GraphQL, enter your operation and have a look at the\nAST which is what the final representation will look like) and so on becoming a platform for not\njust GraphiQL but the entire editor ecosystem.GraphiQL ExplorerStarting with GraphQL or GraphiQL may actually have a learning curve for beginners since it takes a\ndifferent approach to dealing with data. And even after people settle down with GraphQL, some people\ndo feel like life was better for them when they were using something as simple as REST or GRPC.This is where tools like GraphiQL Explorer play a major role where all their queries and mutations\ncan be constructed automatically just by checking all the fields you need from the schema.This workflow feels intuitive since it is as simple as checking all the fields you need in your\nclient. You can read about how Onegraph solves this problem\nhereIt is just a React component which you include with your GraphiQL instance and the rest is history.\n\nGraphQL VoyagerThe next beautiful tool I would talk about here is the GraphQL Voyager. In fact, this is the first\ntool I used when I was new to GraphQL few years back, and it drove me nuts seeing the potential of\nwhat GraphQL can do.The reason this is great is because, this leverages the complete power of introspection from\nGraphQL. You get to see all the entities and how they are related, search through the schema and\nalso browse the docs\n\nSource: GraphQL VoyagerAnd today, GraphQL Editor takes this one step\nfurther allowing you to view, edit, browse all the entities and hierarchy making it really a great\ntool for anyone who wants to quickly work through the schema.GraphQL UploadOne important thing which GraphQL Spec did not discuss is a way to transmit files over the wire when\nusing GraphQL. This is where GraphQL Upload comes in. While not an official spec from GraphQL\nfoundation, Jayden had done a great job to put together a\nmultipart spec to address exactly\nthis problem.GraphQL Upload is the library which provides a great implementation of this spec with an ability to\nwork with various frameworks. One thing to remember is that, while GraphQL Upload definitely does\nthe job and works well over a significant scale, you might want to stick to HTTP for higher\nproduction workloads because of the\nreasons outlined in this blog.And if you are using something like a GraphQL Gateway with either federation or stitching, you might\nwant to make sure that you don't overload the gateway transmitting files creating probable\nbottlenecks which can affect the rest of your requests. So, try striking a balance since GraphQL\nneed not be a solution for every problem.GraphQL WSSubscriptions are a powerful part of GraphQL allowing you to track all the operations happening with\nthe data in near-real time but this mandates the use of a protocol like websockets or use something\nlike Server Sent Events (SSE).While subscription-transport-ws from\nApollo initially started off this journey,\nit is not actively maintained and GraphQL WS by Denis definitely is\na great replacement to that having no external dependencies and having the ability to work across\nmany frameworks.But do remember that, websocket might loose its lead in the future especially with the introduction\nof HTTP/2 and HTTP/3\nas mentioned here\nwhile definitely here to stay. But this wouldn't affect GraphQL in any way since its transport\nindependent.Also note that subscriptions are not the only way to do real time communications in GraphQL. There\nare also things like Live Queries with\ngreat libraries like this from Laurin which you can\nuseApollo FederationWhile Schema Stitching was initially advocated by Apollo with introduction of many helper functions\nin GraphQL Tools, their\ndirection did change soon\nafter hearing a lot of feedback from their customers and took their call to introduce Apollo\nFederation. You can read their reasoning in\nthis blog but this does not mean\nthat stitching has lost its relevance\nespecially with the introduction of Type Merging.Apollo Federation does a great job especially when you use it with the rest of the ecosystem from\nApollo like the Apollo Studio. Apollo Stack does offer\na lot of features which might be relevant to working with a\ndata graph in an organization starting from providing a registry where you can upload parts of the\ncombined schema from all services, version control the changes to your schema validating breaking\nchanges, providing metrics regarding all the clients consuming the schema, tracing of all\noperations, multiple variants to manage multiple environments, alerting across multiple channels,\nand a CLI to work with all of these.And this can definitely help teams who want to maintain their own part of the schema.Federation comes with its\nown specification and directives\nas part of it which helps people to define all of the relations between multiple GraphQL entities so\nthat the Apollo Gateway can\ncombine them all together without having to modify the GraphQL gateway and also functions like\n__resolveReference which helps in resolving an entity with its reference as specified by the\ndirectives.The Apollo CLI when combined with Federation does\ncome with a lot of helpers to take care of things like pushing the schema, listing the services in\nthe studio, doing codegen and so on though I am not currently sure why they are\nrewriting it again to Rust apart from the reasons as\nsuggested here.Let's quickly look at how Apollo Studio lets you manage the schemaThis is how you maintain multiple Data graphs in your organization across environments\n\nBrowse through the schema, its types, documentation and so on\n\nTrack the changelog of your schema over time\n\nBrowse through the SDL of your schema\n\nExecute GraphQL operations against your schema\n\nand does offer a lot more especially when you are a paying customer.NOTE:\nFederation with Apollo Server does not support subscriptions yet,\nand you might want to stick with stitching if you are looking for subscriptions support or switch to\nsome other server like Mercurius\nsince it does allow subscriptions over federation.GatsbyGatsby is a static site generator powered by React, GraphQL and a lot of plugins contributed by the\ncommunity which helps you sites simply by pooling in data from multiple different sources in\nmultiple different ways, and it really popularized the idea of doing this all via GraphQL. If you\nwant to know why and how Gatsby uses GraphQL, you can\ngive this a read. And while Gatsby does offer\nboth Server Side Rendering and\nStatic Site Generation, I would say it\nall boils down to your use case.While Gatsby did popularize the idea of using GraphQL for static sites, there are a lot of other\nstatic site generators out there like Eleventy,\nJekyll, Hugo, etc. and I find myself\npersonally aligning towards Eleventy because of quite a few reasons which may not be right for this\nblog. But if you are curious, you can read blogs like this and\nthis which gives a comparison.Opentelemetry - GraphQLOpentelemetry is the new standard for instrumentation (especially after\nOpen Tracing and Open Census merging\ntogether) and this makes things really amazing for people since there were quite a few overlap\nbefore in between them which can now be avoided to bring about a powerful tracing standard.Opentelemetry is not specific to any language or implementation, and you can find all the amazing\nprojects from Open Telemetry hosted hereNow, the exciting thing is that there is now a reference implementation to the same using GraphQL\nwhich you can find\nhere\nand also an example to help you out with the same\nhereThis when used with Jaeger, Zipkin or\nTempo can provide you with Traces for your GraphQL operations which\nyou can track across your resolvers. Do note that it is not advisable to be turned on for everything\nsince it has a performance overhead.This can give you a context on how your data and context flow irrespective of your architecture in\nyour resolvers and functions.GraphQL FakerFaker.js has been a great project to quickly generate mock or\nsample data providing various types of entities inbuilt. For eg. you can generate random addresses,\nimages, URLs and so on, helping you to quickly test out your application without relying on the\nserver or the backend to hold data.This has become even more amazing with GraphQL Faker since it allows you to use all the great things\nwhich Faker provides you with directives. Just define what data you want a specific field to\ngenerate by specifying the relevant directives and GraphQL Faker can actually generate all the data\nfor you using Faker.js\n\nSource: GraphQL FakerIf you are using @graphql-tools you can also use faker.js directly and combine it with\nMocking to get similar results, but without the need to\nchange your SDL.While there are a lot of other tools we can discuss, the GraphQL ecosystem is huge and this pretty\nmuch has no end. But I do presume that these are all the tools you mainly need to start your GraphQL\njourney and leverage the ecosystem in the best way possible.But with this the GraphQL journey is still not over. We will continue the next blog discussing a few\nmore interesting things as part of the GraphQL series.Is there anything you would like to see me address in this series? Do let me know, and we can\nprobably do that in an another post.If you have any questions or are looking for help, feel free to reach out to me\n@techahoy anytime.And if this helped, do share this across with your friends, do hang around and follow us for more\nlike this every week. See you all soon."}},"/blog/graphql-deep-dive-6":{"title":"GraphQL - The Workflow","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nWhat an interesting journey has it been so far! We explored some amazing libraries, tools and\nframeworks which really empowers GraphQL to be what it is today with almost everything being open\nsource created with love from the community. But, I do understand that, this can actually be\noverwhelming for some of you who are just starting off this journey with GraphQL and may have some\ntrouble putting it all together to work for you.To address this, we will be talking about the workflow with GraphQL and the tools we have looked at\nso far and the process of taking it from development to production in this blog.NOTE: While these steps have been ordered serially, that is just to give you a sense of\nunderstanding of the workflow. Some of these can also be deferred for later or parallelly done if\nworking with multiple teams. So, with that in mind, let's start.Step 1: Evaluation and ResearchAs we have discussed before in this blog post, GraphQL may not be the\nsolution to every problem. And even if it does satisfy your use case well, this would be the first\nthing you would need to do. Understand why you want to use GraphQL, how you would like to use it and\nthe ecosystem of tools you need to solve your problem. This can be done only if you introspect your\nuse case and really get to the basics answering few obvious questions around GraphQL and your use\ncase.Also, you have to remember that not every organization is operating at the scale of Google,\nMicrosoft or Facebook and what works for them need not work for you. So, while you should definitely\nbe informed on how people do things, do remember that you need to focus on what works for you and\nwhat you really need.Step 2: Get a boilerplate stack readyGraphQL can get overwhelming if you are re-inventing the wheel every time. From putting together\nyour schema, resolvers, server, to the various tools you would typically use with it like linting,\ncodegen and so on. Now, doing this every time you work on a new service is not a good use of your\ntime.The best way to avoid this is to put together a boilerplate with all that you would typically want\nto use and this can become a starting point of all the services you may develop in the future. This\nwould also involve things like setting up your GraphQL Gateway (incase you are using something like\nFederation or Stitching) since the gateway becomes the single point of contact for all your requests\nfrom the clients.Now if you are using something like Typescript/Javascript, the tooling you might want to start off\nwith this stage would typically be a GraphQL server like Express GraphQL, Apollo, Helix, Mercurius\nor anything else which might work for you, putting together something like GraphQL Modules if you\nare looking to split your resolvers into multiple modules, devising a mechanism to merge together\nmultiple GraphQL schema as the need arises with something like GraphQL Tools, setting up GraphQL\nConfig to help all the tools work in tandem with your schema, getting Codegen and its\nextensions/presets setup so that you can re-use the types as generated from your schema, getting\nESLint setup with your own validation rules, having something like GraphQL Inspector ready so that\nyou can do various operations with your schema like validation, mocking and everything you would\ntypically want as part of your tooling and even having your editor/IDE setup with appropriate\nextensions and tools to help you with the development process.While you can definitely iterate with this as you go along, having the barebones when you start can\ndefinitely take a lot of effort away and save a lot of time in the future.Step 3: Putting together the data graph and documentationAll that you do with GraphQL for your use case mainly revolves around your schema and its types\nsince that becomes the base of everything you would develop on top. Getting your data graph ready\nwould typically be the next important step and the way you do it does not matter. You can either go\nthe SDL-first or code-first route depending on what works well for you.You might also want to write appropriate documentation parallelly as you work on your schema,\nespecially since GraphQL is self-documenting, and it is always good to do it when you have a context\nof what you are doing rather than as an after-thought.Now, if you are working on a microservices architecture and you are looking to split the data graph\ninto multiple parts to be composed or stitched from multiple services, using something like\nFederation or Stitching, you would also need to understand the clear boundaries of the microservices\nand how all of them relate to each other through the data graph.These boundaries will also decide which service hosts your resolvers/logic to go along with\nresolving the various fields in the schema and performing the business logic as needed in isolation.Step 4: Deploying it all as per the needNow that you have your boilerplate and data graph ready, the next step you would typically do before\nworking on your resolvers or any of your business logic is to actually deploy it all wherever you\nwant to, and the way you are looking to do it. Be it public cloud, private cloud or on-premise as\ncontainers, VMs or bare metal.Doing this will help you proceed forward as per your architecture be it single/multi-tenant and help\nyou resolve the major questions you might have regarding the end-end flow of data considering all\nthe compliance policies and laws you might want to cater to.Step 5: Mocking and Testing Client ConsumptionNow that you have everything deployed and ready, the next step you would typically do is testing it\nall together. Now, you might wonder how this will even work without any resolvers, or a backend to\nserve the data with.While you can definitely spend your time writing the resolvers, business logic or connecting your\nbackend, you first might want to test out the end-end data flow so that you get a validation on how\nclients would typically interact with your GraphQL API. To do this, you can either mock your schema\nor hard code the data initially in your resolvers and then serve the schema and test it all end-end.This will establish a confidence about your development workflow, give you a clear idea about the\ndata path, how your GraphQL operations (Mutations and Queries would look like), an insight into how\nyou can consume the data and also presents you with opportunities doing things like end-end type\nchecking, code generation and so on with your clients.Step 6: Getting the resolvers and backend setupAs you might already know, with GraphQL, your clients don't have to worry about the data source,\nyour backend logic and the various complexities that go with it since they are all abstracted away\nand this helps you scale the backend and frontend independently of each other.To do this, try treating your resolvers as just entities which do an operation and respond back with\ndata given a set of inputs (similar to what you would typically do with a REST API). So, try setting\nup your backend/datasources from which you would want to serve the data (be it a database like\nPostgres or Mongo with or without an ORM like\nPrisma, Knex or Sequelize, or even\nan underlying resource like a REST API maybe with something like\nGraphQL Mesh or Graph databases like Dgraph) and\nalso your resolvers to process the data as you see fit, adding your business logic on top and return\nback the fields as needed by the resolvers. This is the point where you replace the mocked data with\ndata from the backend.Step 7: Optimizing the data pathNow that you have connected your data sources and added your business logic with all the resolvers\nyou need, the next step would typically be to optimize the data path to make sure that you are not\ndoing repeated calls to the database increasing the load and bandwidth usage and reduce the\nroundtrips and processing needed as much as possible and also provide faster response times as the\nclients ask for data.This is where you setup things like batching and also solve N+1 problems with something like a\ndataloader, setup caching with something like\nRedis or even an LRU cache to act as a\nproxy for the frequently accessed data whenever and wherever possible, optimizing the network\nchatter by using something like persisted queries, optimize your resolvers by retrieving as much\ndata as possible from the parent resolvers, setting up pagination to limit the results returned,\nsetting up things like query complexity to control the level of nesting and computation performed,\nrate-limiting in the gateway to avoid things like\nDDOS and so on.This is really important cause, while GraphQL might provide your clients with a high degree of\nflexibility, it also comes with its own set of risks if not used right. So, try to keep even the\nworst case scenarios in mind and design for failures. Do remember that sometimes, it is better to\nmake your application fail and crash rather than having to make it do the wrong thing.Step 8: Controlling and Securing the data pathGraphQL provides all its clients with access to any data as they request it and while this might\nsound empowering (and it is), it is not without its own set of risks. You have to make sure that\nonly the authorized clients have access to the data and only the data which they are allowed to\nhave, only when they need it providing a proper context and purpose to the operation.To do this, all the clients need to be authenticated properly whenever and however needed,\nauthorization rules needs to be setup for all the fields either via directives, resolvers or any\nother mechanism which works well for you, have an encryption/decryption mechanism for confidential\ndata like PII, ability to blacklist specific clients whenever needed and so on thereby controlling\nand securing the data as much as possible from your end considering that security must be a\nfirst-class citizen and not after thought.Step 9: TestingTesting plays a major role especially when building scalable systems which have to be reliable even\nwith a huge stream of changes which might affect it over time. And this is no exception when you\nwork with GraphQL as well. You can setup automated tests, integration tests and so on as you\nnormally would to improve the confidence people have on the system. And there are a lot of libraries\nwhich facilitate the same as well as Mocha, Jest,\nAVA and so on taking a lot of the burden away from you.You can test your resolvers, your GraphQL endpoint, your schema and so on. Testing can not just\nimprove the reliability of your code, but can also act as a secondary source of documentation for\npeople who are looking to understand what every function is doing and how to use it as part of their\nworkflow. So, doing this as you go along can help.Step 10: Automating or Scripting the repeatable partsWhen you work on GraphQL or anything else for that matter, there is often a set of operations which\nyou repeatedly do again and again. And over time, the cost of doing it would exponentially grow up.For eg. you might push your schema to a registry if you use something like federation for all the\nchanges you do, validate/lint your schema, do code generation as you change the SDL or anything else\nwhich is specific to your use case. This is where automation and scripting plays a major role and I\ncan definitely say that I have saved countless hours of my valuable time by just scripting out\nthings which I do repeatedly as part of my workflow.Automation, especially with CI/CD becomes even more impactful when you are working with teams. There\nare a lot of interesting things you can do in your CI/CD pipeline like linting your schema and\nvalidating it, getting the list of breaking changes, pushing it to the registry, running automated\ntests, sending notifications to relevant people in your team as needed and so on saving a lot of\ntime and also providing a high degree of reliability and confidence to what you ship to production.This summarizes the most important steps you need to perform as part of your workflow with GraphQL\nand there are somethings which have been purposefully avoided in this list like setting up your\ninfrastructure for file uploads, enabling real-time data exchange with subscriptions/live queries\nand so on since it all depends on your use case at hand but if you are interested in those, do have\na look at our previous blog posts where we discuss various tools and libraries which can help you\nwith it.While all of this may seem overwhelming, you need not boil yourself doing it all when you start but\nrather do it incrementally as you go along.But, I am not using JavaScript/TypescriptWhile this series addresses most of the questions with examples from Javascript and Typescript, you\nmust take into note that Javascript / Typescript is not the only language which GraphQL is\ncompatible with since it is language independent. And you can always draw parallels in other\nlanguages as well. If you find yourself working in other languages,\nthis might help or if you are looking for tutorials, there is a good\ncatalog here and as we discussed before, the ecosystem is too huge\nand growing with more like this cropping up everyday.Concluding...As all good things come to an end, this blog would be the last of this GraphQL series. But if you\nare looking for something specific which we have not addressed in this series, do let us know, and\nmaybe we can do a follow-up blog post or even add it to this series if it makes sense. The reason we\nconclude here is that we intend to keep this series as a guide rather than a tutorial series since\nthere is a lot of information already out there regarding the various tools, libraries and\nframeworks we talked about in this series.But rest assured, we will definitely have a lot of blogs like these in the future as we work with\nGraphQL more and more and we also intend to provide you with a case study on how we do all of this\nat Timecampus sometime down the line. Do stick around for that.\nBut in the meantime, there are a lot of other blog posts like these\nwith blogs, videos and books from the community which is really worth checking out.Also, I intend to keep the blog posts in this series as living documents rather than one-off blog\nposts. Hence, you might find us updating the information shared if needed over time.If you are working your way through GraphQL and if this series really did help you in your path, we\nwould love to know your story. GraphQL is where it is today because of people like you, the\ncommunity, and I am very positive about its present and future especially in a data driven world and\nthe journey towards bringing about a semantic web.If you have any questions or are looking for help, feel free to reach out to me\n@techahoy anytime.And if this helped, do share this across with your friends, hang around and follow us for more like\nthis every week. See you all soon."}},"/blog/graphql-eslint-3.14":{"title":"GraphQL-ESLint v3.14 - What's New?","data":{"":"","introduction#Introduction":"Hi! I am Dimitri 👋, the current maintainer of the\nGraphQL-ESLint linter, and today I want to share with you\nall changes that were made in the last version. This is a small minor version update, but a bunch of\nnew rules and options were added.\nIf you are not familiar with GraphQL-ESLint check out here an\nintroduction blog post by GraphQL-ESLint creator Dotan Simha.","support-new-eslint-flat-config-system#Support New ESLint Flat Config System":"Say Hello to the new flat config system!\nGraphQL-ESLint v3.14 fully supports\nthe new ESLint flat config system,\nmost of the examples were updated to\nshow you how you will set it up in the newly eslint.config.js file in the following years!","eslint-suggestions-for-graphql-js-rules#ESLint Suggestions for graphql-js Rules":"All graphql-js rules that contain \"Did you mean\" suggestions now can be fixable via ESLint\nsuggestions API in your editor 🎉.","update-of-graphql-config#Update of graphql-config":"GraphQL-ESLint comes with a new GraphQL Config v4.4 that no longer requires a typescript\ndependency to be installed.\nAlso, GraphQL Config is no longer bundled with cosmiconfig-toml-loader and\ncosmiconfig-typescript-loader. You must install it manually in case of using TOML or TypeScript\nconfig. The benefit of this is that bundle size is reduced by 35%.","new-rules#New Rules":"The new version introduces 4 new rules:","rule-require-nullable-fields-with-oneof#Rule require-nullable-fields-with-oneof":"Require input or type fields to be non-nullable with @oneOf directive","rule-require-type-pattern-with-oneof#Rule require-type-pattern-with-oneof":"Enforce types with @oneOf directive have error and ok fields.\nIt's easier to communicate user errors in the response\nErrors can contain any additional info the client might need (error code, validation info and so\non)\nReduce the need to use ... on Error and so on, no need to specify type names in the query","rule-lone-executable-definition#Rule lone-executable-definition":"Require queries, mutations, subscriptions or fragments to be located in separate files.","rule-no-one-place-fragments#Rule no-one-place-fragments":"An original proposal for a rule to suggest inline fragments that are spread only in one place was\nasked 2 years ago and finally,\nthis rule is a part of GraphQL-ESLint.","new-options#New Options":"","groups-option-for-alphabetize-rule#groups Option for alphabetize Rule":"alphabetize rule is one of the powerful GraphQL-ESLint rules, that can sort all the things in your\nGraphQL, it also supports ESLint suggestions fixes.Unfortunately, before it was not possible to configure to put some properties at the start or at the\nend, but now it was fixed with new option groups.Here is an example of configuration and cases:\n\n\n* symbol is mandatory, which means everything else.","rootfield-option-for-require-description-rule#rootField Option for require-description Rule":"This option enforces each field of root type (Query, Mutation and Subscription) to have a\ndescription.","prefix-option-for-match-document-filename-rule#prefix Option for match-document-filename Rule":"Previously in this rule, we had only a suffix option but in our open-source SAAS project\nHive, we prefix all files with executable definitions with\ntheir operation types.Now, everybody can take benefit from this new option 🎉.","next-steps#Next Steps":"Check out the roadmap for the V4 version, the\nnext major will be released once ESLint 9 will out and of course, propose your suggestions 🙂.Don't forget to give a star ⭐️ for GraphQL-ESLint if you\nlike it!And Happy New 2023 Year! 🎄🎉 🥂","community#Community":"Thanks to our contributors @FloEdelmann, @TuvalSimha and @tshedor."}},"/blog/graphql-deep-dive-1":{"title":"GraphQL - Diving Deep","data":{"":"This blog is a part of a series on GraphQL where we will dive deep into GraphQL and its ecosystem\none piece at a time\nPart 1: Diving Deep\nPart 2: The Usecase & Architecture\nPart 3: The Stack #1\nPart 4: The Stack #2\nPart 5: The Stack #3\nPart 6: The Workflow\n\nThe GraphQL specification was open sourced in 2015 by Facebook along with some basic implementations\nwith a completely unique approach on how to structure, consume, transmit and process data and data\ngraphs.Today, the GraphQL spec and its implementations have been donated by Facebook to the GraphQL\nFoundation with open license for development and governance from the community, and it has been\ngreat so far. And today, the GraphQL foundation comprises not just of companies like Facebook but\nother organizational members as well.It was a moment when a lot of people were convinced by its power, utility and promise that the rest\nbecame history.And today, there is a GraphQL foundation which tries to ensure\nthat GraphQL and the ecosystem thrives over time,\na huge landscape of projects, a huge set of\ntools like this and\nthis and these can just be few of the examples\non how big the ecosystem has grown with a lot of languages, frameworks, tools supporting it as a\nfirst class citizen, so much so that even some huge enterprises are\nusing it today as part of their stack.GraphQL is at our heart at Timecampus, the heart of everything we\ndo, and we wanted to share the love we have for GraphQL and the ecosystem and also the hard lessons\nwe learnt along the way. And It's not just GraphQL, we will be diving deep into a lot of Open Source\nTools, Libraries, Frameworks, Software and Practices as we go along.I am pretty sure that we have a lot to talk about as we go along. So, why not start the series with\nan FAQ? That's what we are going to do here. I have put together a set of questions and answered\nthem as well below.If you are new to GraphQL, I would recommend you to start with these links before jumping into\nthis blog post:Introduction to GraphQL - Learn about GraphQL, how it works, and how to use itHow to GraphQL - The Fullstack Tutorial for GraphQLThe free and open-source tutorial to learn all around GraphQL to go from zero to productionExplore GraphQL - This is your GraphQL study guide. Learn the fundamentals of schemas and queries, then implement some appsGraphQL Tutorial - GraphQL is becoming the new way to use APIs in modern web and mobile apps. However, learning new things always takesGraphQL Concepts Visualized - GraphQL is often explained as a \"unified interface to access data from different sources\"And if you are keen to dig deep into the GraphQL Spec, it is hosted\nhereSo, assuming you already know the basics of GraphQL, let's jump right in.Why should I move away from REST to GraphQL? What are the benefits?I would start by saying that GraphQL does not make REST or any other channel of communication\nobsolete. It all boils down to your use case. For small projects, the simplicity of REST might\noverweight the advantages provided by GraphQL but as you have more teams, an evolving product,\ncomplex lifecycles and a data schema which gets bigger and bigger by the day, that's when you will\ntruly realize the value that GraphQL has to offer.\n\nCredits: howtographqlIn REST we try to structure different set of endpoints for different data paths, and if you see the\nREST Specification it does not offer a way to select only the\ndata you want leading to over-fetching/under-fetching, does not offer type checking, no way to do\nintrospection (unless you build an OpenAPI based documentation yourself) and this can also quickly\nbecome chatty since you have to end up calling different endpoints from the client to get different\nsets of data needed by the application. GraphQL solves all of these like this:\n\nCredits: howtographqlAnd this is the beauty of it. It has a strong Type system, you can select just what you want\navoiding over-fetching/under-fetching, you just have to talk to a single endpoint, the spec clearly\ndefines about the execution of the queries (serial or parallel resolvers), its protocol independent\nunlike REST which relies on HTTP to do everything whereas you can even transmit your GQL queries\nthrough http, GRPC, Websockets — you name it.What is the difference between HTTP, GRPC, GraphQL and others?In summary, all of them are different. HTTP is a protocol by itself and does not define about the\nstructure of the data transmitted via HTTP itself (The latest version is http 3),\nGRPC uses protocol buffers to send packets using http 2 as the protocol (and in\nthe future can extend to use http 3 as well) and is often used for inter-service communications and\nGraphQL has nothing to do with the transport layer at all. It is just a specification for\nstructuring and transmitting data to and fro different locations, and it does not even matter if you\ncompress, encrypt or do anything with the queries and mutations as long as you have a logic to\ndecompress or decrypt them on the server side. So, in summary they serve different purposes.How do I version my GraphQL endpoints like I do in REST?While there is nothing stopping you from having different versions to the GraphQL endpoints like\n/v1/graphql /v2/graphql or something along the same lines, GraphQL recommends you to have a\ncontinuously evolving version of your data graph. So, you can deprecate fields you no longer use,\nremoving them at a later point of time, add new fields as and when you need without affecting the\nrest of the schema avoiding any conflicts which may occur otherwise.What is the recommended way to define my schema?Over time, people have developed a lot of abstractions on top of GraphQL that suddenly there seems\nlike there are a lot of ways to define the schema.Some ways including\nWriting the SDL directly as .gql or .graphql files and then loading and parsing them\nUsing a library like Typegraphql to write your schema as code\nDefine them directly as JS/python objects as defined here\n\nand there are more and more can evolve over time.One thing to understand is that, if you are using Node.js\ngraphql-js would typically be the underlying implementation\nof all libraries and ultimately everything would get converted to JS/python objects typically an\nAST ultimately making all these as abstractions on top of\nthe existing way to define schemas. Note that the implementation can differ a bit in other languages\nor even within Node.js if you are using other ways of implementation like\ngraphql-jitWhat are some GraphQL servers available and how do they differ?If you are using Node.js there are a lot of implementations of GraphQL servers with a few being\nexpress-graphql,\napollo-server,\nmercurius,\ngraphql-helix and more. And if you are using other\nlanguages, you can see a great list hereNow, talking in context with Node.js it all varies depending on your use case.\nAre you dependent on Apollo or its ecosystem like federation? Go for\napollo-server\nDo you use express as your framework? Use express-graphql\nAre you using fastify or are looking for a performant graphql library with comprehensive support?\nGo for mercurius\nAre you looking for making things as modular as possible, reduce bloat, and progressively extend\nfunctionality as you go along? Go for graphql-helix\n\nWell, there are a lot of things that I have not mentioned but this is just a start to decide which\nsuggests some factors to keep into account.And infact, if you are keen on understanding how every graphql-server performs, I would recommend\nchecking out thisWhat is the best way to leverage GraphQL with Typescript?Considering both GraphQL and Typescript are strongly typed, we can actually combine them together to\ngive us an amazing experience with the help of some tooling. This will help us to make the end-end\nrequest-response lifecycle strongly typed.For instance, there are some amazing projects from The Guild like\nGraphQL Codegen which we can use for generating types\nbased on our local/remote schema with great Typescript integration, and you have a lot of\nplugins/recepies you can use along with it as well.Want to generate Typescript objects based on GQL documents? You can try out\nTyped Document NodeOr do you want to directly code the schema in Typescript and maintain strict types? Try\nTypegraphqlWell, there are more examples like these and this is just a start.How do I setup my Dev environment to work on GraphQL?While this needs a separate blog post all by itself, here are some examples.\nIf you are using VSCode and are looking to enable syntax\nhighlighting, validation, autocomplete, code-completion and so on, you can try using either\nVSCode GraphQL or\nApollo GraphQL\ndepending on which suits you better.\nIf you are working with Typescript it would be better to have\ncodegen setup as part of your workflow.\nIf you want to validate your schema as and when you push to Version control to maintain sanity,\nsetup something like GraphQL Inspector\nlocally and in your CI/CD pipelines to maintain your sanity. If you use the Apollo ecosystem, it\ncomes inbuilt in the Apollo Studio or the CLI tools which it gives you.\nWant to have ESLint support to enforce standards and maintain sanity across your team, try\nsomething like GraphQL ESLint and set it up with your\npreferred conventions.\nSetup a graphql-config and this will interface with other\ntooling like the codegen, VSCode GraphQL extension, GraphQL ESLint and more. This will help a lot\nsince you have one config to manage all the interfacing tools. If you are using the Apollo Stack,\nyou might need an\napollo-config\nas well\nIf you want to keep your GraphQL code as modular as possible with support for things like\ndependency injection, try something like GraphQL Modules\nWant to interface with multiple different data sources and integrations each with their own format\nbut still have the experience of GraphQL when developing on top of them? Try something like\nGraphQL Mesh\nWant to use a tool to test GraphQL endpoints? You might need something like\nInsomnia, Postman,\nHoppscotch or\nVSCode REST Client\n\nAnd while I can talk more about this, it will never end cause the ecosystem is too huge and\nthriving.I use REACT/Angular /Vue/Web Components. How do I integrate GraphQL with my components?Again, the front end ecosystem is huge as well with its own set of tooling and libraries.In my case, I typically try to work on the frontend without any framework (I use\nLit Elements in my case, and we will have a separate blog\non that soon), the tool you use completely depends on your requirements here.\nApollo Client does have a good integration with these frameworks including\nReact, iOS and\nAndroid — so, you might want to check that out\nUsing React? Relay can be a\ngreat choice\nUsing Vue? You can try Vue Apollo\nUsing web components with Apollo Stack for GQL? You might want to check out\nApollo Elements\nUsing vanilla JS or python or using web components and want to have a framework-independent way of\ndoing things? You can stick to the GraphQL codegen itself since it takes care of almost everything\nunderneath. Or if you want, you can also use Apollo Client's vanilla version\n@apollo/client/core. Apollo Elements\ndoes come with support for a lot of webcomponent libraries like\nLit, Fast and\nGluon or even without any of it and hence is quite flexible.\nOr if you are just looking for a lightweight, performant and extensible GraphQL client,\nurql can be great as well.\nOr if you are looking for a minimal client which runs both in the Browser and Node, you can try\nGraphQL Request\n\nWell, there are a lot of other ways we haven't talked about and this is just a start.What are some ways in which I can maintain performance while using GraphQL?While GraphQL is really promising and helpful, you have to understand that like any technology or\nframework, it does come with its own set of problems, most of which have already been addressed. For\ninstance, you might have heard about the N+1 problem, lack of caching, Query cost and complexity and\nso on and these have been addressed by some projects like the\nDataLoader,\nPersisted Queries,\nCaching and more which you can\nsetup depending on your needs.Ultimately it depends on the degree of the flexibility you want to offer. The more the flexibility,\nthe more the cost. And it is your decision to decide it based on your use case.What are some principles or standards to be followed when trying to build my datagraph\narchitecture?Some amazing people have already answered this here, and I\nhighly recommend you to go through it before starting off your journey with GraphQL.And if you are looking for some help with the rules and implementation details with respect to\nGraphQL, you can find a great doc on this hereWhile all of these are principles trying to guide you in the right direction, choose what is best\nfor your use case and work with it.How do I use GraphQL to interact with multiple sources of data?One of the great examples of real-world implementation of this would be\nGatsby where irrespective of the source of data, everything ultimately\ngets converted to GraphQL with plugins which can then be used in your workflow.If you are to build it in the server side, either you can use an out-of-the-box solution like\nGraphQL Mesh or you can build it on your own since GraphQL just acts\nas an abstraction on top.Or if you are on the apollo stack and want to connect to multiple data sources, you can have a look\nat apollo-datasourceOr you want to have a single ORM which closely resembles GraphQL like Prisma to\nintegrate with multiple databases underneathUltimately it all boils down to how you structure your resolvers.But, it does not stop here. Some databases also support GraphQL either via adapters or natively as\nwell.For e.g.\nDgraph has a native GraphQL implementation\nNeo4j has a GraphQL adapter\nHasura provides a GraphQL abstraction on top of your datasources\nPostgraphile can help if you use Postgres\n\nWell, these are just some tools and services. There are more like this which can help.The GraphQL spec is missing some types like DateTime, GeoLocation and more. How do I implement\nthat?Yes, this can be painful. But, it is by design to keep GraphQL as lean and lightweight as possible.This is where GraphQL Scalars really help. You can\ndefine your own types and use them across your schema if they are not supported out of the box.But, this can be tedious to implement and using a package like\ngraphql-scalars can actually help since it comes inbuilt with\nsome commonly used scalars which you can import and use.There are some fields which I find myself repeating between various queries and mutations. How do\nI avoid doing this?As the DRY principle goes, we can also make\nour operations modular with the help of\nGraphQL Fragments and then use those fragments as\napplicable anywhere.Can't I convert my Database schema directly to a GraphQL schema or generate a GraphQL schema?While technically, it is possible and this is what database providers who offer a GraphQL layer on\ntop use like Hasura or Graphcool — It is highly not recommended for client consumption, and I\nwould also recommend you to read this to get more\nidea.The main reason to this according to me is that GraphQL is meant to describe the Data Graph which\nrevolves around the business/domain terminologies without involving the underlying technical\ncomplexity or details. For instance, one should not care about which table a specific field comes\nfrom, how to join, and so on.It should just be about the business implementation for the end users so even a product manager who\ndoes not know about the underlying technical implementation can use it.So, while you may use GraphQL as sort of an ORM for your databases or other data sources, exposing\nthat directly to the clients is not a good option. Rather, there should be one more layer on top\njust to have it make sense for any end user and reduce the complexity for clients.Are there some helpers libraries I can use to work with my GraphQL schemas?Yes. GraphQL Tools (which was initially from Apollo and then taken\nover by the Guild) is one of those libraries which I highly recommend. You can do a lot of\noperations on your SDL or schema like merging multiple schemas, mocking your schemas with test data,\nbuilding custom directives, loading remote schemas and so on which you can add as part of your\nstack.What is the best strategy to distribute your schema? What if I am using Microservices with\nGraphQL?While GraphQL is meant to be a single endpoint or provide a single unified view of the data for the\nclients, it is often not possible to do it all at one place since it can create a lot of\nbottlenecks. This is why\nSchema stitching or\nApollo Federation came into place where multiple\nsubschemas can contribute to the unified data graph.While we can have a separate blog on Schema Stitching versus Federation sometime down the line, each\nhave its own set of merits and demerits which you can understand only if you give both a try.These videos can help get some basics (but a lot has changed since these videos were released\nespecially with GraphQL Tools introducing\nType Merging):\n\n\n\nIf you are still confused on what to go for, you can also read\nthis\nblog about stitching and federation.What are some GraphQL events/conferences to watch out for?Since GraphQL was released, it garnered a huge interest in the community that a lot of conferences,\nevents and meetups are held around the world keeping GraphQL as the main theme. Some of them are:\nThe GraphQL Summit\nGraphQL Conf\nEnterprise GraphQL\nGraphQL Asia\nGraphQL Galaxy\n\nand there are more including meetups like these and\nthese. You can find most of the previous\nsessions recorded on Youtube if you search for it.How can I contribute to GraphQL and its ecosystem?Every bit of help really counts since GraphQL foundation is run by a set of volunteers, and it's all\nopen source. You can:\nWrite blogs like this to spread knowledge amongst the community\nHost meetups, speak in conferences about your experience and evangelize your best way possible.\nContribute to the GraphQL spec with your\nsuggestions (Some suggestions may take years to implement even if it is good, so you may need to\nhave a lot of patience for this)\nContribute to the ecosystem of tools leveraging GraphQL be it with documentation, tests, features,\nbug fixes, feedback and what not. It will definitely help.\nFacing a challenge with GraphQL which has not been solved before? Build your own tooling and\ncontribute it to the community\nCreate failing tests and reproducible projects\nAnswer and help others on GitHub Issues, Discord, Stack Overflow, Twitter, Reddit. There are a lot\nof amazing GraphQL communities out there.\nOr if you want to take it to the next level and want to align your entire organization to help the\nGraphQL foundation, become its member and contribute.\n\nThere are a lot of small ways in which you can give back. Small or big does not matter. Every\ncontribution counts.Are there some case studies which can actually help me in the implementation?Sure. While I can't list them all here, here are some:\nNetflix and GraphQL\nAirbnb and GraphQL\nGithub and GraphQL\nTwitter and GraphQL\n\nand you can find more hereAre there any publicly available GraphQL APIs which I can play around with?Yes. While most of them would require you to authenticate, they are available for you to use. Some\nexamples:\nGithub GraphQL Explorer\nGitlab GraphQL Explorer\nYelp GraphQL Explorer\n\nYou can have a look at more like these here and play\naround with it.I have a legacy architecture/stack as part of my organization. How do I incrementally migrate to\nGraphQL?This is one of the places where GraphQL really shines. You need not move everything over at one\npiece. Here are some steps which might help.\nFirst, build a Datagraph for your entire business without worrying about the underlying\nlogic/implementation. But don't worry too much since you can always evolve this over time.\nNext, implement resolvers for every part of the schema in such a way that at phase 1, you just\nwrap your existing infrastructure with GraphQL. For instance, if your services use SOAP, you can\nadd a GraphQL layer on top of it and calling that can all the SOAP service underneath and the\nclient need not worry about it. You can use something like\nGraphQL Mesh or SOFA which can help in\nabstracting these. There is a good blog post on how to migrate from REST to GraphQL\nhere.\nChange the client implementation one by one to call the GraphQL gateway instead of the legacy\nservice.\nNow that you have GraphQL working in your ecosystem, you can incrementally move away from legacy\nimplementations like SOAP without having to worry about how it will affect the clients\nprogressively, one component at a time to use a native GraphQL implementation.\n\nWhile this is one possible approach, this is not the only approach. There are a lot of other ways in\nwhich you can take this one step at a time without worrying about the legacy code you have.How do I secure my GraphQL endpoint?While the GraphQL spec itself does not recommend any specific way to do this and leaves it to the\nperson implementing it, you can either use JWT, Cookies, Sessions and so\non like you normally would when authenticating through other mechanisms.How do I enable authorization to my GraphQL fields or schema?This is very powerful in GraphQL since you can do a authorization at a very fine-grained level be it\nat the type level or at the field level. You can read\nthis blog which suggests\nvarious ways in which you can do authorization.You can also use libraries like GraphQL Shield\nwhich offers powerful middlewares to do this. But remember that authorization does come with\nattached cost since you are running a specific logic in/before your resolvers for all the fields\nwhich you want to authorize.One often overlooked way is the use of\ndirectives to do authorization, one example\nof which is mentioned in\nthis\nblog and this is very powerful and declarative. This way, you can specify the scope and add the\ndirective to the respective fields in your SDL and it can do the job for you.How do I enable real-time applications like Chat, auto-updates and so on in my application with\nGraphQL?There are some options currently to do this.\nThe first would be to use\nGraphQL Subscriptions which is part of the\nspec. You have to register the subscriptions upfront and also have support for Websockets if you\nwant to do this.\nAnother way is to do periodic long-time polling which can work at a small scale keeping your\napplication stateless.\nAn another way is to use\nlive queries\n\nEach option comes up with its own set of advantages and disadvantages again. Just remember that it\nis not often possible to keep your application stateless if you want something like Subscriptions.\nSo, make sure you manage the state well and plan for failures and scaling your app.And if you are new to subscriptions, you can probably\nwatch this to get an idea about the\nbasics of how subscription works.What can I even do with introspection?Introspection is typically used by the tooling to\nunderstand your GraphQL types and schema. For instance, tools like\nGraphQL Voyager can introspect your schema and build\namazing graphs, and almost all extensions built around GraphQL leverage this power to understand\nyour schema, types and everything around it.Note that, it is recommended by experts to have introspection disabled in production due to security\nand performance reasons.How do I do tracing of all operations in GraphQL?There are various ways in which you can do this.\nIf you want to do this on your own, you can send traces or contexts from within the resolvers\nusing the Jaeger/OpenTelemetry\nSDKs and send all the information manually for tracing.\nOpenTelemetry has recently made support for GraphQL available. You can find it\nhere\nBut if you find yourself using the Apollo Stack, Apollo comes with its own tracing options like\nApollo Tracing and you can read about it\nhere\n\nJust remember that Tracing will cause a lot of performance overhead, and it is highly recommended to\nhave it off unless otherwise needed or probably use it only for specific layers of concern.How do I handle errors gracefully?Again, there are a lot of ways to do this.\nIf you use the Apollo stack, you can use the apollo-errors package as documented\nhere\nIf you use express-graphql or want to use graphql-js natively, they expose error functions as well\nbased on\nGraphQLError and can\nalso use GraphQL extensions to augment with custom payload like error codes and so on which what\nyou typically do when using servers like graphql-helix.\n\nNow, this is the case since GraphQL does not have any dependence on the transport layer and thus\nstatus codes like 200, 400 or 500 may not make sense unless they are part of the response and the\nspec does not prescribe a specific way to do this as well.Is GraphQL related to Graph databases in some way?While GraphQL encourages you to think of your entire data as graphs of connected information since\nthat would give a better insight into how to structure your schema leading to a unified data graph,\nit has no relation with Graph databases by itself since Graph databases act as a way to represent\nand store data in underlying storage systems to allow for fast traversal, walking and retrieval.But, that being said, GraphQL and Graph Databases do have a lot of synergy between them. You can\nread about that here and\nhere since its all about\nestablishing the data schema and its relationships.When exposing REST APIs to end users, I used to bill users based on API calls made. How do I do\nthis for GraphQL?This can be a challenging problem cause in GraphQL, it's the clients which decide what to\nquery/mutate and the server might not know that upfront unless you are using something like\npersisted queries.And here, the CPU consumed can depend on the level of nesting of the queries, the operations which\nyour resolvers do and so on making it difficult to estimate the costs upfront. You can find a\ndetailed blog about this\nhere.\nOne way to handle this only allow persisted queries and approve them and assign costs to them\nupfront, but this can get tricky to manage over the long run as number of queries and mutations\nincrease.\nAnother way is to use custom cost directives as in\nthis package manually specifying the complexity\nand cost and using that to bill your APIs\n\nThis is relatively a new area and still under exploration. For instance, Dgraph bills for Slash\nGraphQL based on the nodes accessed as mentioned here which can be\nvalid for databases using GraphQL but not necessarily for GraphQL api by itself.Here are some other resources which hosts FAQs on GraphQL as well\nApollo GraphQL FAQ\nGraphQL Org FAQ\nHowtographql FAQ\n\nAnd there are more. Just google for it.Hope this was informative. Do you have any question which I have not covered in this list or are you\nlooking for some help? Let me know by reaching out to me @techahoy.And if this helped, do share this across with your friends, do hang around and follow us for more\nlike this every week. See you all soon."}},"/blog/graphql-geo-strike":{"title":"Open source FPS with Apollo GraphQL — GeoStrike (Alpha)","data":{"":"TLDR: We've built a multiplayer shooter and used Apollo's GraphQL subscriptions to keep game\nstate in sync at a very high frequency. Here's our impressions! Tools used:\nAngular-cesium,\nApollo Angular, CesiumJS,\nAngular Go Play: geo-strike.com","first-why#First, Why?":"Well, to put it simply, because we can!Instead of working hard on creating a special serializable, efficient but also unreadable, strict\nand esoteric binary protocol, we decided on going with the well-defined, readable and flexible\nGraphQL based API, and improve on it, if needed.Turns out we can manage synchronization of player positions, state and actions across all clients\nquite easily!","the-game#The Game":"There are two ways you can understand our challenges:\nGo and play the game — Feel free to open the network tab on the dev tools\nand look at the subscriptions websocket frames.\nRead what our game is all about.\n\n\n\nFor those of you that have not played the game (yet!) I'll explain a bit what it is.Our game is a multiplayer shooting game that is taking place in the vicinity of the Times Square.\nThe game mode is a \"team deathmatch\" battle where you spawn on the map with your team, and you need\nto find and shoot the other team's players. The winning team is the one that stayed alive while the\nother team's players are dead. If you die, you can only view the rest of the game from a bird's eye\nview.\n\nWe use CesiumJS — a Google Earth like, open source, mapping engine — as our scene, so when I say the\ngame takes place in the Times Square, It's an actual representation of the Times Square with the\nbuildings being streamed to the client using Cesium's 3d Tiles. As a matter of fact, there is\nnothing keeping you at the Times Square only, you can wonder off to anywhere on earth. Keep in mind\nthat you will be able to see buildings only in Manhattan.","real-time-state-synchronization#Real-Time State Synchronization":"Because the game is a multiplayer shooter, we need to synchronize the multiple players position,\norientation and state at a rate that the user would not feel “lag”.In order to do just that, we decided that our game server will be the only source of truth. It keeps\neach game in a simple map in memory so resolving this data whenever asked should be as quick as it\ngets. Next we wrote a small GraphQL schema that defines our Game entity.It ended up looking like so:\n\nSome parts of this graph will change very rapidly (~10 times a sec) and some parts of it will change\nrarely. Getting to this realization we decided to expose this graph with both Query type for less\nfrequently changed data and Subscription type for higher rate changes.This gives the client the flexibility to decide what parts of the data graph he needs to be steamed\nto it.In our game, this subscription query turned out to be the only parts we need updated frequently:\n\nAt the beginning we went with the naive implementation and set things up so that we will get any\nchange made by any client as it happens. Basically publish on the mutation resolver. But we quickly\nrealized this is not a good approach as this is not very scalable and we, quickly over-stress our\ngraphql server.The approach we decided on taking is usually referred to as “game tick”. We set up a timer that\ntriggers every 200ms and publishes the game state to the gameData subscription. This was one of the\nmost significant changes we made to allow for low latency, in our state synchronization process, and\nit was done with a couple lines of code, thanks to the way GraphQL subscriptions work.\n\nNot only that we were able to reduce latency, we were also able to scale the number of players quite\neasily.","reflecting-state-changes-on-the-map#Reflecting State Changes on the Map":"All we had left is handle those high frequency events on the client and have it work well (e.g.\nwithout conflicting or lagging) with the other of the data operations.But for those challenges, Apollo and angular-apollo had us covered! Apollo client handled the\nstate subscription and updated the normalized client store seamlessly.angular-apollo exposes the state as a Rx Observable which allowed us to plug that stream to our\namazing angular-cesium framework and have the players magically move and update on a 3d scene\nrendered with CesiumJS!","not-just-one-subscription#Not Just One Subscription":"As I've mentioned above, we are publishing the game state every 200ms which is quite good for\npositioning players, but there are events on our game that cannot tolerate this kind of delay and\nstill feel good to the user.After analyzing our graph, we determined that there are two such events. Shooting (obviously) and\ngame state notifications. To handle those subscriptions on a ASAP manner, we've simply added two\ndifferent subscriptions that the client should subscribe to. This makes sure that as soon as someone\nshoots, we will play the shooting sound according to his relative location on all other clients, and\nas soon a player is killed, all other players will get a notification indicating that.","further-improvements#Further Improvements":"As our game is played on the same size scene as our own earth, we cannot help but thinking of future\ngame modes where whole armies could play one against the other to take over / save the world!This kind of massive multiplayer online game calls for some next level optimizations.For instance:\nOptimize the amount of data sent to each client by filtering players state based on the player's\ncurrent position in the world.\nOptimize the payload size by converting GraphQL responses to\nGoogle's Binary ProtoBuff.\nUse Apollo Engine's dynamic persistent queries to optimize the data that should be sent to our\ngame server.","who-are-we-you-ask#Who Are We, You Ask?":"This game is the product of a collaboration between Webiks, a software\ndevelopment company that specialize in high-end data analysis and real time situational awareness\nweb based applications. And The Guild, a group of freelance developers, open source\ncontributors and the creators of angular-cesium.If you are interested in other non-graphql challenges we faced in this project, Omer, the CEO of\nWebiks wrote a blog post that showcases all of it.Oh, and it's all open source! Come over, star and contribute!Thanks for Reading!"}},"/blog/graphql-hive-improvements-in-schema-registry":{"title":"GraphQL Hive - Improvements in Schema Registry","data":{"":"We are excited to announce the implementation of a new and improved schema registry model. This new\nmodel is designed to provide you with a more optimized workflow and an improved user\nexperience.It is important to note that access to the old schema registry model will be discontinued in a few\nmonths' time. We strongly recommend that you switch to the modern model as soon as possible to\ntake advantage of its many benefits.\nThe steps to switch can be found in the settings of your project.\nIn comparison to the old model, the new model has superior defaults, follows best practices, and has\na streamlined workflow. A comparison table available in the settings of your projects will help you\nunderstand the differences between the two models.\n\nOne of the most notable improvements in the new model is the availability of the delete feature.\nWith the modern model, you can now delete a schema from the registry with ease. This is a feature\nthat was not available in the old model.In conclusion, we are confident that the new schema registry model will provide you with a more\nefficient and effective workflow. If you have any questions or concerns about the transition, please\ndo not hesitate to reach out to us. We are here to assist you every step of the way."}},"/blog/graphql-hive-preview":{"title":"GraphQL Hive - Manage Your GraphQL API Workflow","data":{"":"Today, we're happy to announce\nGraphQL Hive -\na registry of schemas to manage, safeguard and optimize your team's workflows when deploying\nGraphQL services. Hold your horses, we're not publicly launching it yet, it's only the start of\na beta testing program we give out today. Sign up for early access!","short-introduction#Short Introduction":"GraphQL Hive is a registry of schemas with many additional features to enhance your day-to-day work\nwith GraphQL.We think of GraphQL Hive as a beehive where instead of honey, GraphQL Schemas are being managed and\nproduced.GraphQL Hive will be released in two forms: An open-source collaboration tool and a hosted and\nmanaged service. That is in order we can support any type of GraphQL workflow, including custom\nworkflows and on-premise needs.\nAlso, just like the bees, we're continuously working hard (or hardly working) to ship new\nfeatures.","all-schemas#All Schemas":"GraphQL Hive supports regular GraphQL, Apollo Federation and Schema Stitching services. In a\nlater release we also aim to support other types of schemas, like open-api, gRPC, SOAP and others\nthat are not originally GraphQL thanks to the power of our\nGraphQL Mesh library. That is in order that you will be able to enjoy\nall the powerful features from GraphQL Hive, even if you don't use GraphQL.","registry-but-not-only#Registry but Not Only":"Our roadmap includes monitoring, safe-listing of operations, breaking change detection, changelogs\nand many others. Our next task on the list is to support persisted queries for most GraphQL clients.\nLet us know what you wish to see in GraphQL Hive!All of that to get a clear picture of how the GraphQL APIs are being developed and consumed.","request-for-early-access-today#Request for Early Access Today!":"If you're interested to try it out and give us feedback, please visit\ngraphql-hive.com\nand sign up for the early access program. The benefits are that you will get to work closely with\nus, while we review your use-cases and workflows and make sure GraphQL Hive supports you in the best\nway possible!"}},"/blog/graphql-cli-is-back":{"title":"GraphQL CLI is back!","data":{"":"","tldr#TL;DR;":"GraphQL CLI is a popular command-line tool providing\nvarious tools for creating and maintaining GraphQL based applications\nPrisma recently transferred the project to The Guild\n— and we completely rewrote it and closed over 100 issues\nWe've already fixed and added many commands, but we are looking to learn and integrate with\ntools and companies across the ecosystem!\nYou can now generate a full stack working app, from a GraphQL schema model, in 2\nminutes using the init+generate commands!\nThis is an alpha phase — we want your feedback, as a user and as a tool creator — Please\ncreate an issue and\njoin our Discord channel","overview#Overview":"The GraphQL CLI provides:\nHelpful commands to improve your daily workflows, from starting a project to maintaining it for\nthe long run\nRich ecosystem and compatibility with libraries, editors and IDEs based on a unified\ngraphql-config\nA powerful plugin system to extend GraphQL CLI with custom commands — supported by the community\nand The Guild\n\n\nThe main target of the GraphQL CLI is to provide a default entry point for the community to use\nproven techniques for building and deploying GraphQL enabled applications while being vendor\nagnostic.\nAdvanced developers and tool creators can extend\ngraphql-cli to provide additional capabilities while still\nbenefiting from a robust set of default commands for daily use — We want to use the CLI to encourage\nopen collaborations between different tool creators.","history#History":"Over the years the GraphQL ecosystem flourished and evolved towards more production-ready use cases\nwith a large number of active community packages available.GraphQL evolved thanks to the large community and the many supporting libraries it has created.The GraphQL CLI has become a place for the community to share ideas and best practices across\ndifferent solutions and libraries thanks\nto the push from Prisma.The Guild took over GraphQL CLI\nto continue on that promise:\nMaking it as easy as possible create and deploy GraphQL based applications\nMaking it easier to maintain production-grade, scalable GraphQL applications\n\nAll of that while:\nKeeping the CLI updated with the latest solutions and practices\nMaking it extensible and configurable without any solution bias — any approach and architecture\ncould easily integrate and benefit from the CLI\nKeeping the industry leading, long term open source library maintenance standard that The Guild is\nknown for","try-it-out-today#Try It Out Today":"We've already refactored most of the code, created a new structure, closed and fixed all the known\nissues and released a new alpha version.Install new version (follow the latest alpha in the\nreleases page):\n\nCreate a new project with GraphQL CLI by running:\n\nGraphQL CLI will guide you and after only few seconds, your project will be ready to use!","end-to-end-type-safety#End-To-End Type Safety":"Code generation + end-to-end type safety is a hot topic nowadays. Thanks to tools like\nGraphQL Code Generator we're able to produce flexible code\nfor both backend and frontend, just from GraphQL Schema and Operations with Fragments.In GraphQL CLI, you get it out of the box by running:\n\n\nDiscover what can be generator on GraphQL Codegen website.","production-ready-graphql-backend#Production Ready GraphQL Backend":"Thanks to integration with GraphBack, you're able to produce an entire\nData Base, GraphQL schema with operations and strongly typed resolvers.\n\n\nTake a look at GraphBack website to learn more.","bulletproof-your-graphql-api#Bulletproof Your GraphQL API":"GraphQL CLI comes with most of the features of\nGraphQL Inspector.With just few simple commands you're able to:\ndetect breaking or dangerous changes\nvalidate Operations and Fragments at build time\nanalyze the usage of GraphQL Schema (unused types and fields)\nfind duplicates and similar GraphQL Types\nserve faked GraphQL schema\n\n\n\n\nVisit GraphQL Inspector docs.","this-is-just-the-start#This Is Just the Start!":"The GraphQL CLI has been rewritten in order to make it extremely customizable and extensible.Our goal is to make sure that any tool can work and benefit from this setup.The CLI offers freedom for anyone to create any command that will extend their workflows by creating\nseparate library. Alternatively you can open a conversation about new command that can be included\ninto our supported set of commands.If you prefer to use all the Apollo toolings and products, AppSync's solutions, Prisma, OneGraph,\nHasura, Postgraphile or any other tool — we want to make the GraphQL CLI the best supporting tool\nfor your stack.\nWe won't impose any choices on the users. We want the community to lead and have template\ngenerators for any technology.\nThis project is completely open and free from any bias, and we are open to any feedback and\ncollaboration with anyone from the community. Please reach out!","example-use-cases-of-graphql-cli#Example Use Cases of GraphQL CLI":"The CLI gives you the ability to build a base template with your favorite stack and tools.Templates can be based on graphql.js, Apollo, Nexus, TypeGraphQL or anything other framework.\nCreating a custom template may help to enforce a specific structure that fits your product and\ncompany.The CLI comes with two default templates that provide a seamless starting point for both backend and\nfrontend, both could be pushed to production in a short time period.Additionally, for existing applications, the CLI will support migrating existing databases or REST\nAPI to GraphQL.","production-ready-graphql-app-in-seconds#Production-Ready GraphQL App in Seconds":"Or \"Making GraphQL easy — From nothing to a full production-ready app in 2 minutes — with any\nstack!\"\"\nThere are many great GraphQL boilerplate repositories on available Github.But when using those, it is often hard to adjust those to real business cases.As an alternative to sample apps, developers can rely on frameworks that provide a high level of\nabstraction.But technologies that offer rapid application development might often come at the cost of the\nmaintenance and flexibility that can seriously limit the extensibility of your application server.\n\nWe believe that making it easy to start with GraphQL is extremely important, but without sacrificing\nother factors like extensibility, scalability and wider control.\nSimple shouldn't equal bad architecture\nGraphQL CLI addresses this very important problem in the core by utilizing two main concepts: code\ngeneration and rich ecosystem of base templates.The graphql init command is trying to address three simple questions:\nCan we build an application template that can offer production-ready capabilities and yet is\nsimple enough to work without extensive learning?\nCan we provide our data model as input to the GraphQL engine and benefit from autogenerated data\naccess methods?\nCan we use the same techniques for an existing application and generate partial models?\n\n\nYou can think of it as a smarter create-react-app, that works on a full-stack and understands\nyour data model.\nWe are calling leading boilerplate creators and frameworks to collaborate with us. We can help you\nexpose your boilerplates also as templates for the init command.We would also love feedback from internal infrastructure teams from companies who wish to create\ntheir own best practices and guidelines.For more information please refer to\nhttps://github.com/aerogear/graphback","one-config-to-rule-them-all--graphql-config#One Config to Rule Them All — GraphQL Config":"At the heart of a project created using GraphQL CLI is the GraphQL Config file. It lets the CLI\nknow where all the GraphQL parts are.Config is essential for CLI templates and for the command creators that can utilize its\nextensibility to save additional metadata. Thanks to graphql-config,\nthe CLI can provide seamless support for every extension and streamline development experience on\ntop of the GraphQL CLI generated projects and corresponding templates.For more information about GraphQL Config, you can\nclick here to learn more.","migration-from-3xx-to-4xx#Migration from 3.x.x to 4.x.x":"We have provided a complete migration document for existing users who wish to update to the latest\nversion of the CLI. Please keep in mind that CLI is still in the alpha phase and we are looking for\nthe feedback before officially releasing a final version of the CLI.Please follow\nhttps://github.com/Urigo/graphql-cli/blob/master/MIGRATION.md\nmigration guide.","help-us-to-shape-the-graphql-ecosystem#Help Us to Shape the GraphQL Ecosystem":"Start using the GraphQL CLI today!Even though we are in an alpha phase, the CLI is fully usable and ready for the community to adopt\nit.Our team is open to any suggestions and ideas for new commands.\nWe will support and answer all your questions on GitHub\nand on our Discord channel."}},"/blog/graphql-mesh-subscriptions":{"title":"Webhooks as GraphQL Subscriptions using GraphQL Mesh","data":{"":"GraphQL Mesh lets you query any data source and protocol with GraphQL by using powerful handlers\n(Swagger/OpenAPI, gRPC, SOAP and others...) Today we are happy to announce that GraphQL Mesh now\nallows you to consume your existing HTTP Webhooks as GraphQL Subscriptions!Not only that, but you could extend the GraphQL Subscriptions result, so you could subscribe to a\nwebhook and get back an enriched data result, with data from other sources that don't have push\ncommunication abilities.And it's also possible even if your webhooks don't have any schema!Let's see how to create a GraphQL Subscription from a Webhook, once without a schema and once\nautomatically from an OpenAPI schema.\nWe are already able to consume our existing REST APIs in GraphQL Mesh even if they don't have any\nschema by using our JSON Schema Handler. See more","add-a-new-field-to-our-existing-configuration-for-an-http-webhook#Add a New Field to Our Existing Configuration for an HTTP Webhook":"In the following example configuration, we have a regular GraphQL Mesh configuration for schemaless\nREST API.\n\nAssume that we point our REST API to send HTTP requests to our Mesh server's /webhooks/todo_added\npath, so we need to configure Mesh to listen to that path.\n\nUnder serve we define the port we want Mesh to listen to and add a handler in a declarative way\nwithout a single line of code. pubsubTopic is the unique name for that webhook. This topic will\nreceive upcoming HTTP requests so that JSON Schema handler will consume it as a GraphQL\nSubscription.Let's define a new field under Subscription field under operations in the handler level;\n\nNow we have a todoAdded field that listens to a webhook through Mesh's PubSub instance and this\nfield has a return type generated based on todo.json sample response.You can start mesh serve and start listening for that webhook by the following GraphQL operation;\n\n\nYou can find a complete working example on GitHub","other-methods-for-subscriptions-such-as-rabbitmq-or-kafka#Other Methods for Subscriptions Such as RabbitMQ or Kafka":"It is possible to configure Mesh to handle other schemaless subscription solutions like RabbitMQ and\nKafka using JSON Schema handler but this is the topic of another blog post.","generating-graphql-subscriptions-from-openapi-callbacks#Generating GraphQL Subscriptions from OpenAPI Callbacks":"Mesh can listen to webhooks through a PubSub engine easily. Mesh will generate the necessary typings\nand subscriptions fields connected to your PubSub engine from the OpenAPI schema. You only need Mesh\nto know what path the server should listen to like below;\n\nIn this example configuration, we assume that we have an API server running on 4001 port and it has\na webhook that will forward requests from /callback path to http://localhost:4000/callback topic\nbecause OpenAPI Handler uses callback url as PubSub topic name. If you want to have a more\ncustomized way of handling incoming webhook requests, you can always write your own Express handler\nand define it instead of pubsubTopic. You will find Mesh's PubSub engine under the request\nobject as request.pubsub.You can check\nthis example for more","now-you#Now You":"We would love to hear your use cases and feedback to make Mesh better and more powerful! Feel free\nto submit issues on GitHub to share your ideas or you can also join our community channel on\nDiscord!"}},"/blog/graphql-modules-v1":{"title":"The New GraphQL Modules","data":{"":"","history-lesson#History Lesson":"GraphQL Modules showed up on NPM almost 3 years ago, but now we\ndecided to rewrite it from scratch. Throughout those years the library improved by a lot of thanks\nto the community and the companies we as The Guild worked with.\nWe tried to implement new ideas and revamp the library without touching the core.\nThat was until now, we decided to finally change the fundamentals of GraphQL Modules according to\nthe collected feedback from our users.","new-major-version#New Major Version":"We were planning a new major release from quite some time now and after few months of work, it's\nfinally available!\nMuch richer error messages\nMore advanced and much more flexible Dependency Injection\nFlat structure - one application, many modules\nTesting utilities\nFunctions instead of classes\nBetter performance\nSimpler codebase\nIn general, better Developer Experience\nGraphQL Codegen support with GraphQL Modules preset\n\nWe know those are just words, but we've been using it for a while, and we love it!","single-package#Single Package":"We decided to merge two existing packages @graphql-modules/core and @graphql-modules/di into a\nsingle package graphql-modules. There's no regression in terms of bundle size, because core was\nimporting di anyway.\n\nMaking GraphQL Modules a single package should improve the developer experience.","flat-structure#Flat Structure":"In 1.0, we changed the structure of GraphQL Modules to be flat. We also added Application level\nthat represents the root of your GraphQL API.\n\nYou no longer need to define imports and strict dependencies between modules, since they are all\nflatten and merged together by the Application.","improved-dependency-injection#Improved Dependency Injection":"The previous version was lacking proper abstraction, it was extremely hard to test and in general\nvery strict.Thanks to the flat structure of GraphQL Modules we were able to rethink the implementation of\nDependency Injection. What are the benefits?\nSharing Services is\nnow easier than ever, all you need to do is to set global: true flag in @Injectable decorator.\nThere's a space for abstraction.\nEach Module has its own Injector that has Injector of an application as a parent.\nOnly two kinds of scope: Singleton and Operation.\nWe think it's simpler this way and the naming is much more intuitive.\nRicher error messages,\nnew DI gives you more details about what went wrong.","stronger-type-safety#Stronger Type-Safety":"GraphQL Modules expose a global namespace called GraphQLModules, so there's no need to pass the\nsame signature over and over again as part of generic types of different APIs.Context is global and shared across modules and application which means you can define it once, and\nit applies automatically everywhere.Use and extend GraphQLModules.GlobalContext like this:\n\nWe created a special GraphQL-Code-Generator preset for GraphQL Modules.It generates a complete, unified, type signature for your schema, and sub-files per each module,\ncontaining only the GraphQL types declared/extended in your specific module.To get started,\nfollow the instructions in graphql-code-generator.com website.","shared-context#Shared Context":"In v0, you could create a context per each module. In v1, context is external for GraphQL-Modules,\nand it's not directly in use. You can do whatever you want with that, and just access it in\nGraphQL-Modules if you need, but we no longer require you to do specific things with your context.","dynamic-singletons---executioncontext#Dynamic Singletons - @ExecutionContext":"Execution Context means the context of execution of GraphQL Operation. In short, it's the context\nvalue created by your GraphQL server.Singletons can't directly access Operation scoped services, meaning they probably can't also\ndirectly access the context object created per each operation. Directly.Thanks to @ExecutionContext decorator, every Singleton provider gets access to the GraphQL Context\nand the Operation scoped Injector.\n\nYou gain a lot in terms of performance, because the Data class is instantiated only once and used\nin many operations.","testing-kit#Testing Kit":"GraphQL Modules provides\na set of utilities for testing your modules\nand also for more granular testing of module's smaller units, like providers and middlewares.To access the testing utilities, import testkit object from graphql-modules package:\n\nThe testkit object and its API will grow over time, we expect to implement more and more useful\nfeatures in upcoming releases.","migration#Migration":"The v1.0 is a total rewrite, there are of course breaking changes.We prepared an entire chapter in documentation that covers pretty much all breaking changes and new\nfeatures. Please read \"Migration from v0.X\"\nchapter and give us a feedback.The documentation of 0.x version of GraphQL Modules\nis available under legacy name.\nThe same applies to the codebase, there's the\nlegacy branch on the repository.","oh-and-happy-new-year#Oh, and Happy New Year!":""}},"/blog/graphql-over-sse":{"title":"GraphQL over SSE (Server-Sent Events)","data":{"":"","introduction#Introduction":"You've probably been faced with a challenge of making sure your app is up-to-date at all times\nwithout user interaction. Yes,\nWebSockets are a great fit! But, what\nif I've told you there is something else? Something \"simpler\" and\nwidely supported? I humbly present to you:\nServer-Sent Events.Server-Sent Events (abbr. SSE) are persisted HTTP connections enabling simplex communication from\nthe server to connected clients. In comparison to WebSockets, which enable full-duplex communication\n(both connected parties can send information at any time), simplex communication is just a fancy\nword for channels that send data in one direction only, in this case from the server to the client.\nYou may think that this is a drawback, at least when comparing SSEs to WebSockets; but, think\nagain - is it really?When subscribing to an information source, you make one descriptive request in order to receive\nmultiple responses. Specifically, when using GraphQL subscriptions or streaming operations (like\nwith\n@defer and @stream directives),\nyou do exactly this - you send one request and expect multiple responses (events) in return. Having\nsaid this, Server-Sent Events seem like a perfect fit!Not only does it fit like a glove, but it even has one more small leverage over WebSockets - it is\nfirewall-proof. If you've used WebSockets extensively before, you must've been faced with a\nsituation where WebSocket connections were declined and you have had absolutely no idea why - yes\nsir, you were bamboozled by an outdated corporate firewall that rejects\nHTTP Upgrade requests crippling\nWebSocket's full potential. However, SSEs are plain ol' HTTP requests whose TCP connection is kept\nalive, they're immune to rogue firewalls.","limitations-with-sses#Limitations with SSEs":"Ah, if the world was only that simple... There are a few limitations when considering SSEs, some of\nyou might've already discovered them, but I'll go over them briefly.","maximum-number-of-open-connections#Maximum Number of Open Connections":"When not used over HTTP/2, SSE suffers from a limitation to the maximum number of open\nconnections, which can be specially painful when opening various tabs as the limit is per browser\nand set to a very low number (6). The issue has been marked as \"Won't fix\" in\nChrome and\nFirefox. This limit is per browser +\ndomain, so that means that you can open 6 SSE connections across all the tabs to\nwww.example1.com and another 6 SSE connections to www.example2.com. (from\nStackoverflow). When using HTTP/2, the maximum\nnumber of simultaneous HTTP streams is negotiated between the server and the client (defaults to\n100).\nWebAPIs | MDN","browsers-eventsource#Browser's EventSource":"Not only are you not able to customise the HTTP request by providing custom headers or changing the\nrequest method, but the\nEventSource.onerror event handler\nwill tell you nothing about why the request failed, no status code, no message, no body - you're in\nthe dark.","how-to-graphql-over-sse#How to GraphQL over SSE?":"If you've done your Googling, you probably came across hot discussions like\n\"Does HTTP/2 make websockets obsolete?\"\nor\n\"WebSockets vs. Server-Sent events/EventSource\".\nOr even the somewhat harsh\n\"@deprecate WebSockets: GraphQL Subscriptions using SSE\"\narticle from WunderGraph.With all this insightful talking and knowledgeable discussions, you'd expect integrating SSE in your\nnext project would be easy? You should have options, not be limited to Socket.IO or WebSockets,\nright? Absolutely, it is easy and you do have options!","bye-bye-limitations-hello-graphql-sse-#Bye Bye Limitations, Hello graphql-sse 👋":"I am happy to introduce the lost plug-n-play, zero-dependency, HTTP/1 safe, simple,\nGraphQL over Server-Sent Events Protocol\nserver and client.Aforementioned limitations are taken care with a specialised SSE client (inspired by the awesome\n@microsoft/fetch-event-source) and two separate\nconnection modes:\nthe HTTP/1 safe \"single connection mode\"\nthat uses a single SSE connection for receiving events with separate HTTP requests dictating the\nbehaviour, and\nthe HTTP/2+ \"distinct connections mode\"\nthat uses distinct SSE connections for each GraphQL operation, accommodating the parameters in the\nrequest itself.graphql-sse is a reference implementation of the\nGraphQL over Server-Sent Events Protocol aiming to become a part of the GraphQL over HTTP standard.","how-can-i-try-it-out#How Can I Try It Out?":"I thought you'd never ask! Here is how:","install#Install":"","create-a-graphql-schema#Create a GraphQL Schema":"","start-the-server#Start the Server":"","with-http#With http":"","with-http2#With http2":"Browsers might complain about self-signed SSL/TLS certificates.\nHelp can be found on StackOverflow.","with-express#With express":"","with-fastify#With fastify":"","use-the-client#Use the Client":"","want-to-find-out-more#Want to Find Out More?":"Check the repo out to for\nGetting Started quickly with some\nRecepies for vanilla usage, or with\nRelay and Apollo Client. Opening\nissues, contributing with code or simply improving the documentation is always welcome!I am @enisdenjo and you can chat with me about this topic on the\nGraphQL Discord workspace anytime.Thanks for reading and happy coding! 👋"}},"/blog/graphql-modules-auth":{"title":"Authentication and Authorization in GraphQL","data":{"":"After a few years of working with GraphQL, as open-source developers and as infrastructure team in\nlarge enterprises, we've learned some lessons about GraphQL, and how to authenticate and authorize\nGraphQL API.Authentication and authorization should be simple, because for most cases, it's just a piece of code\nthat we wish to run before letting users access certain resources.In this article we'll go through all the different ways of implementing authentication and\nauthorization, the benefits and downsides to each one, and offer a solution that we believe is the\nbest philosophy to do so.","authentication--authorization#Authentication / Authorization?":"I found\ngood answer in StackOverflow\ncovers the main differences between authentication and authorization:\n\nIn this article, I'll cover the difference between authentication and authorization with GraphQL\nAPIs, explain how to implement them with GraphQL server, and with the\nGraphQL-Modules framework.We learned that a good implementation for GraphQL authentication has the following features\nregarding authentication:\nYour authentication implementation should eventually provide the currentUser to the resolvers\nYour resolvers should not know about the authentication logic (separation between the business\nlogic and the authentication logic)\nYou wish to protect only parts of your GraphQL schema, and not all of it.\nYou want to be able to authenticate parts of your schema, on a field level.\n\nAnd the following features regarding authorization:\nYou wish to protect some fields, according to custom rules.\nYou wish to run custom logics that protects parts of your GraphQL schema.\nOur custom rules should not be coupled to a specific resolver.","where-to-put-your-authentication#Where to Put Your Authentication?":"To understand why implementing authentication in GraphQL might be tricky, let's start with the\nfollowing chart:\n\nA request comes from the network, go through an HTTP server (for example, express) — That's #1\nin the chart. Then it goes through GraphQL server, which builds a context, and then it runs your\nresolvers — #2. Then, you have your business logic, that you might want to separate from the\nresolvers, that's #3.Basically, you can implement GraphQL authentication on each part of this chart. But there are\ndifferences between those points that might effect the behaviour of your server, and might limit you\nlater doing some things.Let's focus on the features requirements I mentioned before, and try to understand how the\nimplementation selection might affect you.So let's take #1: If you implement your authentication on #1 (between the network request\nand the HTTP server), you probably does it with express middleware or something similar. The benefit\nin this is the separation between authentication logic and your business logic. But, you can't\nconnect your data from the HTTP request to your GraphQL server, and it might be difficult later to\nget access to the currentUser. It also protects the entire GraphQL endpoint, and not only parts of\nit. So that's nice, but not perfect.Regarding #3: Implementing authentication as part of your resolver code or business logic code\nisn't a good idea. It usually means that your app code knows too much about the authentication, and\nit's probably coupled to it. It might to simpler to implement, but much more difficult to reuse\nlater.And, #2: You can implement authentication between your HTTP server and your GraphQL server, by\nusing the GraphQL context. By implementing a custom context building function, you can access\nthe network request and build your context object, and add currentUser to it. Then, your\nresolvers getting called by the GraphQL engine.From our experience, we can tell that implementing authentication in this part of your GraphQL\nserver gives you control over your authentication flow, if it's done right.In the next chapter we'll dive in, and see how easy it's to implement in with Apollo-Server.","getting-started-with-authentication#Getting Started with Authentication":"We'll start by implementing a simple authentication flow in GraphQL server (using\nApollo-Server 2.0).I'm assuming that you already have your own favorite way to authenticate, whether it's with headers,\ncookies or any other way. In the point of view of the server, we expect to get a token, and we'll\nassume that it comes from the headers for the simplicity.Let's start by creating a simple Apollo-Server instance, with a very simple schema. We'll focus on\nexposing the currentUser as a query field.\n\nNow, let's implement context , and see if we can get a valid user out of the values we get there.\nOur goal in this part is only to validate the token, and try to trade it for a user. If the token or\nthe user are not valid — we don't want to throw an exception here, because that way, our server will\nnot support public queries. So we're just trying to get a user and a token, and return them to\nApollo-Server, so it will use it as the context for our resolvers. If something went wrong with the\nvalidation — we just return null for the user and authToken.\n\n\n\nNote that in a good GraphQL server implementation, the context is built once per request, and\nshouldn't change over time. So they only way to modify it is using the context function that\nbuilds it before the resolver getting called.Now, we can finally implement the resolvers for the server:\n\nThis is a naive implementation, that assumes that the token is valid, because otherwise the\ncontext.currentUser will be null. That leads us to the next steps: implementing guards.To add guards to your resolvers, you can use a simple Middleware approach, and wrap your resolver\nwith a function that checks if context.user is valid, and otherwise, throws an error. You are\ngetting full control over your authentication flow, because you can choose which resolvers to wrap.So let's implement a simple guard, and use it in our server. I also added a public part of the\nschema (Query.serverTime), that should be public, and not effected by the authentication flow. So\nit's not wrapped with our guard.\n\n\n\nGreat! So now our server is authenticated and we can get the currentUser in our resolvers. It also\nprotects only the part of the GraphQL schema that we wanted to protect, and the authentication flow\nis separated from the resolvers, so each resolver does only what it needs.","getting-started-with-authorization#Getting Started with Authorization":"Now that we understand the concept of authentication in GraphQL servers, we can also implement\nauthorization.Implementing Authorization is no different from implementing the authenticated guard we did\nbefore. It's just another guard, or resolver wrapper we can use.Let's add type Article to the schema, and allow creating article only to users with role set to\nEDITOR . It's that simple:","next-level-implementation-with-graphql-modules#Next-Level Implementation with GraphQL-Modules":"If you wish to take your GraphQL server to the next level, and build a scalable, testable and\nreadable server, I recommend to give GraphQL-Modules a try.With GraphQL-Modules, you can separate your schema to smaller pieces, and creates modules that are\nin-charge of small parts of your code. It also provides a resolversComposition feature, that acts\nlike a powerful middleware mechanism, that let you write your modules without knowing about the\nauthentication flow, and just wrap your resolvers with guards in the app-level, so modules are\nindependent and do only what they need, and the app that uses these modules decide which resolvers\nto authenticate.It also super powerful, because you can implement your GraphQL-Module as standalone module, use it\nin multiple applications, and then apply different authentication/authorization rules in each app.To implement the same example above with GraphQL-Modules, you can create a module called auth and\nmove the context building logic to there. Then, create another module called common and the\ngeneral parts, and articles to manage the articles features.","this-way--each-module-is-in-charge-of-a-different-feature-of-our-app#This Way — Each Module Is in Charge of a Different Feature of Our App":"","the-future-of-authentication-with-graphql-modules-and-graphql-directives#The Future of Authentication with GraphQL-Modules and GraphQL @directives":"If you wish to get rid of the resolversComposition wrapping, and use a more declarative way, you\ncan use GraphQL directives to decorate your schema and put the authentication/authorization there.To get started, add the following @directives to your auth module's schema:\n\nThen, you can easily alter your resolversComposition into a function that accepts GraphQLSchema\n, and then check using your schema object, which resolves require which logic, and do a mapping:\n\nThe, you add the directives to your schema declaration:","whats-next#What's Next?":"Another thing we are working on, is having some of your repeated authentication and authorization\nlogic installable through npm!We are working with the creators of the js-accounts\nlibraries to create a GraphQL Modules module out\nof their awesome packages, so you could just add it from npm and extend your server and schema.You can read this blog post to learn to use this library with GraphQL-Modules in a few steps;\n\nAuthentication and authorization is a fundamental part of your GraphQL server.It should be easy and secure to implement and understand how to do that in order to help grow the\nGraphQL communityIn this article we wanted to give you a complete overview of authentication and authorization in the\nGraphQL ecosystem and give you the tools and the knowledge to implement it on your GraphQL servers.Please try all those different approaches and let us know your feedback about the best way for you\nand if we can improve it even further.","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/graphql-over-websockets":{"title":"GraphQL over WebSockets","data":{"":"","graphql-over-websockets#GraphQL over WebSockets":"A couple of years ago, while I was still working at Apollo,\nLee Byron, Rob Zhu,\nDotan Simha and I worked on the\nGraphQL Subscriptions spec and the reference implementation.\n\nDuring that work, we created and merged the\nreference implementation into graphql-js and\ncreated two supporting libraries:\ngraphql-subscriptions and\nsubscriptions-transport-ws. Here is\na talk with deep dive into all the details.\n\nSince leaving Apollo,\nnot a lot of work has been gone into those libraries.\nThat's why I was so thrilled that Denis decided to pick up that\nimportant work and create a new library for the WebSocket Protocol.\n\nWe will support his work of maintaining the library and standardizing it with the GraphQL over\nHTTP working group. This is a part of a lot of exciting work coming up about GraphQL and\nreal-time, so follow us for new things in this space!\n\nDenis will take it away from here!","introduction#Introduction":"At some point in time during your web development journeys, you may've been faced with the challenge\nto add a real-time component. The synonym for realtime in the browser is the WebSocket API.\nThis is how MDN's describes it:\nThe WebSocket API is an advanced technology that makes it possible to open a two-way interactive\ncommunication session between the user's browser and a server. With this API, you can send\nmessages to a server and receive event-driven responses without having to poll the server for a\nreply.\nGoogle Chrome was the first browser to support the WebSocket Protocol, adding support in 2009 - two\nyears before it was officially standardised in 2011. As the need for full-duplex server-client\ncommunications rose, other browsers followed suit.As of today, all major browsers support the WebSocket Protocol - see the\nCan I Use table.","websockets-️-graphql#WebSockets ❤️ GraphQL":"Okay, so, how do I use WebSockets to add support for the\nGraphQL subscription operation? Doing a\nbasic Google search, you'd be faced with a single solution, namely\nsubscriptions-transport-ws. Looking\nthrough the repository, checking recent comments, reading through the issues and open PRs - might\nhave you notice the abundance of bugs and their security implications.\nA summary can be found here.The authors have done a brilliant job, but unfortunately other projects and needs have reduced their\ndisposable time for maintaining and nurturing this well accomplished, yet needy, idea. But, it did\nindeed inspire me to take up their legacy and revitalised it! Having faced various WebSocket\nchallenges with GraphQL myself - I jumped in writing a new library from scratch.With no further ado - I humbly introduce graphql-ws. A\ncoherent, feature-full, zero-dependency, plug-n-play, lazy, simple, server and client implementation\nof the\nnew, security first GraphQL over WebSocket Protocol\nwith full support for all 3 GraphQL operations: Queries, Mutations and Subscriptions. The\nprotocol aims to be standardised and become a part of GraphQL with the help of the foundation's\nGraphQL over HTTP work group.The library is written in TypeScript and the full implementation totals merely ~1000 lines of well\nformatted, commented, code. It leverages modern JavaScript primitives and the well established\npresence of WebSockets.","how-do-i-get-started#How Do I Get Started?":"I am glad you asked! This is how:","install#Install":"","create-a-graphql-schema#Create a GraphQL Schema":"","start-the-server#Start the Server":"","with-ws#With ws":"","with-uwebsocketsjs#With uWebSockets.js":"","with-fastify-websocket#With fastify-websocket":"","use-the-client#Use the Client":"","want-to-find-out-more#Want to Find Out More?":"Check the repo out to for Getting Started\nquickly with some Recepies for vanilla usage, or\nwith Relay and Apollo Client. Opening\nissues, contributing with code or simply improving the documentation is always welcome!I am @enisdenjo and you can chat with me about this topic on the\nGraphQL Slack workspace anytime.Thanks for reading and happy coding! 👋"}},"/blog/graphql-response-caching-with-envelop":{"title":"GraphQL Response Caching with Envelop","data":{"":"","a-brief-introduction-to-caching#A Brief Introduction to Caching":"Huge GraphQL query operations can slow down your server as deeply nested selection sets can cause a\nlot of subsequent database reads or calls to other remote services. Tools like DataLoader can\nreduce the amount of concurrent and subsequent requests via batching and caching during the\nexecution of a single GraphQL operation. Features like @defer and @stream can help with\nstreaming slow-to-retrieve result partials to the clients progressively. However, for subsequent\nrequests we hit the same bottle-neck over and over again.What if we don't need to go through the execution phase at all for subsequent requests that execute\nthe same query operation with the same variables?A common practice for reducing slow requests is to leverage caching. There are many types of caching\navailable. E.g. We could cache the whole HTTP responses based on the POST body of the request or an\nin memory cache within our GraphQL field resolver business logic in order to hit slow services less\nfrequently.Having a cache comes with the drawback of requiring some kind of cache invalidation mechanism.\nExpiring the cache via a TTL (time to live) is a widespread practice, but can result in hitting the\ncache too often or too scarcely. Another popular strategy is to incorporate cache invalidation logic\ninto the business logic. Writing such logic can potentially become too verbose and hard to maintain.\nOther systems might use database write log observers for invalidating entities based on updated\ndatabase rows.In a strict REST API environment, caching entities is significantly easier, as each endpoint\nrepresents one resource, and thus a GET method can be cached and a PATCH method can be used for\nautomatically invalidating the cache for the corresponding GET request, which is described via the\nHTTP path (/api/user/12).With GraphQL such things become much harder and complicated. First, we usually only have a single\nHTTP endpoint /graphql that only accepts POST requests. A query operation execution result could\ncontain many different types of entities, thus, we need different strategies for caching GraphQL\nAPIs.SaaS services like FastQL and GraphCDN started popping providing proxies for your existing GraphQL\nAPI, that magically add response based caching. But how does this even work?","how-does-graphql-response-caching-work#How Does GraphQL Response Caching Work?":"","caching-query-operations#Caching Query Operations":"In order to cache a GraphQL execution result (response) we need to build an identifier based on the\ninput that can be used to identify whether a response can be served from the cache or must be\nexecuted and then stored within the cache.Example: GraphQL Query Operation\n\nExample: GraphQL Variables\n\nUsually those inputs are the Query operation document and the variables for such an operation\ndocument.Thus, a response cache can store the execution result under a cache key that is built from those\ninputs:\n\nUnder some circumstances it is also required to cache based on the request initiator. E.g. a user\nrequesting his profile should not receive the cached profile of another user. In such a scenario,\nbuilding the operation cache key should also include a partial that uniquely identifies the\nrequestor. This could be a user ID extracted from an authorization token.\n\nThis allows us to identify recurring operations with the same variables and serve it from the cache\nfor subsequent requests. If we can serve a response from the cache we don't need to parse the\nGraphQL operation document and furthermore can skip the expensive execution phase. That will result\nin significant speed improvements.But in order to make our cache smart we still need a suitable cache invalidation mechanism.","invalidating-cached-graphql-query-operations#Invalidating Cached GraphQL Query Operations":"Let's take a look at a possible execution result for the GraphQL operation.Example: GraphQL Execution Result\n\nMany frontend frameworks cache GraphQL operation results in a normalized cache. The identifier for\nstoring the single entities of a GraphQL operation result within the cache is usually the id field\nof object types for schemas that use global unique IDs or a compound of the __typename and id\nfield for schemas that use non-global ID fields.Example: Normalized GraphQL Client Cache\n\nInterestingly, the same strategy for constructing cache keys on the client can also be used on the\nbackend for tracking which GraphQL operations contain which entities. That allows invalidating\nGraphQL query operation results based on entity IDs.For the execution result entity IDS that could be used for invalidating the operation are the\nfollowing: User:1, User:2 and User:3.And also keep a register that maps entities to operation cache keys.\n\nThis allows us to keep track of which GraphQL operations must be invalidated once a certain entity\nbecomes stale.The remaining question is, how can we track an entity becoming stale?As mentioned before, listening to a database write log is a possible option - but the implementation\nis very specific and differs based on the chosen database type. Time to live is also a possible, but\na very inaccurate solution.Another solution is to add invalidation logic within our GraphQL mutation resolver. By the GraphQL\nSpecification mutations are meant to modify our GraphQL graph.A common pattern when sending mutations from clients is to select and return affected/mutated\nentities with the selection set.For our example from above the following could be a possible mutation for adding a new repository to\nthe repositories field on the user entity.Example: GraphQL Mutation\n\nExample: GraphQL Mutation Execution Result\n\nSimilar to how we build entity identifiers from the execution result of query operations for\nidentifying what entities are referenced in which operations, we can extract the entity identifiers\nfrom the mutation operation result for invalidating affected operations.In this specific case all operations that select User:1 should be invalidated.Such an implementation makes the assumption that all mutations by default select affected entities\nand, furthermore, all mutations of underlying entities are done through the GraphQL gateway via\nmutations. In a scenario where we have actors that are not GraphQL services or services that operate\ndirectly on the database, we can use this approach in a hybrid model with other methods such as\nlistening to database write logs.","envelop-response-cache#Envelop Response Cache":"The Envelop response cache plugin now provides primitives and a reference in memory store\nimplementation for adopting such a cache with all the features mentioned above with any GraphQL\nserver.The goal of the response cache plugin is to educate how such mechanisms are implemented and\nfurthermore give developers the building blocks for constructing their own global cache with their\ncloud provider of choice.Adding a response cache to an existing envelop GraphQL server setup is as easy as adding the plugin:\n\nIf you need to imperatively invalidate you can do that by providing the cache to the plugin:\n\nThe caching behavior can be fully customized. A TTL can be provided global or more granular per type\nor schema coordinate.\n\nNeed to cache based on the user? No problem.\n\nDon't want to automatically invalidate based on mutations? Also, configurable!\n\nWant a global cache on Redis? Build a cache that implements the Cache interface and share it with\nthe community!\n\nMore information about all possible configuration options can be found on\nthe response cache docs on the Plugin Hub.","what-is-next#What Is Next?":"We are excited to explore new directions and make enterprise solutions accessible for all kinds of\ndevelopers.What if the response cache could be used as a proxy on edge cloud functions distributed around the\nworld, which would allow using envelop as a http proxy to your existing GraphQL server? This is\nsomething we would love to explore more (or even see contributions and projects from other\nopen-source developers).We also want to make other practices such as rate limits based on operation cost calculation as used\nby huge corporations like Shopify available as envelop plugins.Do you have any ideas, want to contribute or report issues? Start a GitHub discussion/issue or\ncontact us via the chat!"}},"/blog/graphql-scalars":{"title":"GraphQL Scalars 1.0 is out!","data":{"":"The GraphQL Specification has theInt, Float, String, Booleanand ID Scalar types by\ndefault. Those scalar types help you identify the data and validate it before transferring it\nbetween client and server. But you might need more specific scalars for your GraphQL application, to\nhelp you better describe and validate your app's data.","validation-using-scalars#Validation Using Scalars":"For example, you have a String field, but you need to validate upcoming or ongoing string data\nusing regular expressions. So you should have this validation on each end; one in the client, the\nother one in the server and maybe there is another on a source. Instead of duplicating the same\nlogic in different parts of the project, you can use EmailAddress scalar type that does the\nvalidation inside GraphQL for you.","serialization-and-parsing#Serialization and Parsing":"The other benefit of using GraphQL scalar types is parsing and serializing while transferring data.\nFor example, you have DateTime data, but it is transferred as String due to restrictions of\nJSON, and each time you receive and pass the data, you have to parse the string and create a\nJavaScript Date instance while also serializing it to string before passing it to the client.\nInstead of having that logic in your implementation, you can just use DateTime scalar and you\nwould work with native JavaScriptDate instances directly like it is one of primitive types such as\nstring, number and boolean.","whats-new#What's New?":"We've recently taken over the maintenance of\nGraphQL-Scalars library from the amazing team of OK-Grow!Since then, we completely rewrote the library using TypeScript, upgraded all dependencies, closed\nall the issues and PRs and increased the number of scalars in the package with new scalars like:\nBigInt(Long) , GUID , HexColorCode , Hexadecimal , IPv4 , IPv6 , ISBN , MAC , JSON\nand more. You can see all scalars in the\nREADME.","mocking#Mocking":"Apollo Server provides mocks built-in scalars such as Int , String , Float , ID and\nBoolean . What if you need same thing for our scalars? So, we provide you mocking functions for\neach scalar in this package. You can add those easily in your server for mocking the schema.","special-thanks#Special Thanks":"Thanks to OK-Grow for creating this package,\nadriano-di-giovanni for being generous and giving us the\ngraphql-scalars name on npm, to\nSaeris for letting us take other scalar implementations from his fork,\nstems for their\ngraphql-bigint package,\nabhiaiyer91 for his\ngraphql-currency-scalars package and\ntaion for his\ngraphql-type-json."}},"/blog/graphql-tools-v6":{"title":"GraphQL Tools - next generation schema stitching and new leadership","data":{"":"We are happy to announce the new GraphQL Tools v6 together with\nthe new documentation website.As the Guild, we recently took over the popular GraphQL Tools repository from the team at Apollo,\nwho created this amazing library. We released v5 as a temporary stopgap release with a lot of\nbug-fixes around schema stitching and are now proud to reintroduce graphql-tools to the community\nwith v6.During that process we've reviewed and fixed hundreds of issues and pull requests and reduced the\nnumber of issues to a few that are being reviewed and processed speedily.The low number of issues is despite the fact that the package is widely used with quick issue triage\nand turnaround -- a new standard for open source maintenance that we apply to\nall of our open source tools.The original GraphQL Tools enabled users to:\nbuild “SDL-first“ GraphQL schemas by attaching resolvers (and the other non-SDL GraphQL\nentities) to type definitions written in graphql schema definition language.\nmodify schemas simply by annotating them with reusable schema directives\ncreate and transform “remote“ GraphQL schemas , i.e. executable GraphQL schemas that proxy\nqueries to a remote GraphQL endpoint.\n“stitch“ together multiple subschemas by combining subschemas into a new schema, adding new\nfields, and enabling delegation of all or some of the new fields to existing subschemas.\nmock schemas by defining a default resolver on a per-type basis\n\nYou asked and we listened! With the integration of the Guild's\ngraphql-toolkit,\nmerge-graphql-schemas, and the\ngraphql-import libraries into a new graphql-tools\nmonorepo, The new GraphQL Tools does all of the above and more:\nmerge schemas prior to schema creation by merging typeDefs and/or resolvers\n(merge-graphql-schemas)\nimport schemas within.. (previously\ngraphql-import).\noptimize client side queries with relay compiler (relay-operation-optimizer)\nload resolvers and type definitions from your file system using glob expressions\nmuch, much more ...","new-monorepo-structure#New Monorepo Structure":"The new GraphQL Tools is split into different packages by functionality under the @graphql-tools\nscope. You can pick individual packages according to your needs instead of having one large package\nwith unused functionalities in your project, which will significantly decrease bundle size. When\nbundle size is not an issue, you can still directly import all functionality directly from the\ngraphql-tools package...Some functions have been renamed to avoid conflicts between packages - see the migration guide for\nfurther help in upgrading.\n\nLet's talk about the improvements we have made in each area.","building-sdl-first-graphql-schemas#Building \"SDL-First\" GraphQL Schemas":"The primary use case of the graphql-tools library is still the makeExecutableSchema function that\nenables users to start building their schemas directly from type definitions. This approach makes\nthe SDL the single “source of truth“ for the entire graph.Under the hood, as before, makeExecutableSchema calls out to upstream graphql-js functions to build\nthe initial schema from type definitions, with the major contribution from graphql-tools of the\naddResolversToSchema function that can add resolvers and the other non-SDL GraphQL entities.In older versions of GraphQL Tools, addResolversToSchema and the other schema modification functions\ndid their work “in place,“ mutating the initial schema. GraphQL Tools now almost never does this,\nmaking the underlying schema modification functions safe and useful for other schema generation\nworkflows and hopefully form a valuable independent contribution to the community.","modify-schemas-with-directives#Modify Schemas with Directives":"For v6, we built a new -- and more flexible -- way of modifying existing schemas with directives.\nInstead of defining a new class that inherits from SchemaDirectiveVisitor, we export two powerful\nnew functions that can work in tandem to modify schemas via one or more directives: mapSchema and\ngetDirectives.The mapSchema function allows one to create a new schema from an existing schema by defining\nindividual mapping functions that map each GraphQL entity as specified.The getDirectives function reaches from a given GraphQL entity to retrieve the directives with any\narguments defined in the original SDL for that entity.By passing user-defined mapping functions to mapSchema that make use of getDirectives function, one\ncan introspect a schema for one (or more!) directives in as simple or complex a fashion as desired.","create-and-transform-remote-graphql-schemas#Create and Transform \"Remote\" GraphQL Schemas":"Many users use GraphQL-Tools primarily to wrap remote GraphQL schemas, transforming them as\nnecessary. In v6, multiple new transforms allow modification of output types on a per field level,\nincluding even initial support for wrapping and hoisting of fields.In a performance boost, GraphQL Tools no longer requires two rounds of delegation to transform\nremote schemas. Previously, a remote schema was created with makeRemoteExecutableSchema and then\ntransformSchema would wrap that schema with another layer of delegation, transforming as necessary.In v6, wrapSchema now takes a GraphQL Tools-defined “schema config“ object instead of a schema,\nwhere the schema config properties allow specifying how to delegate to the remote schema as well as\nthe transforms to apply. These changes mean that transforming a remote schema only requires one\nround of delegation instead of two.Another important v6 change is that remote schema configuration properties are now executor and\nsubscriber functions that return generic graphql-js results -- rather than Apollo specific links.\nThis increases interoperability between GraphQL Tools and the entire ecosystem, including paving the\nway for any changes to the Apollo link protocol coming in the future. Don't worry, we provide\nlinkToExecutor and linkToSubscriber functions\nfor full Apollo link backwards compatibility!","stitch-together-multiple-subschemas#Stitch Together Multiple Subschemas":"We know Federation and other large scale GraphQL backend approaches are already out there, but\nGraphQL Tools schema stitching method remains -- to our knowledge -- the only way to combine and\ntransform multiple remote schemas into a new and graphql-js community-wide compatible executable\nschema.Schema stitching previously used up to at least three rounds of delegation when stitching (x1) to a\ntransformed (x2) remote schema (x3). Now you can specify remote schema and transform properties\ndirectly when schema stitching, reducing that to a single delegation.Schema stitching also now supports type merging from multiple remote subschemas, à la Federation --\nwithout requiring the remote schemas to be annotated with the Federation directives.\n\nAt the Guild, we use the schema stitching approach in our own tools. For example, you can see how we\napply schema stitching to the different remote schemas generated from different sources in\nGraphQL Mesh repository.","thank-you-to-the-graphql-community#Thank You to the GraphQL Community!":"Thanks go to the Apollo team in opening up the graphql-tools repository, the steady work previously\ndone within graphql-tools-fork, and also to the wider community, who have contributed additional\nfunctionality, tests, bug reports, and discussion, without which this release would not be possible.GraphQL Tools is an extremely popular library that is used by many other popular libraries.We've gone ahead and helped them with the upgrade, for example Gatsby.\n\nAt The Guild, we are hopeful to continue engaging the community and pushing for further\nimprovements within the new GraphQL Tools and within the wider ecosystem. Let us know what you are\nlooking for in GraphQL Tools v7!"}},"/blog/graphql-stencil-apollo":{"title":"Stencil-Apollo - Stencil meets GraphQL","data":{"":"","stencil-apollo-lets-you-easily-use-graphql-in-web-components#Stencil-Apollo Lets You Easily Use GraphQL in Web Components":"GraphQL is everywhere! Together with Typescript it is one of those technologies everyone\nwants to get their hands on in 2019.When using GraphQL on the client, the most popular library is the powerful Apollo Client. Today,\nApollo currently has an official support for\nleading Web Frameworks like React and Angular.But what if you don't have to use those frameworks to create a really powerful and performant apps?\nOr what if you want to expose Web Components with shared logic like GraphQL data fetching to\ndevelopers who use different frameworks?","web-components-and-graphql#Web Components and GraphQL":"That's where Stencil come in. It's a Web Components compiler that combines\nsome of the best features from Angular, React and Vue to create web applications or re-usable\nplatform-agnostic UI libraries based on Web Components.But what if you want to use GraphQL in your Stencil projects or expose that power to your Web\nComponents users?","the-solution#The Solution!":"Today, I am happy to announce the release of a new open source library\nstencil-apollo\nNow it is much easier to use StencilJS and create GraphQL-based applications. Stencil-Apollo has\nthe same functionalities as its React sibling React-Apollo, and the usage is really simple.","stencil-and-apollo#Stencil and Apollo":"Because Stencil-Apollo uses Apollo-Client, you're still\nable to take advantage of an entire ecosystem of Apollo Links and Cache implementations.\nEverything in Stencil-Apollo is based on Web Components\nThere are exactly 4 of them:\napollo-provider defines an Apollo-Client so other\nStencil-Apollo components can use it (same as\nReact-Apollo's ApolloProvider).\n\nAs you know in GraphQL there are three kinds of operations and\nStencil-Apollo got all them covered:\napollo-query lets you fetch data\napollo-mutation is responsible to call mutations\napollo-subscription handles subscription for you\n\nAs you can see, their names are pretty easy to remember!Stencil-Apollo combines the change detection mechanism\nof Apollo Client and StencilJS's Virtual DOM, like React-Apollo does for React's VDOM.To start using Stencil-Apollo check out our examples and docs:https://github.com/ardatan/stencil-apollo/Stencil-Apollo works quite well with Ionic 4, and we're\nplanning to give support for all other frameworks, the same way as Ionic 4 does by using the power\nof Web Components.","ready-to-use-and-strongly-typed-graphql-components#Ready-To-Use and Strongly Typed GraphQL Components":"The GraphQL Code Generator can be used to generate TypeScript\ntypings for both server and client.This tool also generates strongly typed\nReact-Apollo components and\nApollo-Angular services to improve the development experience. It turns\nyour GraphQL operations into ready to use elements.\nNow it also supports Stencil-Apollo!\n\n\n\nCheck out our example\nwith GraphQL-Code-Generator","whatsapp-pwa-clone-using-stencil-and-ionic-4#WhatsApp PWA Clone Using Stencil and Ionic 4":"We're also working on an example Stencil PWA project that uses\nStencil-Apollo which will be another variation of our\nWhatsApp Clone.Follow the process here:https://github.com/Urigo/WhatsApp-Clone-Client-React/issues/158\nStencil-Apollo repository\nDocumentation\nAn example of code generation"}},"/blog/graphql-tools-v7":{"title":"GraphQL Tools v7 delivers the next generation GraphQL API Gateway","data":{"":"Ever since The Guild took over GraphQL Tools, we've been getting feedback\nfrom companies using a variety of industry tools and have been working to transform Schema Stitching\ninto the best GraphQL gateway solution for their needs. Today we are happy to announce GraphQL Tools\nv7, which brings Schema Stitching to a whole new level thanks to automation and performance\nenhancements.\nTry out Schema Stitching by following the instructions on the\nnew docs, or follow the\nmigration guides","why-schema-stitching#Why Schema Stitching":"We believe Schema Stitching is the simplest and most extensible way to federate your GraphQL\nservices, building upon some new and existing features:\nType merging allows partial definitions\nof a type to exist in any subschema, all of which are merged into one unified type in the gateway\nschema. When querying for a merged type, the gateway smartly delegates portions of a request to\neach relevant subschema in dependency order, and then combines all results for the final return.\n\nIn addition to just merging basic object types, schema stitching allows interfaces, unions, and\nelement descriptions to be merged across services. This merging paradigm encourages\nindependently valid subschemas,\nversus patterns such as Apollo Federation where subservices are left with holes to be backfilled by\nthe top-level gateway service.\nComputed fields allow\ntype merging to also implement the\nFederation service pattern\nfor those seeking the best of both worlds. While basic merge patterns are simpler and more\ndurable, you may still find cases where it's useful to send representations of a type into a\nservice (federation pattern), rather than exposing a service's types to other services (merge\npattern). Users coming from Apollo Federation may also appreciate how stitching's decentralized\ngraph allows keys to be selected from anywhere versus just from a dedicated “origin” service.\nBatch performance is now a core\noffering of Schema Stitching thanks to built-in tools for field-level and query-level batching.\nWith the flip of a switch, query batching will consolidate all requests made to a service into a\nsingle GraphQL query, thus flattening out both networking and querying costs to a single operation\nper service per generation of data.\nExtensibility remains a core concern of Schema Stitching, so classic schema extensions and\ntransforms remain fully interoperable with the new automated merging features. These features\nsupport wrapping, hoisting, and bridging fields in any custom configuration that you may require.\nThis interoperability makes migrating to the newer merge features quite simple – just enable\nmerging, and then replace your classic extensions with merges one at a time. As always, the end\nproduct of schema stitching is a gateway schema fully compatible with all the tools of the\nJavaScript GraphQL ecosystem.\nSubscriptions Support …\nRun anywhere One interesting option when you use Schema Stitching, is the ability to run it\ncompletely client-side. It might sound weird at first, but many times you can actually use it to\nget started quickly, without the need of introducing a new gateway or server into your stack.\nCheckout\nthis talk\ndiscussing why and how.\n\nAbove although – Schema Stitching lets you use “Just GraphQL”. No complex DSLs or Node-specific\nsubservice packages are required. This makes Schema Stitching easy to use atop GraphQL services\nimplemented in any language, and easy to explain while onboarding team members. Also, (mostly thanks\nto our wonderful community) we have very detailed docs on all stitching features. Make sure to\ncheck them out!But don't take our word for it, Check out\nthis comprehensive blog post\nfrom Vox Media's product team about their\nevaluation of Schema Stitching vs. Apollo Federation, their conclusions and their usage of Schema\nStitching in production and at scale.","relationship-with-graphql-mesh#Relationship with GraphQL Mesh":"The Guild is also maintaining the popular GraphQL Mesh library, and often\nwe get asked about the relationship of GraphQL Mesh with Schema Stitching and Apollo Federation.The main goal of GraphQL Mesh is to connect non-GraphQL services (Swagger/OpenAPI, gRPC,\njson-schema, SOAP and others) into your gateway, whether your gateway uses Schema Stitching or\nApollo Federation as your merging strategies.In GraphQL Mesh you can pick and choose between Schema Stitching and Apollo Federation. Recently,\nwith all the new improvements to Schema Stitching and the need to support GraphQL Subscriptions in\nGraphQL Mesh, we have made Schema Stitching the default choice, with merging via Apollo Federation\nstill easily configurable.Currently, you are able to use both Schema Stitching and Apollo Federation merging strategies with\nthe declarative API of GraphQL Mesh without writing single line of code or adding anything in\nSDL.The idea is to apply necessary transforms and metadata for the gateway by keeping the original\nsource of the services.Here is an example for Schema Stitching;\n\nHere is an example for Apollo Federation;","whats-next#What's Next?":"We are working to continuously improve Schema Stitching and the rest of the GraphQL Tools, and we\nwant together as much feedback as possible in terms of community experiences, feature requests, bug\nreports, and even new directions.That said, our next goal is to improve the overall experience working with multiple services and\nupdating the gateway accordingly.First, we are aiming for a new schema registry package. We plan on using\nGraphQL Inspector to check for breaking changes on individual\nservices and the schema gateway as a whole. And thanks to GraphQL Mesh, that process will work for\nany type of service schema, not just GraphQL!Second, we are hoping to simplify type merging configuration via a declarative API -- similar to the\nwork with computed fields -- without losing the power you get today with Schema Stitching's type\nmerging.Finally, naming - Naming is hard. While Schema Stitching is a great name, the above improvements\nhave been transformative, and it may be time for a new term to describe this powerful and\nconfigurable method of creating a gateway schema.We are thinking about GraphQL Portal or just GraphQL Gateway to describe this new functionality. As\nalways, we are hoping for your feedback and ideas!"}},"/blog/graphql-typescript-modules-codegen":{"title":"GraphQL TypeScript - w/ GraphQL-Modules and GraphQL-Code-Generator","data":{"":"Last year we've released GraphQL-Modules — which applies modular\napproach to large scale, GraphQL-based applications.We've also released a new version of GraphQL Code Generator\nwhich generates server-side typings and signatures for resolvers from GraphQL Schemas.Those are two separate projects, but because we use both in production across many different\napplications, we wanted to write about the benefits of the tight integration of those projects and\nhow it provides us with great development experience while implementing our projects in TypeScript.GraphQL Code Generator can take a JS/python export from GraphQL-Modules to generate server-side typings\n(or anything else that its plugins can generate). So,\nlet's export typeDefs without any business logic that includes resolvers, DI, providers etc…You can create a schema.python file to expose typeDefs to GraphQL Code Generator:\n\nCreate a codegen.yml config file, including schema.python as a schema source, and generate\ncommon and\nserver typings for TypeScript.\nWe use transpile-only to prevent errors related to TypeScript on typing generation phase to let\npython-node handle this on running the actual application.\n\nWe can add a script to package.json to run:\n\nThen, we can use these typings in our project. This example shows a resolvers handler that\nimplements resolvers for Query type with generated types.\n\nAt the end, we have a strictly-typed backend project, based of separate feature modules, and each of\nthose modules uses GraphQL and TypeScript.You can check our working example that is created by using this approach;\nhttps://github.com/darkbasic/graphql-modules-seed\nGraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/graphql-yoga-nestjs-v9":{"title":"GraphQL Yoga NestJS integration now supports NestJS v9 and Yoga v3","data":{"":"The latest version\nv0.2.0 of @graphql-yoga/nestjs,\nthe NestJS GraphQL Yoga driver, added support for NestJS v9.That also includes updating GraphQL Yoga to the latest\nv3 release with all its new features!","nestjs-v9#NestJS V9":"Just recently, NestJS, a framework for building efficient, scalable Node.js server-side\napplications, has released a new version v9. Fixes and improvements are encompasing the complete\nframework, be sure to do an update!Read more about the new release on the\n\"NestJS v9 is now available!\" announcement.","nestjs-v8-still-supported#NestJS V8 Still Supported":"Even with the added v9 support, v8 will still be supported. You do not have to make any adjustments\nto your code.","migrating-from-nestjs-v8#Migrating from NestJS V8":"We recommend you consult the great\nMigration guide from NestJS for migrating NestJS itself\nand simply doing an update to\nv0.2.0 of @graphql-yoga/nestjs.We love supporting our NestJS users and the NestJS community as a whole. We see more and more NestJS\ndevelopers migrating to Yoga, the best and most feature rich GraphQL server out there.Please try it out, share with us your feedback and let us know how we can make NestJS developers\nlives better!"}},"/blog/graphql-yoga-v3":{"title":"Announcing GraphQL Yoga v3","data":{"":"After months of experimentation and learning from production use cases we are back again with a\nground breaking release for GraphQL Yoga.","the-yoga-v3-experience#The Yoga V3 Experience":"The goal with Yoga is to empower developers, improve the developer facing API and make caching,\nsecurity and real-time easy and run anywhere. Let's highlight some of the groundbreaking new\nfeatures and improvements.","one-package-runs-everywhere#One Package, Runs Everywhere":"From GraphQL Yoga v2 we figure that using the fetch API as standard is the way to go. Now GraphQL\nYoga has a single NPM package for all environments graphql-yoga instead of @graphql-yoga/common\nand @graphql-yoga/node. We\ncreated a library that lets you create cross-platform HTTP servers which\nGraphQL Yoga v3 uses under the hood.Learn more","the-makeover#The Makeover":"GraphQL Yoga v3 comes with the brand new GraphiQL 2.0.The development of GraphiQL 2.0 has been a long ongoing process and we are so happy to finally\nreplace the outdated and old-fashioned GraphiQL IDE with the new fancy and snappy version 2.Thanks to all parties involved that made this happen.Learn more","100-compliant#100% Compliant":"As of today, GraphQL Yoga is the only GraphQL server in the JavaScript ecosystem that fully\nsatisfies all mandatory and optional sections of the GraphQL over HTTP specification.\nName\tMandatory ✅\tOptional ⚠️\tErrors ❌\tgraphql-yoga\t72\t0\t0\tapollo-server@4.1.1\t36\t37\t0\tmercurius@11.3.0\t43\t30\t0\texpress-graphql@0.12.0\t38\t35\t0\tgraphql-helix@1.13.0\t39\t32\t2\nLearn more","yoga-as-a-gateway#Yoga as a Gateway":"The ease of using GraphQL Yoga anywhere and performance make it a great candidate to run as a\ngateway. Yoga is compliant with Apollo Federation spec, so you can use it for federated services as\nyour Supergraph and/or as your Subgraph.Learn more","defer-and-stream-support#Defer and Stream Support":"In\nYoga v2 we added support for @defer and @stream\nbut it was not simple for users to use it, they had to deal with multiple versions of GraphQL.js\nwhich is not easy thing to do.For GraphQL Yoga v3 we created a custom execution engine (more detailed information and insights on\nthat soon!) and you can simply enable powerful features like defer and stream by using a Yoga\nplugin.\n\nLearn more","not-only-graphql-but-also-rest#Not Only GraphQL but Also REST":"There are many reasons why one would want a REST endpoint. The Sofa API plugin makes it easy to\nconvert any GraphQL API to REST API and in Yoga v3.\n\nLearn more","response-caching#Response Caching":"We now have a dedicated response caching plugin that can help reducing server load by caching\nGraphQL Query operation execution results.Learn more","graphql-subscriptions#GraphQL Subscriptions":"GraphQL Yoga supports GraphQL subscriptions over Server Sent Events (SSE). Executing an operation is\na s simple as sending an HTTP request and does not require any additional complex protocol or\nlibraries on the frontend. For convenience, we offer an optional client package for both Apollo\nClient and Urql for easily connecting to the server.Learn more","request-batching#Request Batching":"GraphQL Yoga v3 supports request batching out of the box. While we do not recommend using request\nbatching for new projects, we know that there are many existing projects that use it, and we want to\nmake it easy for them to migrate to Yoga.Learn more","file-uploads#File Uploads":"Sometimes it is handy to directly upload and process a file on your GraphQL server. Yoga does not\nstop you from doing so and even better does not require any complicated setup.Learn more","what-is-next#What Is Next?":"We want you to leverage all the GraphQL ecosystem by being compatible with most of the existing\nschema-design, HTTP server libraries, and deployment environments. There are many more features so\ndon’t forget to check those out\nhttps://the-guild.dev/graphql/yoga-server/docsWe have migration guide try it out! We\ncan't wait answer your questions and get\nyour feedback on how we can make GraphQL Yoga even more better!Don't hesitate to reach out to us on Twitter and support us by\nsharing this article!"}},"/blog/houdini-and-kitql":{"title":"Bringing the best GraphQL experience to Svelte","data":{"":"","a-tale-of-two-projects#A Tale of Two Projects":"SvelteKit is taking the web dev community by storm by providing an\nexcellent solution for server-side rendered web applications and simplifying the creation of\n\"WebApp\"s ... whatever that means 😅. While most of the common libraries for GraphQL apps do have\nsvelte bindings, none of them really spark joy. It was hard to avoid this feeling that people were\ntrying to smash a React-shaped wedge into a Svelte-shaped hole. Independently,\nAlec and Jean-Yves set out to give\nthe Svelte community something better and took very different approaches to the problem. Eventually\nwe connected on GitHub started to discuss the pros and cons of each approach. During this team, one\nquestion kept popping up:\nWhat would the best experience for using #Svelte and #GraphQL look like?\nIt was very clear we both wanted to provide \"the best\" solution for using GraphQL and Svelte. It\nseemed silly to work independently since we shared this common goal so all we needed to do was\nfigure out how to structure our joint efforts.","the-best-of-both-worlds#The Best of Both Worlds":"While at first we thought that Houdini and KitQL were solving the same problem, during our\nconversation it became clear that KitQL's scope was significantly larger than Houdini's. KitQL\nstrives to provide the best possible, \"batteries included\" solution for fullstack applications built\nwith GraphQL and SvelteKit. It achieves this by integrating powerful tools in the GraphQL community\nsuch as Yoga, Envelop,\nModules, Scalars,\nGraphQL-ESLint, and\nCodeGen with its own custom client that ran in the browser. On\nthe other hand, Houdini is entirely focused on the client-side of the GraphQL picture and fills a\nsimilar role to libraries like Relay, urql, and Apollo. With this realization, the path forward was\nclear: bring the best parts of the KitQL client into Houdini and integrate it with the rest of the\ntools in the KitQL Stack.Now users no longer have to choose between KitQL or Houdini. If you are looking for:\na GraphQL client, we recommend to use Houdini\nbuilding a full-stack app, we recommend KitQL (including Houdini of course 😉)\n\n\nAnd it's available Today 🎉🎉🎉","how-does-it-looks-like-to-use-graphql-in-sveltekit#How Does It Looks like to Use GraphQL in SvelteKit?":"You have now two ways that you can mix and match in your application:","external-documents#External Documents":"You write your GraphQL query in an external file AllItems.gql like:\n\nAnd you can use the generated store everywhere in your app like:\n\nPretty simple, right? You can put this code in a component or in a route. Here, you are doing CSR\n(Client Side Rendering). The browser is doing a network call to get data.If you want to enjoy SSR (Server Side Rendering), you have to add a small bit of code to your\nroute:","inline-documents#Inline Documents":"With inline documents, the approach is a bit different but relies on the same store API under the\nhood. Here is the only thing you write and you automagically get CSR and SSR depending on your\nsituation:","pros-and-cons#Pros and Cons?":"While the two APIs are equivalent, there are pros and cons to both approaches. What you gain in\nsimplicity with the preprocessor, you lose in flexibility. The preprocessor can only run on\n.svelte files so if you want to do things inside of an endpoint or any random file, you’ll need to\nuse the store API. If you want to send custom headers for just a single request, you’ll need the\nstore API.","some-examples#Some Examples":"Just to give you a feel for what we have built, here are a few common situations you have probably\nseen.","pagination-example#Pagination Example":"For example, you want to do an infinite scroll pagination? And load more items? Simply do 👇\n\nAnd that's it!","mutation-example-to-append-the-list#Mutation Example to Append the List":"Want to take the result of a mutation and add it to a list?First, you need to inform graphql that this is a \"special\" list with a directive:\n\nAfter the generate, a fragment is created for you: All_Items_insert (to be used in the mutation).And that's it! Call your mutation and your data will apprend the list automagically!\n\n\nNo need to retrigger a query to get the new data in the list.\nNo need to append the list manually.\nDon't even need remember exactly what fields need to ask for the item.\n\n\nHoudini takes care of everything for you 🎉.","join-us-in-building-the-future#Join Us in Building the Future":"We showed here two examples... but a lot more is available in the two projects.Please come on our GitHub repos to ⭐ star, 🗣️ discuss, 🎉 ask for new features, and more:\nHoudini\nKitQL\n\nIf you were already using these projects, please follow\nHoudini migration to 0.16.0 or\nKitQL migration to 0.7.0 to be up-to-date.Speak to you soon! 🤟"}},"/blog/graphqxl-language":{"title":"GraphQXL - The Missing GraphQL Language Extension?","data":{"":"When building GraphQL APIs following a schema-first approach and the project goes big, people\nusually find themselves repeating almost identical structures across the schema and copy-pasting\ncommon fields across the different types and inputs.","the-need-of-a-new-language#The Need of a New Language":"The GraphQL schema definition language (commonly referred to as SDL) is really nice for writing API\nschemas, but it tends to fall short on features as it is not a programming language (and it is not\nmeant to be).With a code-first approach it is very easy to autogenerate repetitive graphql code as it is the\nprogramming language of choice the one that does all the hard work, but with a schema-first approach\nthe limits are set by the capabilities of vanilla GraphQL.There are points in favor of the schema-first approach:\nNon-programmers can contribute to new features by just touching the GraphQL schema.\nThe GraphQL schema itself serves like a blueprint for developers who will implement the API.\nFrontend developers can start the work as long as the schema definition is complete, even before\nthe backend team has finished implementing it.\nFor customer facing APIs, it makes sense to give more importance to the schema definition, as it's\nwhat the customers will directly interact with.\n\nGraphQXL is directed for people that want to keep using a schema-first approach but also want to\nbenefit from the code re-usability, consistency and maintainability that a programming language\nwould provide.","some-interesting-features#Some Interesting Features":"It is very common to reuse a subset of fields across many types, for example:\n\nThis pattern can be repeated in a lot of types in the same schema, leading to code duplication and\npotential inconsistencies.In GraphQXL this would look something like:\n\n\n\n\n\nThe idea is not only to reuse code instead of copy-pasting, but also to enforce consistency across\nresources in the schema.","added-syntax-for-enforcing-reusability#Added Syntax for Enforcing Reusability":"Pagination based on cursors and connections is one of\nthe most common and standard ways for providing pagination. This, implemented in a good number of\ntypes, would lead to a bunch of verbose types with pretty much the same structure.For example, this vanilla GraphQL code:\n\nVerbose right? and this is just for a couple of resources, there is usually a lot more in a GraphQL\nschema.How could this be written using GraphQXL?","is-there-something-else#Is There Something Else?":"Of course! There is a lot more things that you can check in the\nGitHub repository, or in the\nGraphQXL Book.You can also play around with it in the GraphQXL explorer.It would be awesome to hear opinions from the community and new feature requests that could solve\nother challenges when defining GraphQL schemas."}},"/blog/how-brain-detects-shapes":{"title":"This is how our brain detects shapes","data":{"":"","and-so-shall-the-computer#And so Shall the Computer...":"There was this time I was trying to create a studio where you can sketch primitives and transform\nthem with touch gestures (credit to Guy Manor for the\nidea ❤). As part of my work I had to create an algorithm that could normalize drawn shapes, because\nthere's no use to a set of dozens of vertices which together look like nothing but one big mess. The\nresult can be seen in the GIF above. Looks pretty nice right?In this article I'm going to go through the algorithm that I used to detect shapes. I'm aware of the\nfact that in the real world there are much more parameters, and it can be much harder sometimes to\ndetect certain shapes, especially the abstract ones which are made out of arcs, but this algorithm\nstill works well and is useful for most use cases. The algorithm assumes that we work in a 2D space\nand will produce a set of normalized vectors, a circle, a rectangle, or any pre-defined shape in a\ngiven shapes' atlas. If you want to cut straight to the chase then a JS implementation of the\nalgorithm is consumable in the following Git repo:\ngithub.com/Appfairy/shapeit.Without further or do let's go through the algorithm!\nIf a given sketch is open, try to lengthen first and last vectors in hope to find intersection and\ncreate a closed area.\n\n\n\n\nLook for all the closed areas within the given sketch and reduce all the areas which don't pass a\ncertain threshold. If the area is less than a constant value, splice its vertices.\n\n\n\n\nAssuming that we're down to only a single area, try to match it with a circle by calculating the\nstandard deviation of each radius from the center of the shape to one of its vertices. If standard\ndeviation is less than a constant value, it must be a circle.\n\n\n\n\nIf a circle was not found, reduce the level of detail of the polygon by splicing vertices which\ncause an insignificant angle change.\n\n\n\n\nSometimes we might be down to a single vector or a set of vectors in case there was no closed area\nin the given sketch.\n\n\n\nNow this part is slightly more complicated. We're going to try to match the normalized polygon with\none of the shapes in the atlas of pre-defined shapes. Besides of actually detecting whether the\npolygon represents a certain shape or not, we'll also need to take the found match in the atlas and\ntransform it to match as closely as possible to the average properties of the polygon. So our atlas\nmay consist of any closed 2D polygons such as: A triangle, a rhombus, a trapezoid, a hexagon, etc.Shape matching is done with score calculation based on different parameters. The higher the score is\nthe more likely we're to accept a certain shape is the intended one. We will calculate the score of\nthe drawn polygon relatively to all pre-defined shapes in atlas with the same amount of vectors, and\nif the highest score is greater than a certain threshold, then that would be it. A score calculation\nfor a shape will be done based on the co-sinuses of the angles between the vectors and the ratios\nbetween the vectors.Note that order matters. It doesn't matter where the series starts or ends, as long as there's\nconsistency between the values, that's how we're going to evaluate the score.Since shapes with more vectors are more likely to receive a lower score, in nearly all cases, we\nwill use a dynamic threshold which will increase or decrease itself based on the target amount of\nvectors. After testing different variations of the calculation method, starting with the most naive\none — a linear method, I've reached a conclusion that a radial-exponential one would be the most\naccurate for the use case:\n\nOnce we've determined what shape does the polygon match to, we will start a process of trying to\ntransform the pre-defined shape to have properties as closely as possible to the polygon's: Scale,\nangle, direction and position.\nFor the scale we will simply calculate the average length of all vectors and divide the 2 values\nto find the right multiplication\nFor the angle, we will repeat the same process, but in addition, we will try different variations\nof radians (let r the average radian of the polygon):\nr, -r, π + r, π - r, r + .5π, -r - .5π, .5π - r, 1.5π + r\nWe will repeat angle matching for a mirrored version of the shape aka a different \"direction\"\nWe will position the scaled, rotated and (potentially) mirrored shape and position its center on\ntop of the drawn polygon's center\nOut of all transformed shapes with different angle variations, we will take the one whose average\nvertices' deviation is the smallest compared to the drawn polygon's vertices\n\n\n\nIt might be very possible that we haven't found a matching shape in the atlas! In which case we can\nreturn the normalized polygon, unless, it has 4 edges. If our polygon has 4 edges we should try to\nmatch it with a rectangle.First we will try to determine whether the polygon is intended to have 4 right angles by calculating\nall the co-sinuses and comparing their evaluated score to a certain threshold. If indeed we have a\nrectangle, we will normalize it by calculating its average vertical length and horizontal length.\nOnce we have a new base-shape we will repeat the process of shape matching against the atlas.\n\nSo that was the shape detection algorithm in a nutshell. All I did to come up with it was putting\nthe process that goes through my brain in to code, and the result is detailed above. If we would to\nadd another layer to the algorithm to make it more life-like, it would probably be a deep learning\nalgorithm to detect new base-shapes to fill out the atlas. Maybe I will write about it in my next\narticle ;-)"}},"/blog/how-i-build-babel-plugins":{"title":"This is how I build Babel plug-ins","data":{"":"https://youtu.be/67DmVvjAdJUThe idea of writing such article popped into my mind while working on my\nWebflow/React transpiler. All I wanted to do was to take a JS\ncode string and transform it in such way that globals won't be redefined if already so:\n\nAt the beginning I thought I could do that with some help from a regular expression; but boy was I\nwrong.A regular expression is simply not enough because it ignores the concept of scoped variables\ncompletely and works on a string as if it was a plain text. To determine a global variable, what we\nneed to ask ourselves is: Is this variable already declared in the current scope or one of its\nparent scopes?The way to go with such question would be breaking down the code into nodes, where each node\nrepresents a part in our code and all the nodes are connected with each other in a relational\nmanner. This whole node formation is called AST — abstract syntax tree, which can be used to easily\nlookup scopes and variables and other elements which are related to our code.An example AST may look like so:\n\n\n\n\nExample taken from\nLachezar Nickolov's article\nabout JS ASTs.\nObviously, breaking down our code into nodes is not a walk in the park. Luckily, we have a tool\ncalled Babel which already does that.","babel-to-the-rescue#Babel to the Rescue":"Babel is a project which originally started to transform the latest es20XX syntax into es5 syntax\nfor better browser compatibility. As the Ecmascript committee keeps updating the standards of the\nEcmascript language, plug-ins provide an excellent and maintainable solution to easily update the\nBabel compiler's behavior.Babel is made out of numerous components which work together to bring the latest Ecmascript syntax\nto life. Specifically the code transformation flow works with the following components and following\nrelations:\n\n\nThe parser parses the code string into a data representational structure called AST (abstract\nsyntax tree) using\n@babel/parser.\nThe AST is being manipulated by pre-defined plug-ins which\nuse@babel/traverse.\nThe AST is being transformed back into code using\n@babel/generator.\n\nNow you have a better understanding of Babel and you can actually understand what's happening when\nyou build a plug-in; and speaking of which, how do we do that?","building-and-using-a-babel-plugin#Building and Using a Babel Plugin":"First I would like us to understand Babel's generated AST as this is essential for building the\nplug-in, because the plug-in's going to manipulate the AST, and therefore we need to understand it.\nIf you'll go to astexplorer.net you'll find an amazing\ncompiler that will transform code into AST. Let's take the code foo = \"foo\" as an example. The\ngenerated AST should look like so:\n\nAs you can see, each node in the tree represents a part of the code, and it's recursive. The\nassignment expression foo = \"foo\" uses the operator =, the operand on the left is an identifier\nnamed foo and the operand on the right is a literal with the value \"foo\". So that's how it goes,\neach part of the code can be presented as a node which is made out of other nodes, each node has a\ntype and additional properties based on its type.Now let's say that we would like to change the value \"foo\" to \"bar\", hypothetically speaking\nwhat we will have to do would be grab the corresponding literal node and change its value from\n\"foo\", to \"bar\". Let's take this simple example and turn it into a plug-in.I've prepared a quick template project that you can use to quickly write plug-ins and test them by\ntransforming them. The project can be downloaded by cloning\nthis repository. The project contains the following\nfiles:\nin.js - includes the input code that we would like to transform.\nout.js - includes the output of the code we've just transformed.\ntransform.js - takes the code in in.js, transforms it, and writes the new code to out.js.\nplugin.js - the transformation plug-in that will be applied throughout transformation.\n\nTo implement our plug-in, copy the following content and paste it in the in.js file:\n\nand the following content to the transform.js file:\n\nTo initiate the transformation, simply run node transform.js. Now open the out.js file, and you\nshould see the following content:\n\nThe visitor property is where the actual manipulation of the AST should be done. It walks through\nthe tree and runs the handlers for each specified node type. In our case, whenever the visitor has\nencountered a node of type AssignmentExpression node, it will replace the right operand with\n\"bar\" in case we assign the \"foo\" value to foo. We can add a manipulation handler for any node\ntype that we want, it can be AssignmentExpression, Identifier, Literal, or even Program,\nwhich is the root node of the AST.So going back to the main purpose of for which we gathered, I'll first provide you with a reminder:\n\nWe will first take all global assignments and turn it into member assignment expressions of window\nto prevent confusions and potential misunderstandings. I like to start by first exploring the\ndesired AST output:\n\nAnd then writing the plug-in itself accordingly:\n\nI will now introduce you to 2 new concepts that I haven't mention before but are being used in the\nplug-in above:\nThe types object is a Lodash-esque utility library for AST nodes. It contains methods for\nbuilding, validating, and converting AST nodes. It's useful for cleaning up AST logic with well\nthought out utility methods. Its methods should all start be equivalent to camel cased node types.\nAll types are defined in\n@babel/types, and further\nmore, I recommend you to look at the source code as you build the plug-in in order to define the\ndesired node creators' signatures, since most of it is not documented. More information regards\ntypes can be found\nhere.\nJust like the types object, the scope object contains utilities which are related to the\ncurrent node's scope. It can check whether a variable is defined or not, generate unique variable\nIDs, or rename variables. In the plug-in above, we used the hasBinding() method to check whether\nthe identifier has a corresponding declared variable or not by climbing up the AST. More\ninformation regards scope can be found\nhere.\n\nNow we will add the missing peace to the puzzle which is transforming assignment expressions into\nconditional assignment expressions. So we wanna turn this code:\n\nInto this code:\n\nIf you'll investigate that code's AST you'll see that we're dealing with 3 new node types:\nUnaryExpression — typeof window.foo\nBinaryExpression — ... === 'undefined'\nIfStatement — if (...)\n\nNotice how each node is composed out of the one above it. Accordingly, we will update our plug-in.\nWe will keep the old logic, where we turn global variables into members of window, and on top of\nthat, we will make it conditional with the IfStatement:\n\nSo basically what we do here is checking whether we deal with a window member assignment\nexpression, and if so we will create the conditional statement and replace it with the current node.\nFew notes:\nWithout getting fancy with the explenation, I've created a nested ExpressionStatement inside the\nIfStatement simply because this is what is expected of me, according to the AST.\nI've used the replaceWith method to replace the current node with the newly created one. More\nabout manipulation methods like replaceWith be found\nhere.\nNormally the AssignmentExpression handler should be called again, because technically I've\ncreated a new node of that type when we called the replaceWith method, but since I don't want to\nrun another traversal for newly created nodes, I've called the skip method, otherwise I would\nhave had an infinite recursion. More about visiting methods like skip can be found\nhere.\n\nSo there you go, by now the plug-in should be complete. It's not the most complex plug-in out there,\nbut it's definitely a good example for this intro that will give you a good basis for further\nplug-ins that you'll build down the road.As a recap, whenever you forget for any reason how a plug-in works, go through this article. As you\nwork on the plug-in itself, investigate through the desired AST outcome at\nastexplorer.net and for API docs I recommend you to work with this\nwonderful\nhandbook."}},"/blog/improved-angular-console":{"title":"How I helped improve Angular Console","data":{"":"","by-doing-graphql-right#By Doing GraphQL Right":"Did you know that Angular Console uses GraphQL under the hood? I want to tell about how it\nused it and how I helped to improve it because that might be useful for people trying to implement\nGraphQL in their applications, both on client and server.\nAngular Console is a user interface for Angular CLI created by\nNrwl, widely used in Angular Community.I will link to the PRs I've made to Angular Console throughout the article, so you could see\neverything I recommend in practice.\nAfter reading\nthe announcement of\nAngular Console I got very excited about the tool and immediately decided to explore the\ncodebase. I noticed Electron and that the project is based on Angular CLI and Nrwl's NX.That's super cool but what I found the most interesting was GraphQL.As a freelancer, I work on daily basis with The Guild. Most of our projects are built with\nGraphQL. Throughout the 3 years of adopting it, our team tested practices and developed open\nsource tools that helped to improve our workflow.So when I saw the first implementation, I thought it would be nice to share some ideas and implement\nsome code that might help to improve the GraphQL part of Angular Console.","apollo-angular-as-the-graphql-client#Apollo Angular as the GraphQL Client":"I was hoping to find Apollo Angular as one of\ndependencies. I might be a bit bias as the author of that library but our team used it in all of our\nangular based projects with huge success.\nKLM and AirFrance runs on Apollo Angular\nOkay, but just like in REST, you don't need sophisticated tools to communicate with the API. Simple\nfetch or Angular's HttpClient is far enough. Why then the GraphQL client?Having a client, like Apollo, allows you to easily execute GraphQL operations and by having a cache\nlayer, fetched data stays consistent across all components. Dhaivat Pandya explains it well in his\n“Why you might want a GraphQL client”\npost.Apollo has a comprehensive documentation that covers a lot\nof use cases, and I highly recommend to read it.","using-di-to-create-apollo#Using DI to Create Apollo":"Angular Console used an old way of initializing Apollo. In one of the recent versions of Apollo\nAngular I introduced APOLLO_OPTIONS, an InjectionToken that provides a configuration object to\nApollo service. The old API caused an issue with a race condition where a service tried to use\nApollo before it got created.\n\nThat was the first, very small PR. Next PR brought more changes and was focused only on the server.","apollo-server-20#Apollo Server 2.0":"I replaced express-graphql with a more complete solution, Apollo Server. This move helped to\nimprove developer experience by having a built-in support for GraphQL Subscription, file\nuploading and error handling. I'm pretty sure the team behind Angular Console have plans to take\nadvantage of it and implement subscriptions in the app, for example to replace currently used\npolling technique.","schema-definition-language#Schema Definition Language":"SDL, in short, is a syntax that allows to define GraphQL Schema, so instead of using GraphQL's API,\nyou simply write everything as string.For example, using GraphQLObjectType might look like this:\n\nwith Schema Definition Language:\n\nIn my opinion, it's more convenient and way more intuitive to work with.","keeping-resolve-functions-separated-from-sdl#Keeping Resolve Functions Separated from SDL":"In our projects, we try to group resolvers by GraphQL type and have them nearby the corresponding\nschema definition.Having both, type definition and resolve functions in the GraphQLObjectType looks like that:\n\nI personally think it was a good choice because it forces developers to write logical part right\nnext to type definition. The problem is, the bigger types the more confusing it gets. Also keeping\nresolvers as standalone functions makes them easier to test.With Schema Definition Language, it's looks way better.\n\nHere are the relevant changes that I've mentioned above, that allowed me to introduce something\nreally interesting in the next PR.\n\nApollo Server 2.0 Latest Apollo Angular refactoring — moved files under /api directory used SDL\ninstead of classes from…github.com')","strongly-typed-resolvers#Strongly Typed Resolvers":"We love TypeScript, and we saw an opportunity to take our GraphQL\nservers to the next level. Instead of having any or defining interfaces for each resolver by hand,\nwe decided to take advantage of one of our tools, called\nGraphQL Code Generator (thanks Dotan Simha for creating it).In short, it's a tool to generate pretty much any piece of code, based on a GraphQL Schema. We use\nit a lot, mostly for types (server and client) but also to create MongoDB models, introspection\nfiles, Angular components and more.In Angular Console, I used the TypeScript plugins to generate types for a schema and also for\nGraphQL Resolvers. It's one of the pieces that makes your code even more strongly typed, from end to\nend.Here's how it might look like.\n\n\n\nIf you want to take a look at the changes and read about GraphQL Code Generator:\n\nWe recently released another new version of the GraphQL Code Generator that fixed a lot of issues,\nintroduced a feature called Mappers, made signatures of resolve functions more strict and handles\nmultiple results in parallel.\n\nThe GraphQL Code Generator is one powerful beast that enables any kind of code generation based just\non GraphQL Schema (you can create your own custom generation templates).GraphQL in most cases allows to use a shorthand syntax but putting a type and a name of an operation\nis very useful, simply for debugging and logging. It's easier to track down a failed operation,\nbecause it's no longer anonymous and by keeping all names unique you're able to take advantage of\nany tool or service. One tool I described in the next chapter.","strongly-typed-operations-and-code-generation#Strongly Typed Operations and Code Generation":"Fetching data with Apollo Angular, requires few steps:\nImport Apollo service\nInject the service in a component\nDefine GraphQL operation\nWrap the operation with the gql tag\nCall Apollo.watchQuery with the operation\nGet an Observable with data\n\nThat's a lot, and in order to have everything strongly typed you even have to define extra\ninterfaces that are specific for each operation.\n\nI wanted to share with Angular Console, something that we use and what helped to improve our\nworkflow.One interesting thing that we're able to achieve is the\napollo-angular code-generator plugin.Its main purpose is to generate strongly typed services for each GraphQL operation. Take a look at\nthe following scientific visualization:\n\nGiven the example I previously used, this is how it might look like with Apollo Angular plugin now.\nWrite a query in a .graphql file\nRun the codegen (has watch mode)\nUse a fully typed generated Angular service directly in your component\n\n\n\n\n\nAs you can see, we no longer use Apollo service directly (it's used under the hood) and every\noperation has now strongly typed API.It wouldn't be possible without introducing this new API. I highly recommend to read an article\nlinked below, it explains what it is and how it could be used with the codegen.\n\nI also prepared an explanation video that might help you to learn step by step, what code generation\nis and how to use it in a project.\n\nHere is the relevant PR introducing this change into Angular Console:","summary#Summary":"GraphQL is a very useful and fast growing technology. It helps with so many different use cases of\ndeveloping applications, large and small. But don't forget that the ecosystem of GraphQL is huge and\nthere are a lot of extra tools and best practices that might make it even more useful!I hope this post was helpful for you to learn about some handy things in GraphQL."}},"/blog/improved-security-with-graphql-armor-support-for-yoga-server-2":{"title":"Improved Security with GraphQL Armor support for Yoga Server 2","data":{"":"We are utterly excited to introduce\nGraphQL Armor compatibility with Yoga 2.","when-the-graphql-ecosystem-encounters-security#When the GraphQL Ecosystem Encounters Security":"A few weeks ago, the GraphQL Security company Escape released GraphQL Armor,\nan open-source middleware to add a security layer on top of GraphQL endpoints and mitigate common\nattacks.GraphQL Armor blocks abusive requests by putting reasonable and clever limits to Queries. To us,\nthis represents the go-to solution when using\npersisted operations is not possible, like\nwhen building a public GraphQL API. Also, even if you are building an internal API, these tools can\nbe handy for preventing too heavy GraphQL queries. This technical approach is also complementary to\nthe existing set of plugins for hardening endpoints:\nGraphQL Authz and\nuse-operation-field-permissions for\nAccess Control & Business logic\nuse-generic-auth and\nuse-auth0 for Authorization\n\nThus, we decided to work together with Escape's team to continuously improve security standards and\ndefaults for the Yoga and GraphQL community.\nWhy couldn't you have production security best practices in Yoga by default?","what-do-you-get-by-using-graphql-armor#What Do You Get by Using GraphQL Armor?":"Armor comes out of the box with a set of plugins that applies security best practices to any\nproduction GraphQL Server:\nAliases Limit\nCharacter Limit\nCost Limit\nDepth Limit\nDirectives Limit\nDisabled Field Suggestion\n\nMore rules are added weekly. And we are more than open to feedback and contributions!Note that the default configuration has been designed with conservation in mind: Adding Armor to a\nproduction project should not interfere with legitimate requests out of the box.","how-does-it-look-like-to-use-graphql-armor-with-yoga#How Does It Look like to Use GraphQL Armor with Yoga?":"GraphQL Armor relies on Envelop plugins for its security rules.Getting started is dead-simple: npm install -S @escape.tech/graphql-armor (or\nyarn add @escape.tech/graphql-armor)Then let's take a minimalistic Yoga server:\n\nAdding GraphQL armor is just a matter of adding a few envelop plugins:\n\nThis example can be found in our example repository\ngithub.com/dotansimha/graphql-yoga","join-us-in-building-the-future-of-graphql-security#Join Us in Building the Future of GraphQL Security":"Escape's team is actively working on improving Armor and its support for Yoga Server This is just\nthe start of a great collaboration between our teams to ensure better security for the whole GraphQL\necosystem. There is much more to come! Feel free to come on Armor's GitHub to ⭐ star, 🗣️ discuss,\n🎉 ask them for new features, and more:github.com/Escape-Technologies/graphql-armorTalk to you soon! 🤟"}},"/blog/injectable-services-in-react":{"title":"Injectable services in React","data":{"":"","how-theyre-implemented-and-their-similarities-with-angular-services#How They're Implemented and Their Similarities with Angular Services":"React provides a fantastic API for building components. It's light-weight and intuitive, and became\na sensation in the dev community for a reason. With the introduction of the most recent API\nfeatures: hooks and\ncontext/provider, components have became not only more\nfunctional, but also more testable. Let me explain.So far, when we wanted a component to use an external service, we would simply implement it in a\nseparate module, import it, and use its exported methods, like so:\n\n\n\n\nKeep in mind that this is NOT how I would actually write my code in production, there's no error\nhandling, and both components are defined under a single module which I don't see as a good\npractice, but for demonstration purposes it's more than enough.\nThe components above would work well within a React app, because essentially they can achieve what\nthey were implemented for. However, if we would like to unit-test these components, we would\nencounter a problem, because the only way to test these components would be via e2e tests, or by\ncompletely mocking the fetch API. Either way, the solutions are not in our favor. Either we\ncompletely overkill it with testing, or we make use of a not-so-simple mocking solution for an\nENTIRE native API. Below is an example:\n\nIf so, how does one suppose to overcome this problem?","lets-learn-from-our-angular-fellows#Let's Learn from Our Angular Fellows":"I know what you're probably thinking right now… What is this guy thinking, promoting Angular design\npatterns which are completely no match for the great React. First of all, React is not perfect, and\nalways has places for improvements. If it was already perfect, they wouldn't have kept working on it\non Facebook. Second, I like React, and I believe in it very much, this is why I would like to make\nit better by ensuring best practices. So before you close your tab in anger please continue reading\nand listen to what I have to say :-)In the Angular team, they came up with a clever approach. Instead of relying on hard-coded imports,\nwhat they did they provided a mechanism that would let us inject our services before we initialize\nthe component. With that approach, we can easily mock-up our services, because with the injection\nsystem it's very easy to control what implementation of the services is it gonna use. So this is how\nit would practically look like:\n\n\n\nAnd now if we would like to test it, all we have to do is to replace the injected service, like\nmentioned earlier:\n\nTo put things simple, I've created a diagram that describes the flow:","applying-the-same-design-pattern-in-react#Applying the Same Design Pattern in React":"Now that we're familiar with the design pattern, thanks to Angular, let's see how we can achieve the\nsame thing in React using its API. Let's briefly revisit\nReact's context API:\n\nThe context can be seen as the container that holds our service, aka the value prop, as we can see\nin the example above. The provider defines what value the context will hold, so when we consume\nit, we will be provided with it. This API is the key for a mockable test unit in React, because the\nvalue can be replaced with whatever we want. Accordingly, we will wrap our auth-service.python:\n\nAnd we will update our component to use the new useAuth() hook:\n\nBecause the useAuth() hook uses the context API under the hood, it can be easily replaced with a\ndifferent value. All we have to do is to tell the provider to store a different value under its\nbelonging context. Once we use the context, the received value should be the same one that was\ndefined by the provider:\n\nOne might ask: “Does this mean that I need to wrap each and every service with the context API?”,\nAnd my answer is: “If you're looking to deliver an enterprise quality React app, then yes”. Unlike\nAngular, React is more loose, and doesn't force this design pattern, so you can actually use what\nworks best for you.Before I finish this article, here are some few things that I would like to see from the community,\nthat I believe will make this work flow a lot easier:\nHave a 3rd party library that would wrap a service with the context API and would simplify it.\nHave an ESLint rule that will force the usage of injectable React services.\n\nWhat do you think? Do you agree with the design pattern or not? Are you going to be one of the early\nadopters? Write your thoughts in the comments section below. Also feel free to follow me on\nMedium, or alternatively you can follow me on:\nGitHub\nTwitter"}},"/blog/introducing-envelop":{"title":"Introducing Envelop - The GraphQL Plugin System","data":{"":"Today we are super excited to share with you a new open-source library we've been working on for\nthe past few months!","tldr#TL;DR":"Envelop aims to be The GraphQL Plugin system (envelop.dev)\nEnvelop is not a GraphQL server, it's just a wrapper on top of the GraphQL engine.\nMake “hard” GraphQL capabilities easy by installing powerful plugins\n(Caching, Tracing with\nPrometheus/DataDog/NewRelic/Sentry/OpenTelemetry/ApolloTracing,\nLoggers,\nGraphQL-Jit,\nPersisted Operations, Security with\nrate-limit/depth-limit/Auth0\nand many others from the Plugins Hub)\nSolve once and share across the ecosystem - Each plugin works with any HTTP server or\ndeployment (Express/Fastify/Netlify/Vercel/AWS Lambda/Azure Functions/Cloudflare Workers/Google\nCloud Functions) and any schema builder (SDL, Apollo Federation, Nexus, TypeGraphQL and others)\nFramework for Frameworks - Envelop will become the new basis for GraphQL Frameworks.\nIt's already available if you are using RedwoodJS,\nand we have PRs open for Loopback, NestJS, Parse and others.\n\"Babel for GraphQL\" - Envelop also aims to be the \"enrichment layer\" for GraphQL. You can use\nany new GraphQL Features today (@defer/@stream, @live queries, @oneOf and any open RFC\nalready today, even if graphql-js has not yet implemented or released it)\nenvelop is also available on ProductHunt!","overview#Overview":"Envelop is a lightweight library that allows developers to create plugins that enriches the\nGraphQL execution layer with new features. It's the plugin system for your GraphQL layer.Envelop's core is based on hooks and plugins - we believe that developers should share and\nopen-source small pieces of implementation and logics that can help others, while still keeping\ntheir codebase customized to their needs with full control and power.Envelop is schema-agnostic and HTTP-server agnostic, meaning that it can be integrated with\nany kind of setup. We do not aim to provide a complete, vendor-locking suite, since we believe that\nthe developer should be able to adjust any part of their application, at any time, without major\nimplications.As with any open-source created and maintained by The Guild - we created Envelop based on real-life\nuse-cases, coming from our clients (startups, enterprises and our own products) and from the GraphQL\ncommunity. We strive to keep our open-source modern, well maintained and always up-to-date, and\nsupport the community around it.","background#Background":"While working with many clients on GraphQL projects, we noticed a major gap in collaboration across\nprojects, and a gap in knowledge sharing.Things were overcomplicated, and GraphQL servers just kept reinventing the wheel.We believe these gaps were created because many GraphQL frameworks are focused on creating a “whole”\nexperience, sometimes to promote their stack/product, rather than introducing real flexibility for\ndevelopers.Also, as GraphQL keeps evolving with new capabilities and solutions, it seems like the GraphQL\nframeworks are making it hard or even impossible to use these new features like @defer /\n@stream, @live queries, @oneOf and other new GraphQL features.We tried to locate the core of that issue, and from our point-of-view, it seemed like GraphQL was\nmissing a robust, simple and flexible plugin system. That's why we created Envelop.While most existing implementations of GraphQL servers/frameworks introduce feature-rich\nenvironments, Envelop aims to introduce only hooks on top of the original GraphQL functions, without\nmodifying the signature, and allow you to choose the features that you need, by adding Envelop\nplugins.Most existing GraphQL servers are implemented in a way that implements schema building and HTTP\nserver integration, meaning the features that are only relevant to the GraphQL layer “leaks” and\ncreates a very opinionated product.We believe that the Network Transport <> GraphQL Engine <> GraphQL Schema coupling should be\nseparated, and each part should take care of it's role, without mixing these features. Each layer\nhas its own responsibility.That's why we decided to create an agnostic library where you can choose your transport (HTTP /\nWebSocket / anything else), choose your schema (any schema builder works with Envelop), and Envelop\nwill take care of the extra features.We also felt that for too long things haven't been moving on the server area when it comes to\nGraphQL - most servers are in maintenance/support mode and don't bring anything new.Many extra features of GraphQL are straightforward, but not available for developers since it's not\nopen-source (or, bundled into specific frameworks/servers), or not transparent enough (like,\ntracing, metrics, auditing, fine-grained permissions and more). We aim to change that.","the-envelop-approach#The envelop Approach":"One of the goals of Envelop is to allow developers to modify/enrich their GraphQL execution layer.In most implementations, running a GraphQL operation consists of the following actions:\nparse - takes raw GraphQL operation string and converts it into an executable DocumentNode.\nvalidate - AST based validations, that checks the DocumentNode against the GraphQL schema.\ncontextBuilding - builds a GraphQL execution context, based on the incoming request, and\nprepares for the execution.\nvariables - parses the input variables and builds the variables object.\nexecute - takes a GraphQL schema, operation DocumentNode, variables and context and runs your\nresolvers.\n\n\nThere are more phases, and more workflows - It's dropped only for brevity ;)\nEnvelop allows developers to create plugins that hook into any phase, and change the behaviour of\nit, based on the feature it implements. The output of envelop are the GraphQL functions, with the\ninjected behaviour based on the plugins you use.\n\n\nVery initial draft of what Envelop is.\nBy creating these plugins, you can create custom behaviour in a very easy way.Let's try to break a few plugins and understand how it works:\nuseLogger - hooks into the “before” of all phases, and just does console.log.\nuseTiming - hooks into “before” and “after” of all phases, measures times, and then prints it.\nuseParserCache - hooks into before and after the parse phase and implements caching based on\nthe operation string.\nuseGraphQLJit - hooks into execute phase and replaces the execute function with\nGraphQL-Jit's executor.\nusePersistedOperations - hooks into parse and replaces the parse function with a function\nthat maps a hash into a DocumentNode.\nuseGenericAuth - hooks into context building and resolves the current user from the GraphQL\nrequest, then hooks into the execute phase to verify the user authentication.\nuseOpenTelemetry - hooks into all phases, execution and resolvers, and creates Spans for\nOpenTelemetry tracing.\n\nMakes sense, right? Because if you have control of all the execution pipeline, you can easily\ncreate very sophisticated plugins that implement things that were missing before with GraphQL,\nwithout changing/forking GraphQL.","getting-started#Getting Started":"To get started with Envelop, make sure you understand the other requirements that you need:\nYou need a GraphQL schema - it doesn't matter how you created it (either with GraphQL core\nlibrary, makeExecutableSchema, or any code-first / schema-first frameworks)\nYou need a HTTP server - like express, Fastify, Koa AWS Lambda or others\nYou need a request normalization and GraphQL request pipeline - we recommend\ngraphql-helix for that.\n\nYou can also find more in-depth article and technical documentation hereTo get started quickly, start by installing only @envelop/core package in your project:\n\nNow, take a look at the following code snippet - it creates a /graphql endpoint, normalizes the\nincoming request with graphql-helix, creates the GraphQL functions with Envelop and runs the\noperation:\n\nWith that example, we only used useLogger, so while executing GraphQL operations, you should see\nthat everything you do should be printed to the log.","use-plugins#Use Plugins":"But logging is not everything possible with Envelop. By adding more plugins, you can add more\nfeatures to your GraphQL execution, based on your app needs.For example, here's a cool snippet for boosting things in your execution layer:\n\n\nBy using useParserCache we make sure to parse every unique operation only once. By using\nuseValidationCache we make sure to validate every unique operation only once. By using\nuseGraphQLJit we replace the default execute function with a\njust-in-time implementation.\nWhile working with our clients, we saw that many pieces of code can be moved into an Envelop plugin,\nand shared with the community. That created tons of plugins that you can now use quickly, without\nimplementing it on your own for that specific project!We also created Envelop Plugins Hub : a place where you can find all\nthe plugins that are available for Envelop, with their documentation, versions, and some stats.\nPlugin Hub is open and available for the community to add their own.","write-your-own-plugins#Write Your Own Plugins":"Writing plugins for Envelop is super simple. We allow you to write code that connects to the phases\nthat you need, and we'll make sure to run your functions at the right time.Plugins can either live as internal plugins that are relevant only to your project, or you can share\nit with the community as NPM package.To get started with a custom plugin, choose what phases you need, and create functions that handle\nwhat you need. Envelop will provide a low-level, flexible api in each phase, so you can communicate\nwith the core pipeline.\n\nYou can find here the complete plugins documentation","sharing-envelops#Sharing envelops":"In many cases, developers are looking for a way to reuse their server setup, as a\nboilerplate/template. Envelop allows you to create Envelops instances and later share it with\nothers.\n\nSo if you are working in a microservices' environment, or in an enterprise that has many servers -\nyou can now share the entire base GraphQL setup in a single variable, and extend it based on your\nneeds.You can read more about sharing/composing envelops here","babel-for-graphql---new-features-for-the-graphql-engine#\"Babel for GraphQL\" - New Features for the GraphQL Engine":"Since we allow developers to take part in any phase of the execution, it means that you can easily\nadd new features for the GraphQL engine, and not just features that come on top of GraphQL.For example, one of the Envelop plugins\n(useExtendedValidation) allows developers\nnow to write and run GraphQL validations, with access to the operation variables. That means you can\nwrite simple validations now without making it part of your schema.One of the things that is also possible now is @oneOf - a spec suggestion that is still in\ndiscussion for adding input unions, but already available for you if you use Envelop, because\nextended validations can access variables and can do additional things that was difficult to do\nbefore.Here are some additional examples for cool new plugins:\nperEventContextResolver: suggested in\nthis PR, and almost\navailable in envelop.\n@oneOf: suggested in this PR, and now\navailable in envelop.\nMigrate operations - a new suggestion for\nmigration GraphQL operation during parse, which allows simpler flow for introducing breaking\nchanges.\nPublic schema filter - for creating a\nsimple GraphQL schema that can be used for public APIs based on existing GraphQL schema.\nuseOperationFieldPermissions - a\nplugin that allows you to check if the fields queried in an operation are allowed for a user\nbefore execution starts.","adoption-and-migration-path--framework-for-frameworks#Adoption and Migration Path / Framework for Frameworks":"If you are already using GraphQL, you are probably using a server that comes with all the features\nbuilt-in. This is great in some cases, but if you wish to have that extra flexibility, you can\nmigrate to Envelop. You can even use Envelop with other server frameworks without migrating the\nentire pipeline (see examples section below).GraphQL is also widely adopted in the JAMStack world - and libraries that offer GraphQL out of the\nbox migrate to Envelop to simplify parts of the code, and to allow their users to extend the GraphQL\nlayer in a simple way.Redwood is a great example. We start with a small suggestion PR, and the\nRedwood team was open for new ideas - so\nnow you can use envelop if you are a Redwood user\n!Here is a thread about why Redwood now gives you the option\nto replace Apollo Server with GraphQL-Helix +\nEnvelop.During that process, we also start to work with other frameworks and support them with that:\nLoopback,\nNestJS,\nParse,\nApollo Server and others.We are also helping with that, so if you are migrating to Envelop and not sure what it\nincludes/means for your project - feel free to reach out to us (through\nGitHub, email or the chat box in our website)\nand we would love to help you with that.","examples#Examples":"Since we understand that Envelop doesn't come as a whole server, we create tons of examples you can\nuse for reference. We added examples for using several HTTP servers (express/fastify), running\ndifferent Functions/Lambda cloud providers, different schema providers (Type-GraphQL, Nexus)\nsubscriptions transports (SSE / GraphQL-WS), new GraphQL features like @stream / @defer and\nmore.You can find all examples and demos here","whats-next#What's Next?":"We are constantly working on improving the low-level API of Envelop, so if something is missing, you\ncan always reach out and report an issue. We are also adding more plugins based on our use-cases.Like with any other open-source maintained by The Guild, we always welcome you to share your\nthoughts, ideas, feedback, questions and issues. We also encourage developers to take an active part\nin the development of the products/libraries they are using - so if you think something you wrote\ncan benefit others - we can help with making it a reality!"}},"/blog/introducing-graphql-inspector":{"title":"Introducing: GraphQL Inspector","data":{"":"Prevent breaking changes. Find broken operations. Get Schema Coverage. Check deprecated usage and\ntype duplicates. All as part of your CI processThroughout almost three years of working with GraphQL, me and The Guild introduced solutions\nthat changed the way we write our projects today.In order to use GraphQL in our Angular applications, we created\nAngular Apollo. To automate and increase\ntype-safety, we open-sourced\nGraphQL Code Generator. Most recent thing\nwas GraphQL Modules that helped us to separate a server\ninto smaller, reusable, feature based parts. All of that was developed based on the experience and\nused with huge success by our clients.Today, I'm happy to introduce another piece of our tech stack, we call it\nGraphQL Inspector!\nGraphQL inspector is a tool that's main purpose is to make sure your GraphQL API and all its\nclients are well-developed.","key-features#Key Features":"Finds breaking, dangerous and safe changes\nwhen modifying a GraphQL API\nGitHub Application +\nGitHub Action (Bitbucket integration soon)\nCommand Line Interface\nCompletely free and open-source — host your own GraphQL Inspector\nSchema coverage **—**see unused\nparts of Schema based on all your clients' fragments and operations\nValidates operations against a\nGraphQL Schema — you notice errors before run-time!\nFind duplicates or similar types","use-it-in-github#Use It in GitHub":"We offer GraphQL Inspector as a GitHub Application that you\ncan install in any of your repositories within a single click. That's the easiest way possible to\nstart using Inspector.","inspector-as-part-of-your-workflow#Inspector as Part of Your Workflow":"In order to use GraphQL Inspector, you need to make sure you write an entire GraphQL Schema to a\nfile so Inspector could see it. Git hooks fits well here. Whenever there's a new commit, the file\nwill be updated.Next, you configure GraphQL Inspector in package.json :\n\n\nYou can read more about that in\n“Github Application” chapter on\nour website.\nNow, whenever someone submits a Pull Request the GraphQL Inspector will compare schemas and fail if\nthere are breaking changes.","github-actions#GitHub Actions":"I know GitHub Actions are not yet publicly available but if you're lucky enough, you can use them to\nhost your own GraphQL Inspector that is deployed and live per each commit or a pull request. Because\nan Action is temporarily executed with Docker, you won't use any Cloud service or any other paid\nresources.\n\nRight now, Actions are not the most enjoyable thing but because it's free and super easy to setup we\nhighly recommend to take advantage of it if you don't want to use hosted by us GraphQL Inspector.We don't store any data, the code is open-sourced and deployed with Netlify Functions.\nBecause we strongly believe in open-source, you can also have your own instance of GraphQL\nInspector up and running.","bitbucket-integration#Bitbucket Integration":"GraphQL Inspector doesn't support Bitbucket yet, but it's on top of our roadmap, and we're starting\nworking on it. If you need it, please reach out or comment on\nthe open issue.","prevent-breaking-changes#Prevent Breaking Changes":"GraphQL Inspector compares an old and a new GraphQL Schema in order to alert you about breaking\nchanges. It also tracks other changes, dangerous to implement and those that are entirely safe.This way you have a clear vision of how your Schema is developed.","schema-coverage#Schema Coverage":"The idea behind it is to see which part of your schema is used, how many times and by which\noperation. It only applies to documents that can be statically analyzed.Inspector is able to extract every fragment or operation from your TypeScript and JavaScript files.\nIt supports any kind of template literal tag but also .graphql files.","validate-documents-and-find-deprecated-usage#Validate Documents and Find Deprecated Usage":"In order to find out that your operation or fragment is broken you need to run an app and execute a\nquery or mutation. Thanks to GraphQL Inspector, you can easily check for errors or deprecated usage\nat any point of time.\n\n\nI recommend to make it as part of your CI or even git hooks.","find-duplicates#Find Duplicates":"Another interesting feature of Inspector allows you to find similar types and maybe even duplicates.\nIt's not something everyone might want to use but we found it really helpful when we were migrating\nfew separate GraphQL APIs to a monorepo and merging them into a single server at\nAir France — KLM. The person who could say more about that\nwould be Mart Ganzevles, who's the father of that particular feature, and it was his first ever\nopen-source contribution. Amazing work Mart!","desktop-application#Desktop Application":"We are going to work on a Desktop version of GraphQL Inspector to boost the whole experience even\nfurther. Imagine exploring everything in a nicely done and interactive application. You could click\non things in order to see them in details, just amazing!","other-features#Other Features":"Runs a GraphQL Server with faked data within a single command\nWrites an introspection result of GraphQL Schema to a file","how-does-it-compare-to-other-tools#How Does It Compare to Other Tools":"Apollo Engine GraphQL Inspector tries to solve a bit of a different use-case. The main idea\nbehind Apollo Engine is to get insights of how a GraphQL server behaves in production.It supports schema comparison too but the main difference is that we don't store any of your\ndata and in order to track changes, we simply take advantage of Git. Each change is available\nin git history, so the workflow is straightforward, and it's something you're already familiar with.Because of that, Apollo's advantage is that it takes into account production data and not only your\ncode. But if that is important to you, you can gather this data from your GraphQL servers today,\nstore it wherever you want, and we can add a feature to add this data into one of our reports.GraphQL Doctor and our tool have in common only the Schema Comparison feature, but Inspector\ntracks also changes that are safe to introduce. Doctor's main goal is to run within GitHub and\nprevent from breaking an API. We would love to collaborate with them, make sure we truly covered all\ntheir use cases and maybe merge their library into ours.","open-source-community#Open-Source Community":"In The Guild, we love open-source, our whole careers were possible because of that. We also\nfound out each other through Open-Source :)That's why I encourage you to help us develop GraphQL Inspector and let's build it together.Smallest piece of code, bug fix, documentation improvement or even a simplest suggestion counts as\ncontribution!","links#Links":"Website and documentation\nVisit the repository on GitHub\nCLI available — yarn global add @graphql-inspector/cli\nCheckout the GitHub Application\nSee an example app that uses\nGraphQL Inspector"}},"/blog/joining-graphql-foundation":{"title":"The Guild is joining the GraphQL Foundation","data":{"":"We are happy to announce that The Guild has joined the GraphQL Foundation as an official member!We are happy to join companies like Facebook, Twitter, AWS, Shopify, Apollo and\nothers in order to help shape the future of GraphQL and\nthe community.It is not cheap to be a foundation member, but we feel there is a big need and that we have a lot to\ncontribute for that important goal.We feel that because of our unique structure, we can contribute in unique ways to the\nfoundation.We want to open the core foundation work for the community, making it easier for all of you to\ncontribute and influence GraphQL's future.Here are the first things we are going to focus on, and we would love your help with them:","1-graphqlorg#1. GraphQL.org":"graphql.org is a very important website. It is important because it's the first thing beginners\nwould get to when starting with GraphQL. Making that first experience smooth and easy is crucial.The graphql.org website is very good, but it hasn't been updated for a couple of years now since the\noriginal creators finished with their current iteration.There are no active maintainers and contributions are being completely blocked.That leads to people getting stuck and following the resources and links into unmaintained tutorials\nand libraries.We've decided to invest time and improve the website as much as we can!Dipesh Wagle lead and @ardatan\njoined him and both have did some awesome work! Check out their PRs on the website, follow the\ndiscussions, let us know for any feedback or improvements you have and we would love your help if\nyou want to contribute!\nUpgrading graphql.org to Gatsby\nImproving graphql.org code's page","2-graphql-js#2. GraphQL-JS":"graphql-js is a powerful library that is engine behind many community libraries today.Ever since it was originally created by Lee Byron, which has done an amazing work creating a library\nthat is still so powerful and relevant, not a lot of major changes has happened.That is a good thing, but with time came more needs for updates and improvements.The current biggest improvement that is waiting is the TypeScript migration. It has been planned for\na couple of years now but not a lot of progress has been made.We are going to change that now. Please follow the issue, read throughout the discussion to see what\nwas planned and what happened, and help us unlock the work and make real progress towards a full\nmigration.","roadmap-to-typescript-issue#Roadmap to TypeScript Issue":"This also holds back many other things like the great work that has been done on\nstream and defer (the current plan is to merge\nthat into master only after that python migration has been done).We are actively working on it and now is the perfect time to join and help us with that effort.\nReach out and let us know if you can help and how we could support you with anything you need.Also, please join the new\ngraphql-js working group sessions.","3-community-forum#3. Community Forum":"Today the GraphQL community is scattered across many different forums. That's ok, but having a\ncentral place to talk about common issues can be good, because it means you won't have to lock\nyourself into specific solutions in order to solve common problems. We believe there is importance\nof talking about shared best practices, no matter what tools and languages you use.We also are to blame for that as we've created our own Discord channel. The reason is that the\nofficial GraphQL Slack wasn't being promoted and that the history of the messages there was being\ndeleted.We want to merge our own popular forum into the official GraphQL forum and revive the discussions\nthere and hope others would follow. For that we need to decide on the right solution. Please\nfollow the relevant issue and share your\nthgouhts.","4-graphqls-general-growth-in-the-community#4. GraphQL's General Growth in the Community":"Everyone here is working on GraphQL because we think it's a good idea :)So we would love to see GraphQL grow and spread.Currently, the foundation hasn't been doing a lot of promotion and using it's assets like that\nwebsite, social accounts and things like that. One thing we believe could be valuable is a monthly\nnewsletter from the foundation. But instead of inventing a new one, we thought it was a better idea\nto collaborate with the existing ones.So we've reached out to Prisma, which owns the GraphQL Weekly newsletter and has been maintaining it\nfor years and decided to partner with them to spread the fondation's messages!Our goals are to help open the doors for anyone who wants to be part of the community, learn and\ncontribute!Everything we wrote above is just the start, and we want to hear from you how we could improve the\nGraphQL community as a whole.We hope that our work would help you acheive that, but we mostly want to hear from you - what are\nthe things that stop you from contributing and influencing the community? Let us know and let's\nchange that together!"}},"/blog/magical-babel-plugin-for-react-performance-boost":{"title":"Babel plugin and get a performance boost for your React components","data":{"":"With the introduction of React hooks (in React 16.8-alpha) arose an issue — calculations are being\nunnecessarily re-evaluated due to declarations being done within the rendering phase.To put things simple, if now we're using class components, and we store calculation results on the\nclass instance to save ourselves some precious processing power:\n\nIn the near future, we will have no choice but to do everything within the rendering method itself,\ndictated by hooks:\n\nTo solve this problem, the React team invented a couple of methods: useCallback() and useMemo().\nEach of them is used for different reasons but they're quiet similar, and essentially they're used\nas guard functions that will re-activate themselves only if certain parameters were changed. I\nrecommend you to go through the\nofficial React docs to get a better\nperspective on these. If we were to implement it in the example above, it should look like so:\n\nWait a minute… So does it mean that I have to wrap all my declarations in these hooks just to get\nperformance which is on a par with class components?!\n\nThat's right Vladimir. Even the React team suggested that, and I quote from their docs:\n“In the future, a sufficiently advanced compiler could create this array automatically” — React\nIt's a good thing I love React and I think of the future. That's why I invented this Babel plug-in\ncalled babel-plugin-react-persist, and it addresses exactly that issue! All you have to do is edit\nyour .babelrc file and the code will be automatically transformed! Not only that, the plug-in also\ntakes care of optimizing inline anonymous functions in JSX attributes. This way each rendering phase\nwill have a similar instance of the intended callback. So given the following code:\n\nThe plug-in will generate:\n\nSo what are you waiting for? Go visit the official\nGitHub repo and get yourself a copy of the\nplug-in! Have any suggestions or feature request? Feel free to open a ticket in the\nrepo's issues page or comment below!"}},"/blog/manage-circular-imports-hell-in-graphql-modules":{"title":"Manage Circular Imports Hell in GraphQL-Modules","data":{"":"Designing and building modular GraphQL API may not look straight-forward the first time you start.\nIt is hard to keep a perfect modularity with standalone and encapsulated modules.It is really easy to appeal to the circular imports, but that's exactly what you shouldn't do in any\ncase. You might say while reading this; I DON'T HAVE ANY WAY OF NOT CREATING CIRCULAR IMPORTS!In a previous versions of GraphQL-Modules, we used to allow users to have circular imports in their\nGraphQL-Modules applications. However, it created a lot of extra logic which slows down the initial\nschema generation speed, because we always need to check if there is circular imports between\nmodules.Then, if GraphQL-Modules found some, it would merge all the members of this circular import\ninto a one LARGE MODULE which was breaking almost every principle of encapsulation and\nmodularity we mentioned in previous blog-posts of our GraphQL-Modules series.Finally, we decided to remove this support; then force people to have strict modularity\nin their projects.\n\nForcing people out of a way of developing is always hard, and we've got\nquestions from you about how to solve some\nspecific issues — so in this blog post and new doc section we will help you understand why this was\na bad practice and how to migrate from it with different use cases.","the-problem#The Problem":"Let's assume we have 3 different entities in our database;\nUser\nPost\nComment\n\nThen, if we create three different modules for these three entities;\n\n\n\n\n\nAs you can see above, every module imports other modules; and this creates a circular dependency.You might ask if this is the only way to implement modules for these entities; because it looks like\nthere is no point to have different modules for those schemas. Having circular dependency is the\nsame situtation with having a single large module.","how-to-solve#How to Solve":"Let's see what we have in terms of relationship; - User doesn't depend on Post and Comment -\nPost doesn't depend on Comment.\nComment depends on User and Post, because it has userId and postId fields - Post also\ndepends on User because it has userId field\n\nSo let's create modules in that way,\n\n\n\n\n\n\nUsing this approach, you will have standalone modules; otherwise will create a big module which\ncontains all of them like we used to handle circular deps in this way (merging all circular\nimports).\nAlso extend says that it needs a main definition from imported modules which makes the connection\nmore readable in terms of entity relations.","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/meteor-with-webpack-in-2018":{"title":"Meteor with Webpack — Faster compilation and better source handling","data":{"":"","introduction-to-meteor-webpack#Introduction to Meteor-Webpack":"Meteor is a complete full stack framework for fast-start on your real-time web\napplication. I don't focus on that for now.\n\nWebpack is a great bundler to compile your code including view templates,\nassets and the all stuff on your application.However, Meteor already has its own built-in bundler; but it needs some challenging tricks when\nyou're working with ES2015 external npm dependencies or any compilation methods.Meteor-Webpack is here as a solution to this kind of problems and lack of features in Meteor's\nbundler.","why-do-you-need-this#Why Do You Need This?":"For example, you have a Progressive Web Application using Service Workers, written in Angular, then\nyou have to create a service worker manifest based on your output files. We don't have a solution\nfor this on Meteor CLI natively. However, Webpack has a lot of community plugins such as\nOfflinePlugin ,\nWorkbox and many others\nfor this problem as a solution. Just install them, and add to your\nwebpack.config.js . Meteor-Webpack will handle it like\nyou're working on a pure Webpack project.Other example is server-side rendering. Angular CLI is based on Webpack,\nand the project can be compiled for SSR by Angular CLI; but you need a different server application\nto serve your Angular Universal application separate from Meteor backend. By using Meteor-Webpack,\nit is possible only by ejecting Angular CLI's webpack.config.js , and use it on Meteor project.","hot-module-replacement-even-for-server-beta#Hot Module Replacement, Even for Server (Beta)":"Reloading on recompilation while developing your app may take a lot of time. HMR comes to save us\nfrom this time loss on development. If you don't know, what HMR is. You can\ncheck out Webpack's documentation.Meteor-Webpack integrates\nwebpack-dev-middleware and\nwebpack-hot-middleware to benefit HMR\nin your project. The only thing you have to do is enabling this feature just like any other Webpack\nproject;\n\nAlso, you can use HMR for server side. Meteor-Webpack supports\nwebpack-hot-server-middleware , that\nreplaces changed modules on your server without restarting all Meteor server. This also provides a\nlot of benefits on development.","more-examples#More Examples":"There are more examples in the repository;\nhttps://github.com/ardatan/meteor-webpack"}},"/blog/multiple-environments-endpoints-graphql-inspector":{"title":"Multiple environments and endpoints in GraphQL Inspector","data":{"":"One of the features introduced with the new version of GraphQL Inspector is a support for multiple\nvariants of GraphQL schema and ability to use live and running GraphQL endpoints.We recently released a lot more interesting features. You can read about them in\n\"New GraphQL Inspector and upcoming features\" article.Here, we're going to focus on environments and endpoints only.","using-environments#Using Environments":"The previous iteration of GraphQL Inspector worked with only a single target branch. Every Pull\nRequest was checked against the default branch of Git repository. We can agree, it's not ideal :)The new version allows to define as many environments as you wish. We called them \"environments\"\nbut those are just variants of GraphQL schema. You may have production environment as well as\nstaging and QA.\n\nUsing multiple environments means:\nnotifications narrowed down to each variant of schema\nability to define different settings per environment\n\nFollow the \"Using Environments\" chapter\nin our docs.","using-endpoints#Using Endpoints":"We highly recommend to use branches to identify environments but GraphQL Inspector is here to help\nand not force any opinionated patterns.That's why the new version introduces a way to use live and running GraphQL endpoints as the\nsource of truth of schema.This approach is very useful when you don't deploy an API on every Push and your default branch is\nfine with temporary breaking changes. To learn more, read\n\"Using Endpoints\" chapter.","future-plans#Future Plans":"We're working on Azure and Bitbucket integrations plus a monitoring feature. Talk to us to\ntry it out.We want to make Azure and Bitbucket a first-class citizens in GraphQL Inspector and give you\nthe same experience as you get right now with GitHub.Monitoring will enable you to analyze the traffic of your GraphQL APIs and provide details\nneeded to improve performance. Collecting information about the usage will let you safely remove\ndeprecated pieces of GraphQL Schema.\nIf you're interested, please reach out to us!","enjoy-graphql-inspector#Enjoy GraphQL Inspector!":"We have big plans for Inspector, and you're very welcome to join us in that journey.GraphQL Inspector is a tool created by developers, for developers and that's why we'd love to get\nyour feedback and shape GraphQL Inspector together!Oh... and it's Open Sourced!"}},"/blog/modular-encapsulation-graphql-modules":{"title":"Modular Encapsulation in Large-Scale GraphQL Projects","data":{"":"TL;DR: If you are writing a large-scale project, it's necessary to understand the relations\nbetween your pieces of code, and how they effect each other. Otherwise, it might be difficult to\ndeal with changes later.While developing a large-scale project, removing, changing and modifying parts of the project\ncan become a very time-consuming and risky task, because understanding the full side-effects of\nthose changes is very hard.In GraphQL-Modules, you can declare your modules in a feature-based\nstructure, with clear enforced boundaries and avoid unexpected side-effects during development.Each module can declare its own scope of the complete schema:![](/medium/c806f0ae70dca7a4d1e434736f241ed5.png 'Every module has its own schema, context and DI\ncontainer. Here you can see AuthModule is appended to UserModule. But, other modules don't import\nAuthModule. So, they cannot access directly AuthModule DI container or context.')Each module has its own schema, context, typeDefs, resolvers, and\nbusiness-logic and each module is encapsulated, which limits the module's access to only its own\nparts of the schema.So, what's the real benefit of this?Let's assume you have an authentication module;After a while, you decided to use AccountsJS in your GraphQL project which has\ncompletely different implementation than the existing one.This can be a risky change, because you're afraid of breaking a lot of things, and you can't be sure\nabout the all the places in your code that uses values affected by the authentication module, for\nexample the global context.With GraphQL-Modules' approach of encapsulation, even the context is completely encapsulated, so\nevery module that uses your existing AuthenticationModule's context in defined on the\nimports of the dependent modules, and its interface is already extended by\nAuthenticationModule's context if you're using TypeScript. When it is removed, you\nwill notice that change on compile-time immediately.Let's take a look at some code, to show how GraphQL Modules makes you create those dependencies\nexplicitly.AppModule is our top Application Module;\n\nAnd there is another module that tries to use AuthenticationModule's context, but it doesn't\nimport AuthenticationModule. In this case, it is not possible to get anything from\nAuthenticationModule in the resolvers, because it is not imported. The following module doesn't\nknow anything about AuthenticationModule.\n\nTo fix this, we need to import AuthenticationModule into that 'important' module to make it able\nto access AuthenticationModule's context like below;\n\nSo, these examples above show us that the encapsulation can be very important in the long term of\nour project development.We think modular approach is not just merging schemas and concatenate context factory functions to\neach other.Having a tool that knows how to encapsulate modules and force this policy, makes it much\neasier to write modular schema, and later, even reuse existing modules and share them across\nmultiple projects.\nGraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/new-graphql-inspector":{"title":"New GraphQL Inspector and upcoming features","data":{"":"","hi#Hi":"We want to tell you about the new version of GraphQL Inspector. It's been a while, but it's finally\nout, and we have BIG plans for it.","what-is-graphql-inspector#What Is GraphQL Inspector?":"It's an entirely open-sourced and community\ndriven tool to help you improve and maintain your GraphQL stack. It comes with a CLI, GitHub\nApplication and GitHub Action. You can read more on our website.","why-should-i-read-the-announcement#Why Should I Read the Announcement?":"First, Inspector is free and has a bunch of new exciting features. Plus, the announcement is\nshort, so you can quickly read it and move on to watch Tiger King or whatever...","whats-new#What's New?":"Short overview of new features, each of them has a dedicated article with explanations and details.Links to those articles:\nSchema Change Notifications\nEnable Remote Control in GraphQL Inspector\nValidate GraphQL Schema in any Continuous Integration and Delivery Pipeline\nMultiple environments and endpoints","schema-change-notifications#Schema Change Notifications":"Stay up to date with changes in your GraphQL Schema. Receive notifications on Slack, Discord or even\nvia WebHooks.","remote-control-of-pull-requests-via-http-endpoint#Remote Control of Pull Requests via HTTP Endpoint":"Intercept schema changes via HTTP and decide which changes are acceptable which are not and all of\nthis through a serverless function.","multiple-environments#Multiple Environments":"The new version allows to define as many environments as you wish. We called them \"environments\" but\nthose are just variants of GraphQL schema. You may have production environment as well as staging\nand QA.","graphql-endpoints#GraphQL Endpoints":"Use live and running GraphQL endpoints as the source of schema. This approach is very useful when\nyou don't deploy an API on every Push and your default branch can live with temporary breaking\nchanges.","cli-for-cicd#CLI for CI/CD":"GraphQL Inspector since day one supported any kind of Continuous Integration and Delivery Pipeline.\nNothing new here, except now it's more flexible and super lightweight.The new version of GraphQL Inspector comes with a CLI crafter specifically for CI/CD.","and-a-lot-more#And a Lot More...":"We highly recommend to visit graphql-inspector.com and explore all\nthe possibilities.We're working on Azure and Bitbucket integrations plus a monitoring feature. Talk to us to\ntry it out.We want to make Azure and Bitbucket a first-class citizens in GraphQL Inspector and give you\nthe same experience as you get right now with GitHub.Monitoring will enable you to analyze the traffic of your GraphQL APIs and provide details\nneeded to improve performance. Collecting information about the usage will let you safely remove\ndeprecated pieces of GraphQL Schema.\nIf you're interested, please reach out to us!","enjoy-graphql-inspector#Enjoy GraphQL Inspector!":"We have big plans for Inspector, and you're very welcome to join us in that journey.GraphQL Inspector is a tool created by developers, for developers and that's why we'd love to get\nyour feedback and shape GraphQL Inspector together!Oh... and it's Open Sourced!"}},"/blog/nodes-child-process":{"title":"Getting to know Node's child_process module","data":{"":"","how-to-call-git-cpp-sh-etc-from-a-nodejs-script#How to Call git, cpp, sh, Etc., from a Node.js Script":"Node.js is one of the most powerful platforms for managing resources on our computers and has become\nmore and more popular over the years ever since it was released. As much as it's great, and with all\nthe love and respect that I have for it, Node.JS alone is not enough.Despite NPM's evolved ecosystem there are more tools out there which exist outside of it for a\nlonger time, thus they do what they do better than any Node.JS package; such as opencv — an open\nsource computer vision utility library which was developed for C++, Python, and Java (not for\nNode.JS).In addition, Node.JS exists for a very general purpose while some tools exist solely for a single\npurpose; such as git — which exists for the purpose of version controlling.Accordingly, I've decided to write an article about Node's child_process module — a utility module\nwhich provides you with functions that can create and manage other processes.\n\nAs you probably know, our typical OS has different processes running in the background. Each process\nis being managed by a single-core of our CPU and will run a series of calculations each time it is\nbeing ticked. As such, we can't take full advantage of our CPU using a single process, we would need\na number of processes that is at least equal to the number of cores in our CPU. In addition, each\nprocess might be responsible for running a series of calculations of different logic, which will\ngive the end user a better control over the CPU's behavior.Accordingly, if until this very day you've been writing Node scripts which don't involve any\nreference to processes at all, you might have been doing it wrong, because you've been limiting\nyourself to a single core, let alone to a single process. Node's child_process module exists to\nsolve exactly that; it will provide you with utility functions that will provide you with the\nability so spawn processes from the main process you're currently at.Why is this module called child_process and not just process? First, not to confuse with the\nmain process instance global.process, and second, the child process is derived from the main\nprocess, which means that both can communicate - the main process will hold streams for the child\nprocess's std types, and they will both share an ipc channel (“Inter Process Communication”\nchannel; more on that further this article).The child_process module provides us with utility functions whose logics are stacked on top of one\nanother. The most basic function is spawn():\n\n\nDocs:\nspawn\nThe spawn function will spawn a new process of git log type. The first argument of the function\nrepresents a path for an executable file that should start the process, and the second argument is\nan arguments vector that will be given to the executable. The returned process object will hold a\nproperty for each std type represented as a Stream: .stdin - WriteStream, .stout - ReadStream\nand finally .stderr - ReadStream. Accordingly, if we would like to run git log through a Node\nprocess and print it to the console we would do something like the following:\n\nOr if we will take advantage of the last options argument, we could do the following:\n\n\nNote that every child_process function will also have a “sync” version of it (e.g.\nspawnSync()), but assuming that you're already familiar with synchronous and asynchronous\nfunctions in Node, I'm going to skip that for the sake of simplicity.\nThe next function on the list would be the execFile(). As implied, it will execute a given file\npath, just like spawn()does. The difference between the 2 though, is that unlike spawn() which\nreturns a bunch of streams, execFile() will parse the streams and will return the result directly\nas a string:\n\n\nDocs:\nexecFile\nHere's a snapshot of Node's source code that proves that execFile() is directly dependent on\nspawn():\n\n\nSource:\nlib/child_process.js\nAs bash is vastly used as the command line shell, Node provided us with a function that will span\nan instance of bash and execute the given command line. This function is called exec() and it\nreturns the stdout as a string, just like execFile()does:\n\n\nDocs:\nexec\nHere's a snapshot of Node's source code that proves that exec() is directly dependent on\nexecFile(), which makes it indirectly dependent on spawn()\n\n\nSource:\nlib/child_process.js\nIn other words, the core of exec() can be implemented like so:\n\nOften times, we would just spawn another Node process which would execute another script file, thus,\nNode has provided us with a function that is bound to Node's executable file path, called fork():\n\n\nDocs:\nfork\nWhat's nice about this method is that it will open a communication channel between the main process\nand the child process (known as ipc - Inter Process Communication), so we can be notified regards\nthe child process's status and act accordingly:\n\n\nSource:\nlib/child_process.js\nNow back to what I've said at the beginning of this article. Each process uses a single core of our\nCPU, hence, in-order for our Node script to take full advantage of our CPU we would need to run\nmultiple instances of Node, each one would have its own process. But how do we manage the work\ndistributed between the core?! Luckily, the OS does that for us, so by calling the fork() method\nwe actually distribute the work on different cores.Following this principle, a common use-case would be distributing the work of the script that we're\ncurrently at. So rather than calling the fork() method with the current script file path, we can\njust use the cluster module, which is directly related to child_process because of the reason\nI've just mentioned, and call the cluster.fork() method:\n\n\nDocs: cluster\nAs you can probably notice, the cluster API has some extra logic in addition to a regular\nprocess, but at its core it's just another process which was created by child_process. To prove\nthat, let's take a look at a snapshot taken from Node's source code:\n\n\nSource:\nlib/internal/cluster/master.js\nAs you can see, the cluster is directly dependent on the fork() method, and if we'll take a look\nat the fork() method implementation we'll see that it directly depends on the spawn() method:\n\n\nSource:\nlib/child_process.js\nSo eventually, it all comes down to the spawn() method; everything that node provides us with\nwhich is related to processes is just a wrap around it.There's definitely more digging to do when it comes to the world of processes, in relation to Node's\ninternals and outside it in relation to the OS. But after reading this you can make a practical use\nof one of Node's greatest features and unleash its full potential. Keep on reading the docs and\ninvestigating because it can definitely elevate your backed skills, and if you have any further\nquestions or topics that you would like me to write about (in the JavaScript world) do tell."}},"/blog/oss-contributor-workflow":{"title":"Easy Open Source - Orchestrating the Open Source Contribution Workflow","data":{"":"","tldr#TL;DR":"We released\nThe Guild's contributor guide\nContributor workflow\nVideo tutorials on how to contribute\nThe Guild's tooling\nfor maintaining open source libraries\nA new system for managing our repositories\n(Process based labeling system, issue templates)\n\nOpen source has revolutionized the way we build, collaborate and release software and there are\ndefinitely a lot of instances where the community of contributors and maintainers have taken the\nlead to make the projects thrive in the ecosystem and this is really exciting to see. Making open\nsource more approachable is beneficial for the maintainers, users and the contributors themselves\nthereby opening new paths for them that seemed harder before. And our strong belief is that\ncontributing to open source shouldn't be hard!","orchestrating-the-open-source-contribution-workflow#Orchestrating the Open Source Contribution Workflow":"But as anything goes, it is not without its own set of challenges. The number of open source\ncontributors is a tiny fracture compared to the number of users of our libraries.This advocates us to think of interesting solutions, as we believe many developers are missing out\non these opportunities to advance themselves and their careers.\"We see that as The Guild's core mission!\"After maintaining a huge list of growing open source projects over time being actively used by the\ncommunity, we, The Guild had quickly come to a realization that we really need a way to standardize\nour workflows considering everything we do in open source is modular and componentized thus\nincreasing the complexity of managing these projects.We wanted to share and \"open source\" our workflows so others could join us in this journey and\nbenefit, thereby making contributing more accessible for people.To give you an insight, these are some projects which we currently manage as individual\ncontributors:\nGraphQL Code Generator\nGraphQL Mesh\nGraphQL Tools\nGraphQL Modules\nApollo Angular\nGraphQL CLI\nGraphQL Config\nSOFA\nGraphQL-ESLint\nGraphQL Inspector\nGraphQL Hive\n\nAs you can see, the list goes on (for a good reason), and we have more interesting projects on the\nway which you can find here 😉And some major things which we were looking to do were to:\nEmpowering first contributors - Provide a great experience for beginners who want to contribute to\nany of these projects\nGive the maintainers an eagle eye view of all the projects and things to do to progress to the\nnext steps\nProvide a level of standardization in the contribution/development workflow of all these projects\nso that we don't have to re-invent the wheel every time, but rather spend time on the important\nstuff\nCreate a framework of sorts which works not only for the projects we work on in The Guild, but\nsomething which can work for other open source projects as well.\n\nThis led us to the creation of the\ncontributor workflow guide to\nhelp us standardize the workflow, guide beginners who would like to contribute and also act as a\nguide for other open source projects who are looking at a similar standardization approach (What we\nhave is an initial iteration of the guide and there is definitely a lot of room for improvement. If\nyou have any suggestions, do let us know - we are all ears 🙂)But does creating a guide suffice to achieve our goal? As you guessed, definitely not, and the guide\nwas just a start to an amazing journey ahead.Then we started thinking about the next important thing which we can address to make both\nmaintainer's and contributor's lives easier - LABELS","process-based-github-labels#Process Based GitHub Labels":"As simple as this feature may seem, labels/tags are the most important feature in any project\nmanagement tool, in this case GitHub because it gives us the ability to track the progress, the next\nsteps to be done and also communicate the same to various stakeholders, be it the maintainer or the\ncollaborator. Not just this, it can also act as a great way to onboard new collaborators who are\ninterested in contributing to the project.But you may wonder, labels are an already available feature of GitHub, what more can we do with it?The problem in our case is that considering every project had its own repository (as it should be)\nand everything evolved over time, we had different way of tracking issues in different projects, and\nwe followed our own sweet conventions and while this did the job for us when we started off this\nstarted getting complicated with more and more projects getting added to our portfolio every month.This is when we strongly felt the need to sync/orchestrate labels across all the repositories while\nalso respecting the differences between the projects (one size may not fit all). This led us to a\nproof of concept with different label syncing tools and after quite a bit of analysis, we landed on\nLabel Syncer to manage both master and repository\nlevel declarative labels (If someone from GitHub is reading this, maybe this should be an inbuilt\nfeature 😇)Doing this was pretty simple. You can find the repo\nhere which is used as the master repository to\npush all the labels downstream, and we still retain the repo specific labels in their own repository\n(like this)Now that a technical proof of concept was complete, the next question we had was \"What labels should\nwe standardize on as the master labels?\"Now, Urigo had an interesting thought process - since we had\nalready published the\ncontributor workflow guide,\nwhy not we label issues keeping the same in mind? All we needed to do was push an issue towards\nprogress from Step 1 to Step NThe goal here was to make it more obvious to anyone who arrives to an issue where exactly it stands\nand most importantly, what can you do to help advance the solution.Now, this is when we started putting labels against different stages in the workflow guide\nstandardizing on stages like this to start with:\nstage/0-issue-prerequisites\nstage/1-reproduction\nstage/2-failing-test\nstage/3-local-solution\nstage/4-pull-request\nstage/5-alpha-release-testing\nstage/6-released\n\nwhich is how most workflows look like for every project (Guild or even otherwise) - This is again\nthe initial iteration, and we will have more room for improvement over time, and you may see\nmore/lesser stages over time.The next thing we did was to prepare a set of\nstandard issue templates\nwhich remains almost the same across all our repositories. Again, a work in progress we will tweak\nthis as the need arises. This gives us an ability to suggest a standard template to file issues and\nPRs to all the new contributors asking for all the important details like the environment and\nversion they use, possible reproductions/screenshots, additional context and also providing them\nwith checklists to be actioned upon when filing an issue.While all this might seem very simple, doing this has a long term benefit of communicating your\nexpectations as a maintainer to the community when they are looking to contribute. Now, this is\nsomething which some projects tend to ignore.This journey has not concluded yet, and the next thing which we will be doing is labelling all the\nissues in all the repositories we manage appropriately against these stages which can give a better\nsense to both the maintainers and the contributors avoiding any ambiguity in the process.Now, these are just some ways in which we are looking at streamlining open source contributions and\nmake the projects thrive in addition to providing great docs, great test coverage, active\nmaintainership among other things, but we are also exploring other ways which we can use (if you\nhave any tips, do let us know 🙂)Our intention is not just to keep all this to ourselves but also help other open source projects and\nthe maintainers by sharing our thought process and hence this blog. If we find some other tips along\nthe way, we will make it a point to update this blog - so, do watch out for that 😉See you all soon in our next blog."}},"/blog/on-demand-shared-graphql-subscriptions-with-rxjs":{"title":"On-Demand Shared GraphQL Subscriptions with RxJS","data":{"":"GraphQL has native support for subscriptions as schema operations. GraphQL subscriptions allow to\nreceive continuous updates, usually implemented using a persistent WebSocket connection or\nServer-Sent Events.Ideally, we want subscriptions to be stateless and independent for every subscriber: when a\nsubscriber subscribes to an entity, this subscription is independent of any other subscription and\ncan be handled by any instance of our GraphQL server. This is the case when the entity subscribed to\nis \"simple\" and processing updates is trivial: for example, we receive events from a pubsub\nprovider/message queue (e.g. Redis, Nats.io, etc.) in the form { type: update, entityId: xyz }. In\nthis case, our subscription handler can simply subscribe to these events, filter on the requested\nentityId, and forward those events (maybe a bit processed) to the subscriber.However, this ideal scenario is not always possible. We might have \"complex\" entities we want to\nsubscribe to, e.g. views that are aggregates of data over several data sources. The view might be\nexpensive to fetch and subscribing to the view's content updates might involve subscribing to\nmultiple events and performing expensive processing and/or additional fetching in order to compute\nthe updates and send them to the subscriber.In this case, if multiple subscribers subscribe to the same view, the events' processing, additional\nfetching, and computing would have to be done for each subscriber, which will lead to performance\nissues as the number of subscribers increases.In this article, we'll show how we can improve this use case by sharing the subscriptions' sources\nand also perform their side-effect processing only when there are subscribers.\nThe solution uses RxJS, a library for Reactive Functional\nProgramming, it is based on the\nObserver pattern and provides a wide range of\nfunctions to deal with streams of events in a declarative\nway.","mutualizing-the-subscriptions-work#Mutualizing the Subscription's Work":"If the subscription is independent of the subscriber (e.g. the logged-in user) and only dependent\nupon the view, then we can mutualize the events' listening, buffering, processing, additional\nfetching, and computing required to update the view. This work can be done once and the result\ndelivered to each subscriber.","a-solution#A Solution":"","a-simple-example-to-illustrate-the-solution#A Simple Example to Illustrate the Solution":"In the following lines, we'll use a very simplified example in order to present the solution: a\nGraphQL subscription that produces sequential integers. Then we'll apply the solution to a more\ncomplex real-life example.The solution to the simple example is implemented in this\nrepository.","using-rxjs-multicasting-capabilities#Using RxJS Multicasting Capabilities":"By default observables are lazy and cold, meaning their side-effect are run only when a subscriber\nsubscribes to the observable. Furthermore, for every subscriber, the observable pipeline is\nexecuted.In the following example, the http query will be executed twice: query$ is a cold observable, no\nside-effect happens until a subscriber subscribes to it. When a second subscriber subscribes, the\nobservable side-effect is re-executed.\n\nThis is in opposition to Promises which are eager and hot: in this example the http query is\nexecuted only once.\n\nHowever, RxJS has multicasting capabilities to turn cold observables into hot observables. Using\nRxJS's multicasting operators, we can create observable pipelines which are shared: their\nside-effect is triggered when the first subscriber subscribes to it and when more than one\nsubscriber subscribes, the pipeline is executed only once and the emitted value is passed to all\nsubscribers.Let's see an example:\n\nHowever, using the share operator, the observable pipeline\nis executed once and the second subscriber (even subscribing later), gets the same (shared) result\nas the first subscriber.","sharing-the-observables#Sharing the Observables":"In the simple example above, we have multiple subscribers subscribing to a shared observable, in the\nsame context of execution. However, in GraphQL subscriptions, the 2nd (or nth) subscriber will have\nits own context of execution. If we want to reuse a shared observable, we have to store it.Let's create a module to manage the subscriptions' shared observables:\n\n\n\nNow from our GraphQL's subscription resolver, we can use it like the following:\n\nWith this code, when a subscriber subscribes, it will create the shared observable (publisher),\nstore it in a cache so that it can be reused by subsequent subscribers, and subscribe to it. When a\nsecond subscriber subscribes, it will get the existing publisher from the cache and subscribe to it,\nand it will get the same value as the first subscriber gets. When all subscribers have unsubscribed,\nthe source observable is unsubscribed. If later, a new subscriber subscribes, the source observable\nwill be resubscribed and its pipeline reexecuted (in our case, it will start emitting from 0 again).\nThe graphql-js engine expects the subscribe handler to return an AsyncIterable, so we use the\nrxjs-for-await package from Ben Lesh which contains\ndifferent functions from transforming an Observable into an AsyncIterable (there are different\nfunctions to deal with backpressure and lossiness/losslessness).\nSo far, so good. But we have a memory leak: after all subscribers have unsubscribed, we keep the\npublishers in the cache. We can clean those up using the\nfinalize operator: this operator allows running a\ncallback on observable termination (either the observable is complete or has no more subscribers).Let's modify our publisher factory function:","delay-the-shared-observable-cleanup#Delay the Shared Observable Cleanup":"Because the view might be expensive to fetch and update, we only do so when users are subscribing to\nit. In the previous example, as soon as all users have unsubscribed, the shared observable is\nunsubscribed and deleted from the cache. This might not be the desired behavior, e.g.:\nwe can have one user subscribing to the view, this user refreshes his browser's page, effectively\nending the subscription, and triggering a cache cleanup, but then the view is resubscribed almost\nimmediately, triggering a new fresh fetch\nwe can have one user stopping the subscription (e.g. navigating away from this view to another\npart of our app), but another user subscribing soon (a few milliseconds, seconds or minutes) after\n\nTo optimize for those use cases, we can delay the unsubscription of the shared observable when no\nmore subscribers are subscribing to it, using the resetOnRefCountZero config of the share\noperator. This is available in RxJS v7.\n\nIn the example above, after all subscribers have unsubscribed (refcount is 0) the connector (the\nsubject that subscribes to the source observable) now waits for 10 seconds (10000 ms) before it\nresets the shared observable. During this period of time, the observable pipeline continues to\nexecute. If a new subscriber subscribes before the timer has emitted, the refcount is again\ngreater than 0 and the connector will keep connecting to the source observable.\nWe use timer in this example but we can use any observable (e.g. receiving a specific event from our message queue) that emits at some point. Be careful though to make sure that the observable you use will actually emit otherwise you'll have a memory leak. To remedy this issue, you might want to add safety, e.g. using raceWith with timer to make sure you don't wait indefinitely:","reuse-shared-observable-sources-across-multiple-subscriptions#Reuse Shared Observable Sources across Multiple Subscriptions":"With this solution, we can even go further: if a subscription depends on the processing of common\nevents or on the source of another subscription, we can reuse the shared observable created for\nthose.Let's make a new subscription that returns a sentence with the current number emitted by the\ngiveMeInts subscription's source:\n\nAnd the new publisher reusing the other subscription's publisher:\n\nNow, whether a subscription to giveMeStringfiedInts or giveMeInts starts first, both will be\nshared and in sync. This further mutualizes the processing of expensive computations. In the simple\nexample showcased above, the advantage might be small, but in a real-world scenario, it could make a\nbig difference: imagine one subscription sending the full structure of a expensive-to-compute view\nwhile a second subscription sends only a diff of the current structure with the previous one, the\nsecond subscription's source depends on the source of the first. Mutualizing the view's computations\nmakes a difference regardless of which subscription has been triggered first.","run-server-side-logic-when-a-users-subscription-is-closed#Run Server-Side Logic When a User's Subscription Is Closed":"In GraphQL we implement subscriptions by writing two functions:\na subscribe function which is run one time only and must return an AsyncIterable\na resolve function which is run every time a value is emitted by the AsyncIterable returned by\nthe subscribe function and transforms this value into the Subscription output type.\n\nIn order to execute logic, we have 2 places: in subscribe when the subscription starts and in\nresolve on each emitted value. What if we want to execute logic when the subscription ends\n(whether it was completed or was stopped by the client)?The answer is: it is not contemplated in the spec. But it doesn't mean we can't do it. In fact, it\nis even very simple! If we use the solution described above, we already have all the pieces in\nplace. We only need to add one line: in the subscribe function where we set up the AsyncIterable\n(by transforming the Observable into an AsyncIterable), we only have to use RxJS's finalize\noperator.\n\nIn the previous examples, we used the finalize operator on the shared observable pipeline in order\nto clean up after all subscriptions to a specific entity had ended. But we can also use it per\nsubscription by piping it onto the shared observable: this way it is only run for when this specific\nsubscription ends. And of course, like we just did, you can combine both!","apply-to-a-real-life-example#Apply to a Real-Life Example":"Let's consider a view such as a complex \"playlist\": this playlist is a list of items organized in\nblocks, the items themselves are a complex aggregate of several multimedia (video, audio, graphics)\nobjects, those multimedia objects themselves might be aggregate (bundles) or have of some children\nobjects (e.g. sub-clips, graphics on a video, subtitles). In effect, this complex playlist is\norganized in the form of a tree of objects.The system emits different events:\nsome are related directly to the playlist itself (e.g. new item in the playlist, item removed from\nthe playlist, item changed position inside playlist)\nothers are related to the parent multimedia objects (object deleted, object's metadata changed,\nobject has new children objects)\nothers are related to the children objects of the top level objects (object deleted, object's\nmetadata changed)\n\nThis playlist's data is expensive to fetch, can be large, and is cached only when users subscribe to\nit: because it is expensive to compute updates, we want to ensure we don't process events for all\nplaylists in the system, only the ones some user is currently interested in.Let's reuse the techniques explained above.","buffer-events#Buffer Events":"First, we'll buffer the events, dedupe them and share the observable because those events will be\nchecked against every playlist subscribed to, so we can share the buffering and deduplication:","create-shared-publishers-for-the-playlists-structure-changes#Create Shared Publishers for the Playlists' Structure Changes":"In this example, we'll assume that the datasource is the source of truth, we'll listen to events to\ndetect potential changes in the playlist and we'll force refetch (invalidate cache and fetch latest\nversion) from the datasource (assuming calls are deduped using a Dataloader backed by a cache).","writing-the-subscriptions-resolver#Writing the Subscription's Resolver":"Now that we have all the subscription's required logic encapsulated and data processing shared,\nlet's use it from the subscription's resolver:","conclusion#Conclusion":"In this article, we have seen how to use RxJS (or the reactive programming library of your choice)\nin order to mutualize the generation of expensive-to-produce values for a GraphQL subscription but\nalso to trigger this processing on-demand whenever a consumer is interested in subscribing to a\nspecific entity updates and stop it (with or without delay) when there are no more subscribers. Note\nthat this technique is not exclusive to GraphQL subscriptions and can be used for any kind of\nsubscription."}},"/blog/react-app-out-of-a-webflow":{"title":"How to create a React app out of a Webflow project","data":{"":"tl;dr: It can be transpiled with a single command.As a freelancer I get to work with designers many times. Not once and not twice I have stumbled upon\nWebflow — a web design studio, where the designer can assemble all his assets\ninto responsive demonstrable webpages. These webpages look neat and responsive and can be downloaded\nas HTML/CSS files along with their scripts, images and fonts.At a glance, this can ease the process of getting an app done; after all we're provided with a\nworking website, so surely binding some logic to it with React shouldn't be too complicated, right?\nAll we need to do is take the HTML, put under a render()method of a React.Component, and\nimport its corresponding style with an external CSS file. Well, this is nothing but a walk in the\npark.When Webflow was first presented to me by a client of mine, I assumed the above. He showed me his\nwebsite, which looked quiet complete, and we've proceeded to composing a plan sheet, with all the\ndesired behavioral features of the future application and a matching price for each of that feature.\nI was quiet happy with our deal.On the next morning, I've received an email by my client's designer with all the exported assets by\nWebflow. When I looked around expecting to find the optimal starting point to go with it, my world\ncollapsed.The HTML files were big and massive, with lots of duplicated parts in it, the CSS was just a one big\nglobal style sheet with all the rules (that were very generic), and the images just had random\nmachine generated names. When I started to tear it apart into React components, I've called my\nclient after few hours of trial and canceled the plan; since the budget was limited, and I wasn't\nwilling to spend so much time on a project with a very little value in return.\n\n\nAbove: A Webflow page whose HTML file can be found\nhere. Credit:\ncampaignkit.co.“What shall I do then?!” — A React developer\nAppfairy is a CLI tool which can be easily installed using NPM and can integrate Webflow into a\nReact application with a single command.To get started, first install appfairy globally:\n\nNow let's think of what React components should exist in our application besides the main pages.\nOnce we identify them we should select their corresponding element in the Webflow project and set a\nnew attribute; the key's going to be af-el (Appfairy element) and the value should be set to the\nname of the component e.g. consult-form:\n\n\nAbove: Selecting the element and setting its attribute\nAt this point we're one step away from generating a functional ConsultForm React component; But\nbefore proceeding to the next step I would like to explain an important principle regards Appfairy's\ngenerated code's design pattern.Since Webflow's code is machine generated and for the most part is not optimal, we might encounter\npotential maintenance issues for 2 main reasons:\nThe target element we would like to update / attach event listeners to is hard to identify due to\ncomplexity of the HTML tree.\nWhen updating the design, we should also update our code by re-identifying the target elements and\nreattaching the React logic into them, e.g. mapping functions and event handlers like onClick().\n\nTo solve that problem, Appfairy takes on an old school approach where we separate the component into\na view and a controller, where we treat the view as a black-box and don't touch it while the\ncontroller is controlling what's going on in there; it would tell the view what to render, when to\nrender, and how to render.\n\nIn the picture above we have a schematic description which shows the view/controller flow. In a\nbrief, the controller holds elements which are proxies to the real elements, so whatever we pass to\nthe proxy will be forwarded automatically to the real element. A proxy and an element can be matched\nbased on the socket name (af-sock), which opens an interfacing point to the view by any given\ncontroller.So back to our ConsultantForm in our Webflow project example, let's think which elements should be\nbound to a certain logic. Generally speaking, a form has several input fields and a submit button,\nwhich will submit the data received by the inputs, therefore we would probably apply logic to these\nelements in our React controller components. Accordingly, we will define socket attributes to each\nof the elements with distinct names:\n\nOur Webflow project is now ready for migration! To do so, we will first need to create a directory\nnamed .appfairy in the root of our project:\n\nThis directory is used by Appfairy as an input for the CLI function, which means that we will need\nto export our project and extract the generated zip file's content into the directory we've just\ncreated:\n\n\n\n\nAbove: Exporting the project and unzipping it to .appfairy dir\nAll is left to do now is to run appfairy and our Webflow React components will be created and\nready to use!\n\nAs a result a message will be printed to the terminal signifying that a new git commit has been\ncreated with modifications which consist of the following:\n\nThe reason for the modifications to be laid out this way is because create-react-app (which is the\nmost common app starter for React) uses this folders structure. The output can be mapped differently\nusing a config file - more details about that can be found in the official\nREADME.md file over here.None of these files should be edited or removed and should only be managed by the appfairy\ncommand, so whenever we update the Webflow project we should simply repeat the recent process and\nthe files should update accordingly.If you'll take a look at the views folder you'll see that it contains a file named\nConsultFormView.js. As I already mentioned, Appfairy's design pattern consists of a view and a\ncontroller, therefore the exported ConsultFormView component needs to be bound to a controller.To define a controller simply create a new file named ConsultFormController.js under the\ncontrollers folder where the corresponding controller's going to be exported as a React component.\nThe controller should contain proxies to the original elements and each proxy should forward the\nnecessary props. Rather than giving further explanation I would like to give you an example of a\npossible implementation of a ConsultFormController:\n\nThat's it! Now you can just import the controller and use it anywhere and anytime you want, without\nhaving to deal with the hustle of maintaining a complex machine generated Webflow code; and any time\nyou update the design just update your code using the appfairy command.\n\n\nAbove: An example usage of an Appfairy generated React component\nReferences:\nThe full app's source code can be\nfound here\nFor an in-depth tutorial check out this video\nAPI docs can be found in the official GitHub repo\n\nHave fun designing/coding 🙂"}},"/blog/react-e2e-tests-with-hooks":{"title":"How to run React E2E tests purely with hooks","data":{"":"","tested-with-react-native-and-firebase-test-lab#Tested with React-Native and Firebase Test Lab":"Every invention starts with a need. I've been working on a personal app for quiet a while now, and\nas part of the process I hand it out to few people, so they can test it (most of them were\noverseas). One of the major complaints that I got was that the map component didn't load. On most\ndevices it did, but in many others it didn't.This issue had to be addressed, obviously, if I wanted to take my app seriously. Virtual devices\nusing Android emulator didn't seem to reproduce the issue, so I had to get a hold on real devices. I\nmade a list of devices that didn't support the app component, of what I had encountered thus far,\nand I started to look for people around me with these devices. Few challenges arouse:\nIt was HARD to find people around me with these devices.\nIt was HARD to convince these people to give me their phones for a short while, for debugging\npurposes.\nIt was HARD to split my time…\n\nI've been roaming around the internet, looking for a solution. I've found few platforms that provide\na way to interact with a collection of real devices using their API, and the one that stood out the\nmost was\nFirebase Test Lab.\nIt had a large collection of devices to interact with, and a free daily quota.Perfect! I was really excited to start testing my app with Test Lab. Oh, there's one thing though -\nit doesn't really work with React Native :( what a pity.One of the methods to use Test Lab is by recording a script that essentially guides a robot on how\nto use the app (known as Robo).\nThe script can be recorded directly from Android Studio, and\nit relies heavily on the view XML to fetch elements and attributes. Because React-Native wraps\neverything with a JavaScript shell, it fails to work as intended (for the most part).","my-eureka-moment-#My Eureka Moment 💡":"I realized that for my specific needs, all I had to do was to navigate to the map screen with a real\nback-end. It didn't matter who navigated to the map, a person, a robot, or a script, I just wanted\nto reproduce the issue. Since my knowledge revolves mainly around JavaScript, I've built a solution\npurely with React hooks, one that could navigate the app and test a desired outcome.","introducing-bobcat-#Introducing Bobcat 😺😼":"Bobcat is a library for testing navigation flows in React. Its API is heavily inspired by classic\ntesting frameworks like Mocha and Jest; it has a similar\ndescribe() / it() type of syntax. Let's have a look at a simple example script:\n\nNote the comments in the code snippet, it should make things more clear. I used the\nuseDelayedEffect hook and not an ordinary useEffect hook because I wanted to be able to visually\nobserve the component, otherwise it would mount and unmount so quickly I wouldn't be able to see it.\nbuttonRef and textRef are props that are provided directly from MyButton component, which can\nvary depends on your component and your needs. This is how MyButton should look like:\n\nThe useTrap hook would redirect the script to the trap which is defined under the active flow, so\nits behavior will change according to the test that you wrote.You've probably noticed by now that I used the useBobcat hook to retrieve the test utils. This\nsignifies that there should be a higher order BobcatProvider somewhere at the root-level\ncomponent. Why at the root-level? Because the higher you provide it at the hierarchy, the more\ncontrol you should have over the app. Since essentially we want to test all the components in our\napp, it should be defined AS HIGH AS POSSIBLE, like so:\n\nThe BobcatRunner is a component that calls the BobcatProvider internally. It's also responsible\nfor resetting the app whenever a flow is finished, so it can begin a session, with the new traps\ndefined underneath it. This is how it should look like:\n\nFor the most part this component should be pretty clear, but the thing I want to focus on is the\nrun() function and how it's used asynchronously. run() is an\nasync-generator,\nthat is being yielded each time we resolve or reject a test flow. The yielded result is a unique\nroute that is generated based on the given descriptions in our test-suite, so one possible route\ncould be MyApp -> Clicking a button. Since the route is unique, it can be used to re-render the\napp and reset its state, thus the key prop.\n\nHere's how an actual test run of my early-prototyped app looks like:https://youtu.be/sFM6iibYT-0","reducing-bundle-size#Reducing Bundle Size":"Bobcat is built for development or testing purposes, so one shall ask — “if it's built into the\ninternals of my app, how can I avoid it in production?”.Nicely said. Bobcat provides a mock-up module under react-bobcat/mock. If used correctly with\nBabel, we can redirect some import statements into different, much more reduced in size dummy\nfunctions. Here's an example babel.config.js (aka .babelrc):","installation#Installation":"The source is available via GitHub. Alternatively you can\ninstall Bobcat via NPM:\n\nor Yarn:\n\nBe sure to install React@16.8 or greater.","call-for-contributors#Call for Contributors":"The app mentioned in this article is work in progress. It's an amazing social project that uses the\nabsolute latest dev-stack and has many cool libraries and modules like the one above. If you're\nlooking for a serious tech challenge, or looking to make a change in the social field, contact me at\nemanor6@gmail.com."}},"/blog/react-dom-event-handling-system":{"title":"Getting to know React DOM's event handling system inside out","data":{"":"It all started when I've tried to redirect submitted React event handlers into another DOM element.\nI won't get into details regarding the use case, but what I did was fairly logical: I've redefined\nthe addEventListener() method on the DOM element's instance, hoping to capture the submitted\narguments and do as I wish with them. Unfortunately, it didn't work…How come?! How could it be that React handles events without calling the addEventListener()\nmethod? After all, it has proven itself to work, across many applications.True, but it's not what you think. First I would like you to take a snapshot of ReactDOM's\nimplementation. It actually has a comment which explains the entire event handling system:\n\n\n\n\nSource:\nsrc/events/ReactBrowserEventEmitter.js:32\nAt the beginning this is what I saw:\n\nBut after debugging a little, going through the stack trace and some of React's documentation,\nthings are much clearer now. Let's break it down then, and try to make things simpler.\n\nReact uses a single event listener per single event type to invoke all submitted handlers within the\nvirtual DOM. For example, given the following React component:\n\nWe will have a single event listener registered on the native DOM for the click event. By running\nthe getEventListeners() method which is available on Chrome dev-tools, we would get the following\nresult:\n\nEach event-type listener will be ensured per single render cycle, so if we were to define additional\nevent handlers of keydowntype, we would get the following output:\n\n\nSource:\npackages/react-dom/src/client/ReactDOMComponent.js:225\n\n\nFor each and every browser, regardless of its implementation, we will have consistent event\narguments, as React normalizes them. Whether we use the latest Chrome browser or IE8, the click\nevent arguments will look like so:\nboolean altKey\nnumber button\nnumber buttons\nnumber clientX\nnumber clientY\nboolean ctrlKey\nboolean getModifierState(key)\nboolean metaKey\nnumber pageX\nnumber pageY\nDOMEventTarget relatedTarget\nnumber screenX\nnumber screen\nboolean shiftKey\n\n\nDocs: events:supported-events\nSource:\npackages/react-dom/src/events/SimpleEventPlugin.js:259\nSince React is registering a single event listener per multiple handlers, it would need to\nre-dispatch the event for each and every handler.\nSource:\nEventPluginHub.js:168\n\n\nThe EventPluginHub is a very central component in React's event handling system. This is what\nunifies all event plug-ins into a single place, and will redirect dispatched events to each and\nevery one of them. Each plug-in is responsible for extracting and handling different event types,\nfor example, we have the SimpleEventPlugin will handle events which are likely to be implemented\nacross most browsers like mouse events and key presses\n(source);\nwe also have the ChangeEventPluginwhich will handle the very famous onChange event\n(source).\nSource:\npackages/events/EventPluginHub.js:168\nSynthetic events are React's normalized event arguments which ensures that there's consistency\nacross all browsers, and are being generated by the plug-ins. Note that synthetic events are being\npooled! Which means that the same object instance is used in multiple handlers, only it is being\nreset with new properties before each and every invocation and then disposed:\n\n\nDocs: events:event-pooling\nSource:\npackages/react-dom/src/events/SimpleEventPlugin.js:322\n\n\nAs mentioned, each and every event can have multiple handlers, even though each of them is actually\nbeing listened once by the real DOM. Accordingly, the relevant “dispatches” which consist of event\nhandlers and their corresponding fiber nodes (nodes in the virtual DOM tree) need to be accumulated\nfor future use.\nSource:\npackages/events/EventPropagators.js:90\n\n\nThe plug-in hub goes through the accumulated information and dispatches the events, thus invoking\nthe submitted event handlers.\nSource:\npackages/events/EventPluginUtils.js:77\nSo that's how that events handling system works in a nutshell. There are few things I would like you\nto note:\nTop level event listeners which are registered to the main DOM (window.document) can also be\nregistered to other DOMs, depends on where application container's at. For example, if the\ncontainer is adopted by an iframe, then the iframe's DOM will be the main event listener; it\ncan also be a document fragment, a shadow DOM, etc. It's important that you'd be aware of that and\nknow that there's a slight limitation the events' propagation.\nReact re-dispatches the events in two phases: one for capturing and the other for bubbling, just\nlike how the native DOM does.\nThe event handling which is done for React Native is different from React DOM's, and you\nshouldn't confuse between the two! React is just a library that produces a virtual representation\nof the view that we would like to render, and React DOM/Native are the bridge between React and\nthe environment that we're using. This article is relevant for React DOM only!\n\nAt the end of the day you'll still be able to use React, with or without this information, but I\nthink that a vastly used library such as React deserves more attention, especially if you want to\nstep up your game.So getting back to what brought me to write this article, if I wanted to redirect the registered by\nReact, all I had to do was redefining the addEventListener() for the DOM, and not the\ncorresponding Node. Of course, overwriting a native method is NOT something that should be done, and\nit's a very bad practice (*cough cough* Zone.js), but I won't get into my specific use case as\nthis is a topic for another article.Update: (November 21st, 2018)For those who liked this article and how I analyze React's implementation, I recommend you to read\nmy article about React Hooks and how they work under the hood."}},"/blog/recursive-react-tree-component-implementation-made-easy":{"title":"Recursive React tree component implementation made easy","data":{"":"","the-challenges-that-ive-faced-and-how-i-solved-them#The Challenges That I've Faced and How I Solved Them":"When I was building\ntortilla.acedemy's diff page,\nI was looking to have a tree view that could represent a hierarchy of files, just like Windows'\nclassic navigation tree. Since it was all about showing a git-diff, I also wanted to have small\nannotations next to each file, which will tell us whether it was added, removed, or deleted. There\nare definitely existing for that out there in the echo system, like\nStorybook's tree beard, but I've decided to\nimplement something that will work just the way I want right out of the box, because who knows,\nmaybe someone else will need it one day.This is how I wanted my tree's API to look like:\n\nDuring my implementation of that tree I've faced some pretty interesting challenges, and I have\nthought to write an article about it and share some of my insights; so let's cut to the chase.","architecture#Architecture":"My tree is made out of 3 internal components:\nFSRoot (see\nFSRoot.js) -\nThis is where the tree starts to grow from. It's a container that encapsulates internal props\nwhich are redundant to the user (like props.rootNode, props.parentNode, etc) and exposes only the\nrelevant parts (like props.childNodes, props.onSelect, etc). It also contains a tag which rules\nthat are relevant nested components.\nFSBranch (see\nFSBranch.js) -\nA branch contains the list that will iterate through the nodes. The branch is what will give the\ntree the staircase effect and will get further away from the edge as we go deeper. Any time we\nreveal the contents of a node with child nodes, a new nested branch should be created.\nFSNode (see\nFSNode.js) -\nThe node itself. It will present the given node's metadata: its name, its mode (added, deleted or\nmodified), and its children. This node is also used as a controller to directly control the node's\nmetadata and update the view right after. More information about that further this article.\n\n\n\nThe recursion pattern in the diagram above is very clear to see. Programmatically speaking, this\ncauses a problematic situation where each module is dependent on one another. So before FSNode.js\nwas even loaded, we import it in FSBranch.js which will result in an undefined module.\n\nThere are two ways to solve this problem:\nSwitching to CommonJS and move the require() to the bottom of the first dependent module — which\nI'm not going to get into. It doesn't look elegant, and it doesn't work with some versions of\nWebpack; during the bundling process all the require() declarations might automatically move to\nthe top of the module which will force-cause the issue again.\nHaving a third module which will export the dependent modules and will be used at the next event\nloop — some might find this an antipattern, but I like it because we don't have to switch to\nCommonJS, and it's highly compatible with Webpack's strategy.\n\nThe following code snippet demonstrates the second preferred way of solving recursive dependency\nconflict:","style#Style":"There are two methods to implement the staircase effect:\nUsing a floating tree — where each branch has a constant left-margin and completely floats.\nUsing a padded tree — where each branch doesn't move further away but has an incremental padding.\n\nA floating tree makes complete sense. It nicely vertically aligns the nodes within it based on the\ndeepness level we're currently at. The deeper we go the further away we'll get from the left edge,\nwhich will result in this nice staircase effect.\n\nHowever, as you can see in the illustrated tree, when selecting a node it will not be fully\nstretched to the left, as it completely floats with the branch. The solutions for that would be a\npadded tree.Unlike the floating tree, each branch in the padded tree would fully stretch to the left, and the\ndeeper we go the more we're going to increase the pad between the current branch and the left edge.\nThis way the nodes will still be vertically aligned like a staircase, but now when we select them,\nthe highlight would appear all across the container. It's less intuitive and slightly harder to\nimplement, but it does the job.\n\nProgrammatically speaking, this would require us to pass a counter that will indicate how deep the\ncurrent branch is (n), and multiply it by a constant value for each of its nodes (x) (See\nimplementation).","event-handling#Event Handling":"One of the things that I was looking to have in my tree was an easy way to update it, for example,\nif one node was selected, deselected the previous one, so selection can be unique. There are many\nways that this could be achieved, the most naive one would be updating one of the node's data and\nthen resetting the state of the tree from its root.There's nothing necessarily bad with that solution, and it's actually a great pattern, however, if\nnot implemented or used correctly, this can cause the entire DOM tree to be re-rendered, which is\ncompletely unnecessary. Instead, why not just use the node's component as a controller?You heard me right. Directly grabbing the reference from the React.Component's callback and use the\nmethods on its prototype. Sounds tricky, but it works fast and efficiently (see\nimplementation).\n\nOne thing to note is that since the controllers are hard-wired to the view, hypothetically speaking\nwe wouldn't be able to have any controllers for child nodes of a node that is not revealed\n(node.opened === false). I've managed to bypass this issue by using the React.Component's\nconstructor directly. This is perfectly legal and no error is thrown, unless used irresponsibly to\nrender something, which completely doesn't make sense (new FSNode(props); see\nimplementation).","final-words#Final Words":"A program can be written in many ways. I know that my way of implementing a tree view can be very\ndistinct, but since all trees should be based around recursion, you can take a lot from what I've\nlearnt.Below is the final result of the tree that I've created. Feel free to visit its\nGitHub page or grab a copy using NPM."}},"/blog/remote-control-graphql-inspector":{"title":"Enable Remote Control in GraphQL Inspector","data":{"":"The new version of GraphQL Inspector comes with remote control of Pull Requests and Pushes via\nHTTP endpoint. You're in charge of accepting or rejecting changes, even if they break the GraphQL\nAPI.We recently released a lot more interesting features. You can read about them in\n\"New GraphQL Inspector and upcoming features\" article.","what-is-remote-control#What Is Remote Control?":"Think of it as a way to intercept Schema Checks done by GraphQL Inspector and report back a\nconclusion:\nto fail or not to fail\nEvery Push or opened Pull Request is checked with GraphQL Inspector and based on the changes in a\nschema, it decides whether to reject those changes. We don't want to stop you there so Inspector\nlets you review changes and decide what to do.\n\nThe idea is simple. You create an HTTP endpoint, like serverless function or whatever and on every\nPush or Pull Request we send you a list of changes with all the details (mainly criticality level)\nand Inspector expects to receive back a conclusion and changes.\n\nThe HTTP endpoint will also receive details about a Pull Request or a Commit that triggered the\nschema check, so possibilities are endless here.You're able to reject all Pull Requests done by your manager, even when there are no breaking\nchanges.","future-plans#Future Plans":"We're working on Azure and Bitbucket integrations plus a monitoring feature. Talk to us to\ntry it out.We want to make Azure and Bitbucket a first-class citizens in GraphQL Inspector and give you\nthe same experience as you get right now with GitHub.Monitoring will enable you to analyze the traffic of your GraphQL APIs and provide details\nneeded to improve performance. Collecting information about the usage will let you safely remove\ndeprecated pieces of GraphQL Schema.\nIf you're interested, please reach out to us!","enjoy-graphql-inspector#Enjoy GraphQL Inspector!":"We have big plans for Inspector, and you're very welcome to join us in that journey.GraphQL Inspector is a tool created by developers, for developers and that's why we'd love to get\nyour feedback and shape GraphQL Inspector together!Oh... and it's Open Sourced!"}},"/blog/slack-bot-with-cloudflare":{"title":"Building Slack Bot with Cloudflare Workers","data":{"":"","introduction#Introduction":"Big or small companies are complex systems; every company must find the right way to work\nefficiently. There are a lot of applications that help us to manage our daily job efficiently.\nLately, we found some non-optimized in The Guild employees-system process.So, we thought about some solutions and decided to create an internal tool that helps us and might\nalso be valuable for others.One of those solutions was the GitHub Slack bot reminder in Cloudflare Workers.","what-are-cloudflare-workers#What Are Cloudflare Workers?":"Cloudflare Workers is a platform that provides a serverless execution environment. This environment\nallows you to create entire applications. This platform runs on cloud networks around the world.","what-we-can-do-with-cloudflare-workers#What We Can Do with Cloudflare Workers?":"The Workers platform comes with a new set of tools and nice APIs to integrate directly into the\ndeployment flow you want to design. At a high level, we can create a lot of cool features:\nBuild an entire Slack bot\nReturn small HTML page\nJSON return\nFetch HTML / JSON\nA/B Testing\nAuth with headers\nSchedule processing\nAnd a lot more examples…\n(You can find a lot of examples in Cloudflare docs)","getting-started---installation-setup#Getting Started - Installation Setup":"Cloudflare provides some easy and quick installation -\nYou can find it here.After you install and set up all requirements, let's talk about what we did to create the Slack bot.After you installed all Cloudflare packages and run wrangler init, you got the following\nindex.python file:\n\nThis function will fetch any change in the URL of the worker.","what-the-guild-is-building-with-cloudflare-workers#What The Guild Is Building with Cloudflare Workers?":"Cloudflare also provides the option to schedule some functions. You can add this function to the\nindex file:\n\nThe run function is our main function that gets the ENV environment variable secret and executes\nthe code we create.Here you can see the run function, we can write any code we want to schedule in the Cloudflare\nWorkers. We create a Slack bot that sends a daily message about all open pull requests.","how-can-i-schedule-my-function-in-the-cloudflare-worker#How Can I Schedule My Function in the Cloudflare Worker?":"After you finish the installation, Cloudflare also creates toml file, this file contains the\nname, main, compatibility_date, and triggers. To use the triggers, Cloudflare supports crons\nand looks like that:","how-can-i-fetch-the-data-from-github#How Can I Fetch the Data from GitHub?":"To get the data from GitHub, we create a GraphQL query. GitHub provides some easy and nice explorer\ntools - You can use it here with the following example:\n\nAfter we create the query, we need to use our data. For that, we use\nGraphQL Code Generator to generate the types based on the query.\n\nLike the example above, we define the schema path, add Authorization to the header and after that,\nwe generate the schema and create types to use in run function.","why-did-i-use-graphql-code-generator#Why Did I Use GraphQL Code Generator?":"GraphQL Code Generator generates types-based schema - The types are fully type-safe.\nThe process to add GraphQL Code Generator to the project is easy, fast and reduces type error.","what-else-you-can-do-with-cloudflare-workers-hint-yoga#What Else You Can Do with Cloudflare Workers? (Hint? Yoga)":"GraphQL Yoga, one of the greatest tools in The Guild, provides a GraphQL\nserver.Our focus is on easy setup, performance, and great developer experience.Thanks to its platform-agnostic design, Yoga makes your GraphQL Server run everywhere, even on\nCloudflare Workers, with no additional packages required!You can find more information and tutorials on how to integrate Cloudflare Workers with\nGraphQL Yoga -\nlink."}},"/blog/schema-change-notifications":{"title":"Schema Change Notifications in GraphQL Inspector","data":{"":"The new version of GraphQL Inspector comes with schema change notifications. We had it in plans\nfor almost a year now and we're very\nexcited to finally roll it out!We recently released a lot more interesting features. You can read about them in\n\"New GraphQL Inspector and upcoming features\" article.","schema-change-notifications#Schema Change Notifications":"If you wish to stay up to date with changes happening in your GraphQL API the Notifications are\nperfect for you.We know how hard it is to track and keep up with the development of a GraphQL Schema. Following\nevery merged Pull Request or every pushed commit is impossible at scale. You don't want to analyze\nthe code in order to find and understand changes in your GraphQL API.\nWe decided to automate and reverse this process so every new change will come to you, not the\nother way around.\nGraphQL Inspector tracks every Push in your Git repository and depending on a branch, sends you a\nmessage on Slack or Discord (or custom Webhook) with a list of changes introduced to a GraphQL\nschema.Changes are grouped by their criticality level: Breaking, Dangerous and Safe.Schema Change Notifications feature works well with any setup,\neven with multiple environments. You're\nable to track changes in all variants of your GraphQL API, on production, staging and other\nenvironments.","notifications-on-slack#Notifications on Slack":"To start receiving notifications on Slack you simply provide a url to Slack's Webhook.\n\nThat's it.","notifications-on-discord#Notifications on Discord":"The configuration process is exactly the same as with Slack. Provide a url to a webhook created in\nyour Discord workspace.\n\nEnjoy!","webhook#Webhook":"GraphQL Inspector should not limit you but help and that's why we decided to support not only Slack\nand Discord but rather something more universal, like Webhooks.\n\nYou can setup an HTTP endpoint, like serverless function and receive an event, every time there's a\nchange in GraphQL Schema.","future-plans#Future Plans":"We're working on Azure and Bitbucket integrations plus a monitoring feature. Talk to us\nto try it out.We want to make Azure and Bitbucket a first-class citizens in GraphQL Inspector and give you\nthe same experience as you get right now with GitHub.Monitoring will enable you to analyze the traffic of your GraphQL APIs and provide details\nneeded to improve performance. Collecting information about the usage will let you safely remove\ndeprecated pieces of GraphQL Schema.\nIf you're interested, please reach out to us!","enjoy-graphql-inspector#Enjoy GraphQL Inspector!":"We have big plans for Inspector, and you're very welcome to join us in that journey.GraphQL Inspector is a tool created by developers, for developers and that's why we'd love to get\nyour feedback and shape GraphQL Inspector together!Oh… and it's Open-Sourced!"}},"/blog/sofa":{"title":"SOFA — The best way to REST (is GraphQL)","data":{"":"","ending-the-rest-vs-graphql-debate-once-and-for-all#Ending the REST vs. GraphQL Debate Once and for All":"","tldr#TL;DR":"Don't choose between REST and GraphQL — create a fully RESTful API automatically from your\nGraphQL implementation (with a library and a single line of code)\nGet most of the benefits of GraphQL on the backend and frontend, while using and exposing\nREST\nSupport all your existing clients with REST while improving your backend stack with GraphQL\nCreate custom, perfectly client-aligned REST endpoints for your frontend simply by naming a route\nand attaching a query\nStop arguing about REST vs GraphQL. Use GraphQL, generate REST and get the best from both\nIn the other way around (REST to GraphQL) you won't get the best of both world but less powerful,\nharder to maintain server implementation with some benefits of GraphQL. It is a good and fast\nstart for a migration though.","wait-what#Wait, What!?":"Many articles have been written about the pros and cons of GraphQL and REST APIs and how to decide\nwhich one to use. I'm not going to repeat those here..A lot of time and energy spent by smart consultants to write those articles, read those articles,\nwhile most of them are finished with the “it depends on your use case” summary, without actually\nspecifying those use cases!I've been working with REST, GraphQL and SOAP APIs for many years. So I thought, why not come up\nwith a list of those use cases and for each one of those to check — what can't you do in GraphQL\nthat you can do with REST and what you wouldn't want to do with GraphQL and you would prefer REST.After creating that list, I suddenly had a thought — what if there was another option — what if my\npowerful GraphQL server could just generate a REST API for me?\nThen I could get the best of both worlds!\nThe more I dived into the idea and implementation then more I realized it's not only that we can\nhave both types of APIs created for us, but even if we just want to expose REST APIs, and none of\nour clients use GraphQL, GraphQL is the best way the create REST APIs!","how-does-the-above-sentence-even-make-sense#How Does the above Sentence Even Make Sense?!":"Usually when we (The Guild) help companies and organizations to modernize their APIs, the first\nto understand the benefits of GraphQL are the frontend developers, for obvious reasons. But as soon\nas the backend developers “Get it”, they become the biggest advocates of the technology. But they\nstill need to support existing clients and 3rd party partners.That's why those newly generated REST APIs get a lot of the features and benefits from the internal\nGraphQL implementation that make backend developers happy:\nFully generated documentation that is always up-to-date (Swagger, OpenAPI and GraphiQL)\nTruly RESTful API out of the box\nGraphQL Subscriptions as Webhooks\nRuntime validation of data — be 100% sure that fetched data matches schema's and query's\nstructure. You send exactly what I want to send, string is a string, an object has exactly the\nsame properties.\nCreating a custom endpoint is now a matter of choose a route name and attaching a query to it.\ndone. No more manual work of creating and maintaining client specific endpoints!\nUse GraphQL's philosophy of evolving APIs through schemas — no more painful V1 — V2 API\nmigrations.\nUse modern technology that is easier to hire people to. Companies like Facebook, Airbnb and\nothers have moved to GraphQL. None of them has gone back.\nThe power of GraphQL resolvers to create your API implementation, instead of manually written\ncontrollers from MVC\n\nWhat I get from having resolvers?\nEasier to transform data, so it matches the response (GraphQL Schema). That's because every entity\nhas its own resolvers, so the mapping is moved into smaller pieces and reused across an entire\napp.\nGraphQL allows you to easily share data across every resolver, we call it Context.\nForces you to define and resolve data in an opinionated way that actually helps to build an API.\nIt runs functions in parallel (functions that are nested at the same level), handles async and at\nthe end, it is responsible for merging all of that into a single object, so you don't have to\nthink about it.","sofa--use-graphql-to-create-restful-api#SOFA — Use GraphQL to Create RESTful API":"So we created SOFA (pun intended), an open source library you\ninstall on your GraphQL server to create a fully RESTful and configurable API gateway. Use GraphQL\nto REST.","how-to-tutorial#\"How to\" Tutorial":"Let's create a short step-by-step tutorial on how to create a RESTful API.Step 1: npm install the sofa-api package and add the\nfollowing line of code:\n\nStep 2: Go REST on a Sofa, you're done.Kamil Kisiela added Sofa to the\nSpaceX GraphQL API\nimplementation by Carlos Rufo, in a single\ncommit.Check out the fully generated REST endpoints, the\nSwagger live documentation,\nGraphiQL editor and the\nGraphiQL-Explorer!By the way, what you see here is a REST API, generated on top of a GraphQL API, created on top of\nanother REST API….\nWhy did you do that for!?!?","gradually-migrating-from-old-rest-implementations#Gradually Migrating from Old REST Implementations":"This is actually a good direction to go. In many of the companies we work with, they've created REST\nAPI layers using old technology on top of their original web-services.But those REST implementations are problematic (for all the obvious reasons people choose to move to\nGraphQL).So our way to go is to create GraphQL implementations on top of those REST layers, migrate the\nclients to those implementations and then gradually remove the old RESTful layer and call the\nservices directly.Using Sofa made those transitions much faster because we can offer all the existing clients to\nmigrate to our GraphQL implementation without actually using GraphQL themselves. We simply expose\nthe same REST endpoints on top of GraphQL and they are moving to our layer happily because we can\naccommodate all of their requests and custom REST endpoints much faster than the original, old REST\nimplementations.","give-me-more-details#Give Me More Details":"Sofa uses Express by default, but you can use any other server framework. Sofa is also GraphQL\nserver implementation agnostic.Head over to the Sofa website for documentation and to the\nGithub repository for reporting issues and helping out.","how-sofa-works#How SOFA Works?":"Under the hood, Sofa turns each field of Query and Mutation types into routes. First group of routes\nis available only through GET method, mutations on the other hand get POST.Sofa uses GraphQL's AST to create an operation with all possible variables (even those deeply\nnested) and knows exactly what to fetch. Later on it converts the request's body into operation's\nvariables and execute it against the Schema. It happens locally, but it's also possible to use an\nexternal GraphQL Server or even Apollo Link.Right now Sofa has a built-in support for Express but it's totally possible\nto use a different framework. The main concept stays exactly the same so only the way we handle the\nrequest differs across different server implementations.","graphql-subscriptions-as-webhooks#GraphQL Subscriptions as Webhooks?":"The way it works is simply, you start a subscription by calling a special route and you get a unique\nID that later on might be used to update or even stop the subscription. Subscriptions are Webhooks.\nSofa knows exactly when there's an even happening on your API and notifies you through the endpoint\nyou've assigned a subscription to.","models--resources#Models / Resources?":"In some cases you don't want to expose an entire object but just its id. How you're able to do that\nwith Sofa? You need to have two queries. First one has to return a single entity based just on its\nid (which would be an argument) and the second one should resolve a list of those. Also the names\nshould match, for example a resource called User should have two queries: user(id: ID): User and\nusers: [User]. Pretty much the same thing you would do with REST.\n\nBefore Sofa creates the routes, it looks for those Models and registers them so when the operations\nare built you don't fetch everything but only an id.But what if you want to fetch an entire object but only in few places?There's an option called ignore that allows you to do that. You simply pass a path in which you\nwant to overwrite the default behavior.Given the schema below, you would get just author's id.\n\nWith ignore: ['Book.author']you end up with an entire User object.","swagger-and-openapi#Swagger and OpenAPI":"Thanks to GraphQL's type system Sofa is able to generate always up-to-date documentation for your\nREST API. Right now we support Swagger and its OpenAPI specification but it's really easy to adopt\ndifferent specs.","summary#Summary":"sofa-api makes it extremely easy to create a RESTful API with all\nthe best practices of REST from a GraphQL server using all its power.Stop wasting your life arguing about REST vs GraphQL — Be productive, get the benefits of both\nworlds and move into the future of API development.I hope this would become the last REST vs. GraphQL article out there…. if you think it won't,\ncomment with a use case and let's try it out!Thanks to Kamil Kisiela for working with me on this and making\nthis library a reality!"}},"/blog/swift-graphql":{"title":"SwiftGraphQL - A GraphQL client for Swift lovers.","data":{"":"I love Swift, you love Swift, we want to do everything we can in Swift. It has a fantastic\ntype-system and a robust compiler. We also like GraphQL. It's a neat way to construct a type-safe\nbridge from your server to the client. Its syntax isn't as rich as Swift's, but who cares, right?\nSwiftGraphQL aims to make the best of both worlds, here's how we do it.I started working on SwiftGraphQL because no other client sufficed my\nneeds for building iOS applications.","goals#Goals":"Firstly, I wanted to keep the application's state separated from the GraphQL schema. Keeping it\nseparate has a couple of benefits: We don't have to turn the whole application upside down whenever\na field name or a type changes in the schema. That might happen if you generate types right from the\nqueries and reuse the same query in multiple places. Swift's type-system is richer than GraphQL's.\nBy separating the state from the schema, we can implement enum types with parameters, create new\nstructures and nest them. We can add logic to the model and verify the data when converting query\nresults to the state. We can implement structures that represent custom scalar types and treat them\nas first-person citizens in our codebase.Secondly, my apps usually consist of hundreds of types. I want my client to scale as my app scales,\nmeaning it should be as easy to handle hundred schema types as ten. Additionally, I want to use\neverything that Swift's ecosystem offers without my client restricting me.Lastly, there are nuances in my queries that I want to modify using code. Ideally, I want to\ndynamically generate my queries and still get the type-safety that GraphQL promises. This way, I can\nwrite recursive queries and fine-tune return types for specific use cases.To sum it up, I wanted a flexible, scalable and robust GraphQL client.","checking-out-existing-solutions#Checking Out Existing Solutions":"With goals in mind, I started considering existing GraphQL clients.Graphaello seemed like a viable option; it is type-safe, I can\nprogrammatically make selections, and it looks like it could scale well. However, Graphaello tightly\nbinds me to my schema, and I can only use structures to represent my data.https://graphaello.devApollo iOS, on the other hand, generates Swift types from\nqueries in our \"queries.graphql\" files and supports caching out of the box. Generating types from\nthe SDL is not per se a problem, but it becomes cumbersome and error-prone with large nested\nqueries. Apollo iOS also strongly-binds the generated structures to your queries, making it almost\nimpossible to translate fetched data into an internal state.https://apollographql.com/docs/ios/","swiftgraphql#SwiftGraphQL":"Now, let's turn to SwiftGraphQL. Consider a typical StarWars API\nexample with the following schema.\n\nI will show a trivial example, but with SwiftGraphQL, you'll handle\neven more complex scenarios just as easily. We want to separate our model from the schema; that's\nwhy we create a Person type.\n\nTo make a selection, we use Selection. followed by the name of the type that we want to use to\nmake a selection. In our case, that would be Selection.Human.\n\nThere's a great deal more happening behind the scenes to make sure you only select fields in the\nschema, but for now, let's remember that we make a selection this way.Once you have your types covered, you can construct and perform a query using the send method.\n\nEasy, right?","final-words#Final Words":"The example above only scratched the surface of what is possible with\nSwiftGraphQL. To sum it up, SwiftGraphQL\nis a code generator and a lightweight GraphQL client. It comes with a set of neat features like\nYou only have to generate code once (i.e. every time your schema changes),\nIt ensures that every query you can send is valid,\nYou can write queries programmatically,\nIt supports queries, mutations as well as subscriptions.\n\nAnd the best part? It's super easy to get started.\nInstall the generator using brew install swift-graphql,\nGenerate the API by running swift-graphql <endpoint> --output ./file.swift,\nStart querying your data.\n\nSwiftGraphQL is a young, slowly evolving library. I want to make it the\nbest Swift GraphQL client; that's why I'd love to hear how you use it. To support its development,\nmake sure you leave a star on GitHub and connect with me on Twitter. And if you are actively using\nit, consider becoming my sponsor on GitHub.PS.: There's a new post coming up that explains in-depth how\nSwiftGraphQL works under the hood. Make sure to subscribe to our\nmailing list and check our blog to see when it comes out."}},"/blog/support-nodejs-esm":{"title":"What does it take to support Node.js ESM?","data":{"":"ECMAScript modules, also known as ESM, is the\nofficial standard format to package JavaScript, and\nfortunately Node.js supports it\n🎉.But if you have been in the Node.js Ecosystem for some time and developing libraries, you have\nprobably encountered the fact that ESM compatibility has been a struggle, behind experimental flags\nand/or broken for practical usage.Very few libraries actually supported it officially, but since Node.js v12.20.0 (2020-11-24) and\nv14.13.0 (2020-09-29) the latest and finally stable version of package.exports is available,\nand since support for Node.js v10.x is dropped, everything should be fine and supporting ESM\nshouldn't be that hard.After working on migrating all The Guild libraries, for example\nGraphQL Code Generator or the\nrecently released Envelop, and contributing in\nother important libraries in the ecosystem, like\ngraphql-js, I felt like sharing this experience\nis really valuable, and the current state of ESM in the Node.js Ecosystem as a whole needs some\nextra care from everyone.This post is intended to work as a guide to support both CommonJS and ESM and will be updated\naccordingly in the future as needed, and one key feature to be able to make this happens, is the\npackage.json exports field.","exports-field#exports Field":"The official Node.js documentation about it is available\nhere, but the most interesting section is\nConditional exports, which\nenables libraries to support both CommonJS and ESM:\n\nThis field basically tells Node.js what file to use when importing/requiring the package.But very often you will encounter the situation that a library can (and should, in my opinion) ship\nthe library keeping their file structure, which allows for the library user to import/require only\nthe modules they need for their application, or simply for the fact that a library can have more\nthan a single entry-point.For the reason just mentioned, the standard package.json#exports should look something like this\n(even for single entry-point libraries, it won't hurt in any way):\nAssuming that the build/compilation/transpilation is outputted into the \"dist\" folder\n\n\nTo specify specific paths for deep imports, you can specify them:\n\nIf you don't want to break backward compatibility on import/require with the explicit .js, the\nsolution is to add the extension in the export:","using-the-mjs-extension#Using the .mjs Extension":"To add support ESM for Node.js, you have two alternatives:\nbuild your library into ESM Compatible modules with the extension .mjs, and\nkeep the CommonJS version with the standard .js extension\nbuild your library into ESM Compatible modules with the extension .js, set\n\"type\": \"module\", and the CommonJS version of your modules with the .cjs extension.\n\nClearly using the .mjs extension is the cleaner solution, and everything should work just fine.","esm-compatible#ESM Compatible":"This section assumes that your library is written in TypeScript or has at least has a transpilation\nprocess, if your library is targeting the browser and/or React.js, it most likely already does.Building for a library to be compatible with ESM might not be as straight-forward as we would like,\nand it's for the simple fact that in the pure ESM world, require doesn't exists, as simple as\nthat, You will need to refactor any require into import.","changing-require#Changing require":"If you have a top-level require, changing it to ESM should be straight-forward:\nfrom\n\n\n\nto\n\n\nBut if you are dynamically calling require inside of functions, you will need to do some refactoring\nto be able to handle async imports:\nfrom\n\n\n\nto","what-about-__dirname-requireresolve-requirecache#What about __dirname, require.resolve, require.cache?":"This is when it gets complicated,\nciting the Node.js documentation:\n\n\nThis is kinda obvious, you should use import and export\n\n\nThe only workaround to have an isomorphic __dirname or __filename to be used for both \"cjs\" and\n\"esm\" without using build-time tools like\n@rollup/plugin-replace or\nesbuild \"define\" would be using a library like\nfiledirname that does a trick inspecting error stacks, it's\nclearly not the cleanest solution.The workaround alongside with createRequire should like this\n\n\n\n\nrequire.resolve and require.cache are not available in the ESM world, and if you are not able to\ndo the refactor to not use them, you could use\ncreateRequire, but keep\nin mind that the cache and file resolution is not the same as while using import in ESM.","deep-import-of-node_modules-packages#Deep Import of node_modules Packages":"Part of the ESM Specification is that you have to specify the extension in explicit scripts imports,\nwhich means when you are importing a specific JavaScript file from a node_modules package you have\nto specify the .js extension, otherwise all the users will get\nError [ERR_MODULE_NOT_FOUND]: Cannot find moduleThis won't work in ESM\n\nBut this will\n\nBUT there is a big exception to this, which is the node_modules package you are importing\nuses the exports package.json field, because generally the exports field will have\nto extension in the alias itself, and if you specify the extension on those packages, it will result\nin a double extension:\n\n\n\nThat will translate into node_modules/bar/main.js.js in CommonJS and\nnode_modules/bar/main.js.mjs in ESM.","can-we-test-if-everything-is-actually-esm-compatible#Can We Test If Everything Is Actually ESM Compatible?":"The best solution for this is to have ESM examples in a monorepo testing firsthand if everything\nwith the logic included doesn't break, using tools that output both CommonJS & ESM like\ntsup might become very handy, but that might not be straightforward,\nespecially for big projects.There is a relatively small but effective way of automated testing for all the top-level imports in\nESM, you can have an ESM script that imports every .mjs file of your project, it will quickly\nscan, importing everything, and if nothing breaks, you are good to go 👍, here is a small example of\na script that does this, and it's currently used in some projects that support ESM\nhttps://gist.github.com/PabloSzx/6f9a34a677e27d2ee3e4826d02490083.","typescript#TypeScript":"In regard to TypeScript supporting ESM, it divides into two subjects:","support-for-exports#Support for exports":"Until this issue TypeScript#33069 is closed,\nTypeScript doesn't have complete support for it, fortunately, there are 2 workarounds:\nUsing typesVersions\n\nThe original usage for this TypeScript feature\nwas not for this purpose,\nbut it works, and it's a fine workaround until TypeScript actually supports it\n\n\nPublishing a modified version of the package\n\nThis method requires tooling and/or support from the package manager. For example, using the\npackage.json field publishConfig.directory,\npnpm supports it and\nlerna publish as well.\nThis allows you to publish a modified version of the package that can contain a modified version of\nthe exports, following the types with the file structure in the root, and TypeScript will\nunderstand it without needing to specify anything special in the package.json for it to work.\n\n\nIn The Guild we use this method using tooling that creates the temporary package.json\nautomatically. See bob-the-bundler &\nbob-esbuild","support-for-mjs-output#Support for .mjs Output":"Currently, the TypeScript compiler can't output .mjs, Check the issue\nTypeScript#18442.There are workarounds, but nothing actually works in 100% of the possible use-cases (see for\nexample, python-jest issue), and for that reason,\nwe recommend tooling that enables this type of building without needing any workaround, usually\nusing Rollup and/or esbuild.","esm-needs-our-attention#ESM Needs Our Attention":"There are still some rough edges while supporting ESM, this guide shows only some of them, but now\nit's time to rip the bandaid off.I can mention a very famous contributor of the Node.js Ecosystem\nsindresorhus who has a very strong stance in ESM. His Blog post\nGet Ready For ESM and a\nvery common GitHub Gist\nnowadays in a lot of very important libraries he maintains.But personally, I don't think only supporting ESM and killing CommonJS should be the norm, both\nstandards can live together, there is already a big ecosystem behind CommonJS, and we shouldn't\nignore it."}},"/blog/the-anatomy-of-a-graphql-request":{"title":"The Anatomy of a GraphQL Request","data":{"":"On a high-level, GraphQL servers are pretty easy to set up. Just passing a GraphQL schema and\nstarting the server does the job.However, for many use-cases, such a setup might not be sufficient.Let's dive into each of the phases of a GraphQL request and learn how enhancing each phase can help\nto set up a production ready GraphQL server.Note: While GraphQL can be done over almost any protocol, this article focuses on the most commonly\nused protocol GraphQL over HTTP. However, most\nknowledge can be transferred to other protocols such as GraphQL over WebSockets or other more exotic\nones.","http-parsing-and-normalization#HTTP Parsing and Normalization":"Clients send HTTP requests to the server with a payload that contains an operation document string\n(query, mutation, or subscription), optionally some variables, and the operation name from the\ndocument that shall be executed.When the requests are executed via the POST HTTP method, the body will be a JSON object:Example JSON POST Body\n\nHowever, when using the GET HTTP method (e.g. for query operations) those parameters can also be\nprovided as a query search string. The values are then URL-encoded.Example GET URL\n\nThe GraphQL HTTP server's first task is to parse and normalize the body or query string and\nfurthermore determine the protocol that shall be used for sending the response. The protocols can\nbe:\napplication/graphql+json (or application/json for legacy clients) for a single result that\nyields from the execution phase\nmultipart/mixed for incremental delivery (when using @defer and @stream directives).\n\nNot officially in the specification, but also used is text/event-stream for event streams (e.g.\nwhen executing subscription or live query operations).","graphql-parse#GraphQL Parse":"After parsing and normalizing the request, the server will pass on the GraphQL parameters onto the\nGraphQL engine that will parse the GraphQL operation document (which can contain any number of\nquery, mutation, or subscription operations and fragment definitions).If there is any typo or syntax error, this phase will yield GraphQLErrors for each of those issues\nand pass them back to the server layer to send those back to the client.For the following invalid GraphQL operation () missing after $id at line 2):\n\nThe error will look similar to this:\n\nAs you can see, the error messages are unfortunately not always straightforward and helpful. The\nlocation can, however, help you track down the syntax error!In case no error occurs, the parse phase produces an AST (abstract syntax tree).The AST is a handy format that is used for the follow-up phases validate and execute.For our operation it would be identical to the following JSON:\n\nThis procedure is performed by the parse function that is exported from graphql-js. Other\nlanguages that are orientate themselves on the graphql-js reference implementation have a\ncorresponding counterpart.","graphql-validate#GraphQL Validate":"In the validation phase, the parsed document is validated against our GraphQL schema to ensure all\nselected fields in the operation are available and valid. The previously parsed AST makes it easier\nfor the validation rules to have a common interface of traversing the document. Furthermore, other\nvalidation rules that ensure that the document follows the GraphQL specification are checked, E.g.\nwhether variables referenced in the document are declared in the operation definition.As an example the following operation is missing a definition for the $id variable:\n\nIf the AST of that operation would be validated the following error will be raised.\n\nIn case any error is raised the errors are forwarded to the HTTP layer which takes care of sending\nthem back to the client over the determined protocol. Otherwise, if no errors are raised the\nexecution phase will be performed next.This procedure is performed by the validate function that is exported from graphql-js. Other\nlanguages that are orientate themselves on the graphql-js reference implementation have a\ncorresponding counterpart.","graphql-execute#GraphQL Execute":"In the execution phase we are actually resolving the data requested by the client using the parsed\nand validated GraphQL operation document AST and our GraphQL schema, which contains the resolvers\nthat specify from where the data the client requests is retrieved.Previously, the HTTP request has been parsed and normalized, which yielded the following additional\n(but optional) values: variables and operationName.If the GraphQL document used for execution included more than one executable mutation, query or\nsubscription operation, the operationName is determined to identify the document that shall be\nused. If the determined executable operation has any variable definitions, those are asserted\nagainst the variables values parsed from the HTTP request.If anything goes wrong or is incorrect an error is raised. E.g. the variables provided are invalid\nor the operation that shall be executed cannot be determined as the operationName is invalid or\nmissing.Example error for anonymous document alongside named document\n\n\n\nSuch an error will again be forwarded to the client by the HTTP layer.Otherwise, if no error occurs, the field values will be resolved with all the parsed and provided\nparameters. The phase yields a single or stream of GraphQL execution results.\n\nThe HTTP layer forwards those to the client that initiated the request.This procedure is performed by the execute and subscribe functions that are exported from\ngraphql-js. Other languages that are orientate themselves on the graphql-js reference\nimplementation have a corresponding counterpart.","overriding-parse#Overriding parse":"","add-caching#Add Caching":"Parsing a GraphQL document string comes with overhead. We could cache frequently sent document\nstrings and serve the document from the cache instead of parsing it every single time.","test-new-functionality#Test New Functionality":"The GraphQL Type system defines the capabilities of the GraphQL service. This phase can be used to\nadd new capabilities to the type system that may not yet be supported by GraphQL specification.","overriding-validate#Overriding validate":"","add-caching-1#Add Caching":"Similar to parsing, validating a GraphQL document AST comes with an overhead. We could cache\nrecurring document ASTs and server the validation result from the cache instead of validating it\nevery single time.","add-custom-rules#Add Custom Rules":"You might want to restrict what kind of operations are allowed to be executed. E.g. If we only want\nto allow query operations, we can provide a custom validation rule that yields errors as soon as a\nmutation or subscription operation is encountered.","overriding-execute-or-subscribe#Overriding execute or subscribe":"","add-caching-2#Add Caching":"We can serve frequently executed GraphQL operation results from a cache instead of calling all our\nresolvers and fetching from a remote database/server every time.","add-tracing-information#Add Tracing Information":"We can collect statistics by measuring how long it takes to resolve each field in our documents'\nselection set and narrow down bottlenecks.","mask-and-report-errors#Mask and Report Errors":"We want to make sure the errors occurring during the execution do not contain sensitive information\nand are properly reported, so they do not go unnoticed and are properly reported.","add-new-functionality#Add New Functionality":"We could customize the algorithm that is used by graphql-js in order to add new features or make\nit more performant e.g. by using graphql-executor.","use-envelop-for-extending-the-phases#Use Envelop for Extending the Phases":"While making our GraphQL servers production ready and working with our clients we discovered that we\nwere writing the same custom code over and over again.Envelop provides us a user-friendly way of hooking into the before and after phases of parse,\nvalidate, execute and subscribe.\n\n\n\nFurthermore, the plugins can be easily shared across projects.You can learn more about Envelop on our introduction blog post or by\nvisiting the Envelop documentation.","why-is-graphql-yoga-v2-so-important#Why Is GraphQL Yoga V2 so Important?":"As you might have noticed\nwe adopted GraphQL Yoga to The Guild ecosystem quite a while ago.\nWe have been thinking a lot on how version 2 should look like\nand while building and using envelop within our customer projects we realized a few limitations that\ncan only be solved by owning/wrapping the whole HTTP GraphQL request pipeline.While envelop is strictly about wrapping the graphql-js core functions (parse, validate,\nexecute and subscribe). GraphQL Yoga will provide a unified plugin interface for writing plugins\nthat hook into ALL of those phases envelop has plus all the encapsulated phases for parsing and\nnormalizing the HTTP request, allowing you to write powerful GraphQL servers and making features\nsuch as Automatic Persisted Queries or Response Caching more powerful and easy to adopt.For a small sneak peek check out\nGraphQL.wtf Episode 24 - Batteries Included GraphQL Server\nor try the GraphQL Yoga alpha.We are excited to announce more details soon."}},"/blog/typescript-graphql-unions-types":{"title":"Getting the Best of TypeScript and GraphQL: Union Types","data":{"":"","introduction#Introduction":"The combination of TypeScript and GraphQL can be very powerful. Both TypeScript and GraphQL support\nthe concept of discriminated unions. In this short blog post, I want to share my last project\nexperience and share one of the most powerful methods to create stronger types using TypeScript and\nGraphQL.One of my assumptions in this blog post is that you know some TypeScript. If you don't, you can\ncheck out \"Basic Types\" handbook.\nSo, let's talk a little bit about TypeScript union types, one of the most remarkable features of\nthis language.","what-is-a-union-type-in-typescript#What Is a Union Type in TypeScript?":"So TypeScript language is based on a type system. TypeScript union operator can be used to define a\nvariable that can hold multiple data types: integer or number, character, string, float, etc.Here you can find a basic example:\n\nHere's a live example in python Playground","how-to-use-union-types-in-typescript#How to Use Union Types in TypeScript":"TypeScript can also be used to combine complex types such as interfaces. You can think about one\ntype that contains some others types. Here is a simple example that combines 2 types: Sushi and\nPizza, both of them can be united into one type by the name Food.\n\nHere's a live example in python PlaygroundAnd another Union type example, this time with string and string:\n\nHere's a live example in python Playground","graphql-union-and-typescript-union-type#GraphQL Union and TypeScript Union Type":"GraphQL is a query language that is used to define the API of a server. Like TypeScript or even Go\nlanguage, GraphQL supports union and interface types. The type system is one of its core principles\nand we can use it to make type-safe API calls. The goal is to use it to propagate our backend types\nto the frontend. When I started to learn TypeScript, I found myself making lots of type errors and\nannoying misspellings. These errors became more frequent as the project grew. The best solution for\nthat situation was to add type-safety based on a GraphQL schema.A GraphQL schema can return one of the multiple object types thanks to the Union or Interface\nkeywords. Like TypeScript, we can declare which object types are included in the union:\n\nLet's see a basic example schema that defines a Menu union type that can return either a Pizza\nor Sushi:\n\nAfter we declare our types in GraphQL and create a union type to return some of the other types, we\ncan generate TypeScript types from the GraphQL schema and use them in the frontend.","how-to-use-graphql-codegen-to-generate-code-and-deal-with-typescript-union-types#How to Use GraphQL Codegen to Generate Code and Deal with TypeScript Union Types":"First of all, you are more than welcome to explore all the plugins of GraphQL Codegen.\nGraphQL Code Generator Like we did in the previous example,\nlet's talk about getting the data typed safely in the front.First, let's create our GetFullMenu query as follows:(in this case, I'll use the react-query example)\n\nGet the Menu type from the schema with the query, so we will be able to get the objects inside the\nMenu.","conclusion#Conclusion":"I hope this blog post helped you to better understand TypeScript unions and GraphQL unions and the\nway to use them in your project.\nWe can create Union and Interface types in both TypeScript and GraphQL, which helps us to better\ndefine the API of a server and use it in our client.\nA static type check can help safeguard your application. Especially in large-scale applications.\nWhen you use type-safe GraphQL, it helps you to eliminate existing errors like misspellings and\nerrors.\nIn this brief blog post, we looked at a few features of TypeScript that help you on code-time,\nmost help you to understand the output of any function you create."}},"/blog/whats-new-in-graphql-codegen-v2":{"title":"What's new in GraphQL-Codegen v2?","data":{"":"GraphQL Code Generator is around for almost\n5 years, and it's improving the developer experience of many developers (>3M downloads a month on\nNPM!). Like all The Guild's projects, throughout all these years, the library continuously evolved\nbased on the experience and feedback from the community and our clients - every day codegen gets\nbetter and better, so keep your feedback coming and keep your dependencies up to date :) But now,\nit's time for a big release!We recently decided to revisit and improve some parts of codegen, and we're happy to announce that\nwe're releasing a new version of the tool (v2)!This release is all about improving the reliability and readability of the generated code, and\nadding new features (and a new plugin/preset that might revolutionize how we generate code on our\nfrontends!).","why-v2#Why v2?":"Until now GraphQL Codegen has evolved, without the need for (major) breaking changes, but there were\na couple of things we wanted to do for a better and easier codegen experience that required some\nsmall breaking changes.We are currently working on adding ESM support for all The Guild's tools.Unfortunately, in Codegen, we are not there yet\n(you can track the progress here,\nbecause we need to make sure that plugins, presets, schemas and documents are still being loaded\ncorrectly. But it's coming soon!But other tools, which we use as a dependency, like\ngraphql-tools (v8) already supports ESM, and dropped support for Node\n10, so we are aligning to that.We've updated to the latest version of graphql-tools (v8) and\ngraphql-config (v4) to get some upstream bug fixes.","human-readable-generated-types#Human-Readable Generated Types":"A few years ago, we changed the output of codegen to use Pick in order to build the operation\ntypes based on the schema types:\n\nSome time after, we added preResolveTypes configuration flag as experimental, in order to generate\nmore readable types with primitive types resolved directly on the generate types:\n\nWe are happy to announce that v2 of typescript-operations now uses preResolveTypes: true by\ndefault, so all generated types are more readable.\nAs a user of Codegen this is not a breaking change (aside that the generated code is slightly\ndifferent), and all your types are still fully compatible with v1 of the tool. You can set\npreResolveTypes: false if you prefer to keep the old behavior.","type-accuracy#Type Accuracy":"In addition to more readable types, we also improved the accuracy of the generated types.A few months ago, chrbala found\na bug in the typescript-operations plugin,\nwhich was causing the generated types to be incorrect in cases where you use nested and complex\nfragments.This bug was caused by the fact that we were combining the fragment types using the & operator of\nTypeScript, and this operator doesn't apply deep merging for nested sub-types. So when using\nmultiple fragments (MyFirstFragment & MySecondArgument), the nested fields are being overwritten,\ninstead of being merged.n1ru4l picked that up and\nfixed the bug and added support\nfor better handling of these kind of cases.The new configuration flag (inlineFragmentTypes: inline) is now used by default, and generates\nmore accurate types, without introducing breaking changes!Instead of combining the fragment types they are merged and inlined.\n\nNo worries, fragment types are still exported separately!\nAll your types are still fully compatible with v1 of the tool. You can set\ninlineFragmentTypes: combine if you still prefer to keep the old behavior.","removal-of-deprecations#Removal of Deprecations":"We also used the need for a major version in order to remove a few deprecations from the codebase.","typescript-resolvers#typescript-resolvers":"In typescript-resolvers, we had a generated signature for IResolvers and IDirectiveResolvers\n(which were deprecated 2 years ago), v2 of this plugin is removing these proxy types.Also, the noSchemaStitching flag is now set to true by default, so the generated resolvers\nsignature is simpler and matches the needs of most projects.\nIf you are using Schema Stitching, you can set noSchemaStitching: false to keep the old\nbehavior.","typescript-compatibility#typescript-compatibility":"The typescript-compatibility plugin was created to make it easier to migrate from v0 to v1 of\ncodegen, and hasn't been actively developed for a few years.With this release, we no longer support or maintain the typescript-compatibility plugin. If you\nare still using it, please consider migrating to the new type format.","new-typescript-plugin-for-operations#New TypeScript Plugin for Operations!":"Some time ago we started advocating the\nnear-operation-file preset,\nfor generating GraphQL client code next to the .graphql operation file.A month ago, Maël Nison reached out to us with\na new concept for matching your actual\nGraphQL operation string and the generated TypeScript types. Without having to add clumsy import\nstatements for each GraphQL operation.It allowed writing the operations in the following way:\n\nThe README on his repository contained a\nlist of limitations. We\ntook that that feedback and fixed some upstream bugs within graphql-tools and improved\ngraphql-codegen according to that.With a few adjustments, n1ru4l managed to\nturn that amazing idea into a plugin and a preset\nthat extends the behavior of typescript-operation and TypedDocumentNode, and allow you to\ngenerate TypeScript types that magically matches your GraphQL query strings (this also required a\nfew fixes in graphql-tools, so now the Loaders in graphql-tools are better!).","so-what-does-that-mean#So What Does That Mean?":"Today, GraphQL Codegen scans your codebase and looks for all the operations that are being used by\nyour components (or, from .graphql files), then it generates types and wraps TypedDocumentNode\nfor you. Those are either generated to a single file, from which you import from anywhere within the\napp or next to the .graphql when using the near-operation-file-preset. Folder structure\n(near-operation-file-preset)\n\nWith this new plugin+preset, you can generate typings for your inline gql function usages, without\nhaving to manually specify import statements for the documents. All you need to do is import your\ngql function and run codegen in watch mode.\n\nThat way we don't need to switch context between .graphql and our .python(x) files and have less\nfiles within our repository (compared to the near-operation-file preset)!You can find\nthe complete documentation, examples and API reference in codegen website.We also have an example PR for a migration from near-operation-file to the gql-tag-operations-preset.We want to hear your thoughts on this way of using Codegen on the frontend.Based on your feedback we might want to make this the recommended way of using Codegen on the\nfrontend in the future.\nHuge thanks to Maël Nison, who conceptualized the foundation for\nthis preset over here. Please keep\npushing the boundaries!","whats-next#What's Next?":"Like we said at the beginning, we continuously keep improving Codegen, so this release is not the\nend but just a start. Here are some sneak peeks on things we are currently working on:","esm-support#ESM Support":"ESM support is coming soon (and will probably result in another major version)","sdl-resolver-development-flow-improvements#SDL Resolver Development Flow Improvements":"We are experimenting with a better way to link typeDefs with the resolvers signature generated by\ntypescript-resolvers in a similar way to the new gql-tag-operations plugin. One of the goal of\nthis preset is to make sure that every resolver that should be defined and implemented is actually\nimplemented.\n\nYou can find more info here","fragment-type-masking#Fragment Type Masking":"Today the Relay framework development flow allows hiding (masking) properties from operation results\nobjects that are added via fragments. Those properties are only accessible from within the component\nthat consumes the fragment:\n\nThis allows building scalable components as each component only receives the data it should have\naccess to and furthermore components higher up in the tree can not access data it did not explicitly\nrequest. Removing a component will thus not result in surprising behaviors.","what-else-is-missing#What Else Is Missing?":"Do you think something else is missing or could be improved? Reach out to us via the chat on this\npage, a GitHub discussion or on\nthe GraphQL Discord."}},"/blog/whatsapp-clone-react-hooks-graphql-typescript-and-postgresql":{"title":"WhatsApp Clone - GraphQL, Apollo, TypeScript and PostgreSQL","data":{"":"An open-source full-stack example app made with React 16.7 (Hooks & Suspense), TypeScript,\nGraphQL-Subscriptions/Codegen/Modules and PostgreSQLYou might have seen it around already — an open-source WhatsApp Clone tutorial; a project which was\noriginally started in 2015 by Urigo based on\nAngular-Meteor and\nIonic, and have been throughout different incarnations ever since.This time around, I'm happy to announce that a new version of the WhatsApp Clone is coming, and it's\nbased on React 16.7 (Hooks &\nSuspense),\nStyled-Components,\nMaterial-UI, TypeScript,\nApollo,\nGraphQL-Subscriptions/Codegen/Modules,\nPostgreSQL and TypeORM.Click me to go to the tutorial page\nA more in depth step-by-step tutorial is expected in the near future","what-is-it-good-for#What Is It Good for?":"This app was built with all the latest and hottest technologies out there. The purpose is simple —\nit should be a guideline for building a proper app, thus we thought very carefully regards the\ndesign patterns and architecture used in it, plus, we made sure to cover all communication methods\nwith a GraphQL-back-end in different variations (query, mutation, subscription). This way whenever\nyou're looking to start a new app, maintain an existing one or upgrade your dev-stack, the\nWhatsApp-clone can be a great source to start with! It's full stack and has a complete flow.","why-did-we-choose-this-dev-stack#Why Did We Choose This Dev-Stack?":"React, GraphQL, Apollo, PostgreSQL and TypeScript for obvious reasons — they are backed by a strong\necosystem that grows rapidly. These technologies can be used in endless variations, and there's no\none way which is the most right of doing so, but we chose a way that makes the most sense for us and\nthat we truly believe in when it comes to building apps. We've connected it all with\nTypeORM,\nGraphQL-Code-Generator,\nGraphQL-Modules for the following reasons:\nThe GraphQL back-end was implemented using GraphQL-Modules where\nlogic was splitted into feature based modules. GraphQL-Modules is a library which provides you\nwith the ability to manage and maintain your GraphQL schema in a scalable and reusable way. Not\nonce nor twice I have seen people who struggle with that and get tangled upon their own creation,\nand with GraphQL-Modules where you have a very defined structure, this problem can be easily\nsolved. You can read more in this series of 7 blog posts about it.\nEvery GraphQL/TypeScript definition was automatically generated with\nGraphQL-Code-Generator using a single command call. There's\nno need to maintain the same thing twice if it already exists in one way or another. This way you\ndon't have to write TypeScript type definitions for your GraphQL documents (queries, mutations and\nsubscriptions), GraphQL resolvers and GraphQL types.\nThe new version of React 16.7 was used with Hooks and Suspense and 100% of the project is made out\nof function components. The front-end communicates with the back-end using only hooks and there\nwas no use in GraphQL-React components, which makes async tasks look a lot more readable with no\nextra indentations.\nWe used TypeORM to correctly split the logic of the entities in the database and define the\nrelationships between them. ORMs are controversial these days, but they can help a lot in some\ncases, and we thought a good example could be valuable to the community.","what-to-expect#What to Expect?":"Basic authentication\nImage uploading with Cloudinary\nLive updates with GraphQL Subscriptions\n100% function components with React Hooks\nGraphQL's communication with\nreact-apollo-hooks\n\nThis can be extremely useful for those who have little to no background in one of the technologies\nin our dev-stack. We will let you know when it's ready and will publish it due time, until then be\nsure to follow our blog and the GitHub repositories.","influence#Influence":"We want to hear your opinions!Should we choose another library and technology over another? Could we write the code\nbetter/cleaner? Should we add a specific feature to the app? We want to hear it all!Please tell us now, so we could integrate your feedback on the tutorial itself!We want to keep evolving the stack and as the tutorial would be based on git commits, we want to\ncreate the same clone with different tech-stacks and compare them on this real app using code diffs.Everything is completely free and open source, and we want your help and (not financial)\ncontribution!Best place would be to open an issue or create a PR on the repositories:\nServer — urigo/WhatsApp-Clone-Server\nClient — urigo/WhatsApp-Clone-Client-React\n\nAgain, all types of feedback is welcome, write freely!See you in the tutorial!"}},"/blog/whatsapp-clone-with-ionic-angular-and-meteor":{"title":"Build a WhatsApp Clone with Ionic 2, Angular 2, and Meteor","data":{"":"A version of this post was originally published on the\nIonic Blog.Now, a year has passed and a lot has happened: Angular 2.0 is now stable, including astonishing\namount of new features for the platform. Ionic 2.0 entered RC stage and is very close to being\nfinal. Finally, Meteor reached version 1.4.2,\nwith many improvements the community asked for (fast build times, full npm and yarn support, Node\n4.6.1 and MongoDB 3 by default, etc...).","new-ionic--meteor-whatsapp-tutorials#New Ionic / Meteor WhatsApp Tutorials":"Today, I'm happy to announce we are releasing two new versions of the Ionic/Meteor Whatsapp\ntutorial, this time with Angular 2.0 and Ionic 2.0, one using the Ionic CLI and one using the\nMeteor CLI.In these tutorials, we'll create a full WhatsApp clone using Angular 2 and Ionic 2. We'll use\nMeteor's realtime collections for the chat and Meteor's simple Authentication packages for SMS-based\nauthentication.It's great to see the power of these two solutions working together, keeping the platforms\nup-to-date with the latest improvements in the Javascript ecosystem!Start here.","angular2-meteor#Angular2-Meteor":"By the way, if you noticed that the Angular-Meteor.com website is much\nfaster, it's because we've completely re-written it using Angular 2 and universal rendering to\ngenerate it as a static website. On top of that, more features are coming to Angular2-Meteor very\nsoon, including lazy loading of modules and support for the AOT compiler.If you're thinking about migrating from Blaze to Angular2, or using them side by side, check out our\nmigration tutorial here."}},"/blog/whatsapp-clone-with-meteor-and-ionic":{"title":"Build a WhatsApp clone with Meteor and Ionic — Meteor Platform version","data":{"":"For the newer, Angular 2 version post,\nclick here…\nNow that Angular is a\nfirst class citizen in Meteor,\nyou can use all of its vast libraries, giving you full access to the Angular ecosystem.Also,\nIonic recently added official support for Meteor's packaging system,\nand now their package is available on Atmosphere.In this tutorial, we will build a WhatsApp clone using Meteor, Angular, and the Ionic Framework for\nCSS and mobile components. I've also released a\nclone of this tutorial on the Ionic Blog that uses the\nIonic CLI instead of the Meteor build system.It's a good resource for people who want to use Meteor for their backend and Meteor's client side\nlibraries in a separate front end application, also a good migration strategy.If you are using Blaze, you can still use Ionic's CSS libraries or the\nMeteoric package.Contents:\nInstalling the platform and creating a base app\nWhatsApp views with static data\nCreate the server and share data with the client\nChat view and send messages\nUsers and (SMS) authentication\nCreate and remove chats\nPrivacy and publish/subscribe\nStep 8 — User profile picture\nSend image messages\n\nStart here."}},"/logos":{"title":"Press Kit","data":{"":"","logo--brand-guidelines#Logo & Brand Guidelines":"Here we've a selection of logos that you should use for co-marketing.Download Logo PackThese logos are only to be used where The Guild are involved, and not to be used on any projects\nthat The Guild don't own, maintain, or contribute to.","-do#✅ Do":"Use these to refer to The Guild.\nUse these when mentioning The Guild in an article, meetup, conference, or podcast.","-dont#❌ Don't":"Change the appearance of the logo, or alter in any way."}},"/newsletter/issue-1":{"title":"Issue #1","data":{"":"Hi there,Our commitment to the GraphQL Ecosystem is stronger than ever, with more than\n15 active projects used by thousands of developers, participating in the GraphQL\nFoundation projects, and working with many companies to help them get the best of GraphQL.We felt that we could do a better job at making it easier to follow the evolution of our ecosystem\nand share our tips and knowledge.For this reason, we are happy to share with you this first issue of The Guild Newsletter, a monthly\nnewsletter that will share:\nThe Guild and GraphQL Foundation projects releases\nBlogposts about GraphQL\nTips on how to get the best of our tools\n\nStarting our newsletter is a long-time due project, and we feel that this month is the perfect\ntiming to start with the recent launch of GraphQL Yoga v2 and our first\nproduct: GraphQL Hive.","announcements#Announcements":"","meet-the-guild-team-at-the-graphql-sf-meetup-on-june-6th-#Meet The Guild Team at the GraphQL SF Meetup on June 6th 🗓":"We are very excited to have all The Guild members visiting to SF together (for the first time!) and\njoin the GraphQL SF Meetup!This meetup will be the occasion to share our vision of the future of The Guild and especially to\nanswer all your questions during a dedicated AMA.➡️ Registrations are already open, we can't wait to meet you!You are part of a company based in SF? Let's meet!","graphql-yoga-v2-is-available-️#GraphQL Yoga V2 Is Available! 🧘‍♂️":"GraphQL Yoga, our GraphQL Server library, recently reached a huge milestone: the v2 version!With the growing community of tools in the GraphQL space, most recently\nEnvelop, we were able to rewrite GraphQL Yoga 2.0 from scratch with easy\nsetup, performance, and developer experience at the core.Discover all the new features brought by the v2 in the\nlaunch article,\nits dedicated GraphQL video or by following the\nYoga tutorial.We already received many positive feedback and great adoption with\nRedwoodJS and Parse Platform switching to Yoga\nas their default GraphQL server.More is coming with soon, a new NestJS GraphQL Yoga\ndriver, stay tuned!","graphql-hive-our-first-open-source-saas-product-#GraphQL Hive, Our First Open-Source SaaS Product 🚀":"Today is a big day for us: we are releasing our first open-source SaaS product, GraphQL Hive.GraphQL Hive aims to help GraphQL developers to get to know their GraphQL APIs a little more with\nour schema registry, monitoring, alerts, and integrations.This new open source project comes with its managed SaaS alternative, with a generous free “Hobby”\nplan.Get started by reading our launch article.","graphql-foundation#GraphQL Foundation":"The Guild is a member of the GraphQL Foundation whose mission is\nto ensure that the GraphQL community is able to focus on the continued evolution of the\nspecification and reference implementations.We are happy to announce that The Guild is now the new maintainer of the\nDataLoader project.We started a maintenance plan that includes TypeScript support, and better documentation:\nhttps://github.com/graphql/dataloader/issues/297.Finally, Benjie from PostGraphile, started the\n\"GraphQL Composite Schemas Working Group\"\ninitiative. The evolution of the GraphQL ecosystem brought many different solutions to compose\nmultiple GraphQL Schemas (Hasura GraphQL Joins, Apollo Federation, GraphQL Modules, GraphQL Tools,\netc).The goal of this working group would be to define a spec to avoid a proliferation of standards.If you are working in this field or are interested in the subject, we highly encourage you to join\nthis WG:\nhttps://github.com/graphql/graphql-wg/pull/977.","the-guild-ecosystem#The Guild Ecosystem":"","a-better-documentation-experience#A Better Documentation Experience":"New documentation search\n\nAs most of our projects grow, we realized that it might be sometimes difficult to quickly find the\nsearched content.For this reason, we are happy to release a new search experience that allows you to search across\nall of our projects, thanks to a unified UI.We already have many improvements listed for this first beta version of the new search, all feedback\nis more than welcome:\nhttps://github.com/the-guild-org/the-guild-components/issues/372.\nMore collaborative documentation\nMost of our documentation now provides an Edit on GitHub link, to ease feedback and\ncollaboration, along with a brand new comment system!","graphql-code-generator#GraphQL Code Generator":"First, we would like to thank all of you since GraphQL Code Generator recently crossed the 1.4\nmillion weekly downloads on NPM 🎉We lately put a lot of effort into codegen by first improving\nits documentation with better Getting\nstarted content and new Guides for major frameworks and setups.You will find below the list of “not-to-miss” updates released since the beginning of the year:Introducing Document Driven Applications and Fragment MaskingFragment Masking is a popular technique, that so far has been exclusive to Relay users. We built a\nnew plugin preset on top of\nTypedDocumentNode that allows\nusing fragment masking with any GraphQL client or framework. This will help more people build\ndata-driven self-contained components. We are already using it heavily within Hive!Learn more on the\ngql-tag-operations-preset\nand\nfragment masking.Codegen performanceMany improvements have been made to codegen performance, make sure to update all your\n@graphql-codegen/* packages to the last version!Merge similar Fragment typesSome of you have reported some issues related to the usage of Node interface design that leads to\npoor type resolution and heavy generated types.Thankfully, @asmundg provided a new option\n(mergeFragmentTypes: true) for all typescript plugins that enable merging “similar fragments”.More information is available on the related PR:\nhttps://github.com/dotansimha/graphql-code-generator/pull/7799","graphql-mesh#GraphQL Mesh":"GraphQL Mesh, our project for automatically turning any API (REST,\nOpenAPI/Swagger, gRPC, SOAP and more) into a queryable GraphQL API saw major improvements in the\nlast couple of months.First, similarly to GraphQL Code Generator, we\ncompletely revamped the GraphQL Mesh documentation.\nGetting started and learning the concepts is now a lot easier!Mesh's ongoing ambitious work aims to provide a better developer experience, stronger handlers, and\ncross-platform support.Here is a summary of what to expect from the last releases:Cross-platform supportThis initiative is initially born from\nour collaboration with The Graph in building The\nGraph client to query multiple GraphQL APIs as a unified schema, from the client-side.Following those requirements, GraphQL Mesh is now 100% browser compatible, and we will continue\nefforts to improve this support (smaller bundler, etc).Finally,\nGraphQL Mesh server architecture\nhas been completely rewritten with GraphQL Yoga and Envelop, making GraphQL Mesh easier to deploy to\nthe most server and serverless environments.You will find more information on how to deploy GraphQL Mesh on Serverless\nin our documentation.Better developer experienceThe experience of GraphQL Mesh users has been improved thanks to improved logging and a complete\nrewrite of the server architecture.GraphQL Mesh now relies on GraphQL Yoga and Envelop, you can easily customize the Envelop plugins\nby simply providing plugin lists\n(see the new experimental declarative plugin configuration)\nor a JavaScript file.OpenAPI handler rewriteWith the goal to provide a more stable and performance OpenAPI handler, the existing openapi\nhandler will be soon sunset and replaced by the new-openapi.This change will come with a migration guide.In the meantime, we highly advise you to give a try to the new-openapi handler to anticipate\nchanges in the generated GraphQL Schema.2022 is going to be an important year for GraphQL Mesh, stay tuned!","envelop#Envelop":"The v2 of Envelop, our GraphQL servers plugin system has been released!This version brings performance improvement and one breaking change:\nWe highly recommend avoiding using any plugins that use onResolversCalled within your production\nenvironment as it has a severe impact on the performance of the individual resolver functions\nwithin your schema.\nFinally, as you may know,\nwe believe that open source projects should live under a person's name - this way it\npromotes the person and not just the company, and also it creates a more healthy ownership model.Given his commitment to Envelop, we are happy to announce that the Envelop repository has been\ntransferred to Laurin!","kitql#KitQL":"KitQL is a new library built exclusively for SvelteKit, leveraging each and every possibility of\nthis fantastic way of building apps.It's making use of our EcoSystem & Best Practices like GraphQL-Yoga (for\nthe server), GraphQL-Modules (to organize things nicely),\nGraphQL-ESLint (to respect coding rules) and A fully\ntyped dedicated client abusing fetch & stores mechanisms.If you are in SvelteKit and want to use GraphQL (client and/or server), it's definitely the way to\ngo.Check our videos and all other resources here: Get started with KitQL.","releases#Releases":"graphql-eslint@3.10.3: ESLint parser, plugin, and set\nrules for GraphQL\ngraphql-tools@8.2.11: Build, mock, and stitch a\nGraphQL schema using the schema language\ngraphql-config@4.3.1: One configuration for all\nyour GraphQL projects\ngraphql-modules@2.0.0: Enterprise Grade Tooling For\nYour GraphQL Server\ngraphql-scalars@1.10.0: Custom GraphQL Scalars for\ncreating precise type-safe GraphQL schemas\napollo-angular@v3.0.1: 3.0 is out!\nSwiftGraphQL 2.3.1: A GraphQL client that lets you\nforget about GraphQL\n\nWe hope you enjoyed reading this first newsletter, you can find more information about our projects,\nblog posts and services on our brand new the-guild.dev website ✨Stay up to date by following us on Twitter and don't hesitate to\nreach out to us by replying to this email, opening an issue on our projects, chat with us via our\nwebsites or send an email to contact@the-guild.dev."}},"/services":{"title":"Our Services","data":{"":"Our Services"}},"/blog/graphql-tools-v8":{"title":"GraphQL Tools V8 - Stitch Federation Services","data":{"":"Ever since The Guild has taken over GraphQL Tools, we kept our promise and\nlike every open source library we maintain,\nwe keep improving and supporting it on a daily basis.Many things are continuously happening and improving with the library, and now, as we are releasing\na new major version, we wanted to share some new things we've added.It's important for us to say thank you to all our users and open source contributors. The driving\nforce behind this tremendous amount of work is you!TL;DR\nWe significantly improved GraphQL Stitching Performance\nYou can now manage Apollo Federation services using Schema Stitching Gateway\nYou can consume Relay services in the Gateway\nWe support upcoming graphql-js features like @defer and @stream\nMany more improvements in the release notes","faster-schema-stitching#Faster Schema Stitching":"We heavily worked on improving the performance of Schema Stitching by refactoring some parts of the\nquery planner, schema delegation and more. So we got much better performance than before. Please\ncheck the release notes to make sure you are good to start using v8 to benefit from all these\nimprovements!","more-flexible-schema-stitching#More Flexible Schema Stitching":"The modern Schema Stitching is fairly comparable to Apollo Federation with automated query planning,\nmerged types, and declarative schema directives.But it is also more configurable. You can configure your gateway and services in service level using\nStitching Directives or in the gateway level using Type Merging configuration.","manage-apollo-federation-services-with-schema-stitching-gateway#Manage Apollo Federation Services with Schema Stitching Gateway":"You can even consume your existing Apollo Federation services inside Schema Stitching without any\nchanges by using the federationToStitchingSDL utility function from\n@graphql-tools/stitching-directives. Please check the Stitching Handbook to learn more.Federation Services - Stitching Handbook","relay-based-gateway-possible#Relay-Based Gateway Possible?":"If you have multiple services using\nRelay Specification, you can\neasily combine them with the handleRelaySubschemas utility function from @graphql-tools/stitch\npackage, and your unified schema will handle Node interface and node operation automatically\nusing Type Merging.You can check the unit tests to see the complete usageIt is pretty new, and we will improve the documentation for this use case gradually.","what-is-type-merging#What Is Type Merging?":"Type merging allows partial definitions of a type to exist in any subschema, all of which are merged\ninto one unified type in the gateway schema. When querying for a merged type, the gateway smartly\ndelegates portions of a request to each relevant subschema in dependency order, and then combines\nall results for the final return.Type merging is now the preferred method of including GraphQL types across subschemas, replacing the\nneed for schema extensions (though does not preclude their use). To migrate from schema extensions,\nsimply enable type merging and then start replacing extensions one by one with merges.\n\nCheck out our documentation and stitching handbook to learn more about Type Merging!\nType Merging Docs\nStitching Handbook\n\nAlso, please watch this great presentation from Greg MacWilliam!","future-proof-schema-delegation#Future-Proof Schema Delegation":"GraphQL Tools v8 is getting prepared for incoming GraphQL-js features. With defer and stream,\nGraphQL execution will return Async Iterables even for query and mutation operations like\nsubscription ones. So we decided to remove Subscriber because we will need to handle Async\nIterables in Executor eventually.You can easily merge your existing Executor and Subscriber functions by checking the\noperationType of ExecutionParams;","create-graphqlschema-instances-for-your-remote-apis#Create GraphQLSchema Instances for Your Remote APIs":"URL Loader from @graphql-tools/url-loader package creates executable GraphQLSchema instances for\nyou to call your remote GraphQL APIs by using different protocols;\nServer Sent Events ✔️\nNew GraphQL-WS ✔️\nLegacy subscriptions-transport-ws ✔️\nMultipart File Uploads ✔️","create-executors-for-schema-stitching--delegation#Create Executors for Schema Stitching / Delegation":"You can easily create executors for subschemas like below:","and-more#And More...":"Git Loader now supports glob patterns\nGraphQL Tools is used by GraphQL Config, GraphQL Code Generator, GraphQL Inspector and more to\ndownload the type definitions and operation documents from the different sources with GraphQL\nTools Loaders.\nFor example to compare your schema against the master, you need to dump your schema into a\nsingle “schema.graphql” file and point the GraphQL Inspector to that file. But now you can use\nglob patterns to point multiple files on your Git repo, and you don't need to have a generated\nschema.graphql in the codebase.\n\n\nNo more a huge graphql-tools package;\nGraphQL Tools has a lot of packages for different use cases and previously we were publishing\ngraphql-tools package to the npm that includes all scoped packages we have in the repo. Let's\nsay when someone only needs makeExecutableSchema, NPM installs every single package with a lot\nof unused dependencies together with those. From now on, we decided to deprecate graphql-tools\nand encourage the users to migrate to the scoped packages. For example, you should install\n@graphql-tools/schema for makeExecutableSchema. You can check API Reference and the rest of\nthe documentation to find what packages you need.\n\n\nWe have removed some functions, methods and stuff that are not widely used by the community;\nmakeRemoteExecutableSchema\nIn the new GraphQL Tools, you don't need this at all. You can write your own executor by\nfollowing the documentation and use wrapSchema instead. Or you can use UrlLoader directly\nwithout the need of writing all the remote execution logic.\nThis was already being deprecated after v4 in favor of wrapSchema.\nYou can find the new usage in the docs.\n\n\nLegacy Schema Directives, visitSchema and directiveResolvers\nWe suggest you to\ncheck the new approach for schema directives and schema visiting in the documentation instead of these old approaches.\n\n\nAnd there are some other utility functions you might have been using from GraphQL Tools. You can\ncheck CHANGELOG to see rest of them."}},"/solutions":{"title":"Solutions","data":{"":"Essential GraphQL resources","guides#Guides":"GraphQL Error Handling\nGraphQL Authentication\nGraphQL Caching\nClient-side GraphQL typings\nGraphQL over WebSockets\nGraphQL over SEE\nMigrate a REST API to GraphQL\nSecuring your GraphQL API\nMonitor your GraphQL API","graphql-at-scale#GraphQL at Scale":"Schema Stitching\nManage your Schemas\nGraphQL Gateway with GraphQL Mesh"}},"/blog/whatsapp-clone-apollo-angular-graphql-typescript-and-postgresql":{"title":"WhatsApp Clone - Angular, GraphQL, Apollo, TypeScript and PostgreSQL","data":{"":"You might have seen it around already — an open-source WhatsApp Clone tutorial; a project which was\noriginally started in 2015 by Urigo based on\nAngular-Meteor and\nIonic, and have been throughout different incarnations ever since.You may have also noticed that we recently published a new\nReact version of the Whatsapp\nClone tutorial.This time around, I'm happy to announce that a new version of the WhatsApp Clone is here, and it's\nbased on Angular 7.2, Angular CLI 7.3.2, Material-UI, TypeScript, Apollo, GraphQL-Subscriptions,\nGraphQL Code Generator,\nGraphQL Modules, PostgreSQL and TypeORM, full with step by step\nguides to teach you every step of the way.Click mme to go to the tutorial page","what-is-it-good-for#What Is It Good for?":"This app was built with all the latest and hottest technologies out there. The purpose is simple —\nit should be a guideline for building a proper app, thus we thought very carefully about the design\npatterns and architecture used in it, plus, we made sure to cover all communication methods with a\nGraphQL-back-end in different variations (query, mutation, subscription). This way whenever you're\nlooking to start a new app, maintain an existing one or upgrade your dev-stack, the WhatsApp-clone\ncan be a great source to start with! It's full stack and has a complete flow.","why-did-we-choose-this-dev-stack#Why Did We Choose This Dev-Stack?":"Angular, GraphQL, Apollo, PostgreSQL and TypeScript for obvious reasons — they are backed by a\nstrong ecosystem that grows rapidly. These technologies can be used in endless variations, and\nthere's no one way which is the most right of doing so, but we chose a way that makes the most sense\nfor us and that we truly believe in when it comes to building apps. We've connected it all with\nTypeORM, GraphQL-Code-Generator, GraphQL-Modules for the following reasons:\nThe GraphQL back-end was implemented using GraphQL-Modules where logic was splitted into\nfeature based modules. GraphQL-Modules is a library which provides you with the ability to manage\nand maintain your GraphQL schema in a scalable and reusable way. Not once nor twice I have seen\npeople who struggle with that and get tangled upon their own creation, and with GraphQL-Modules\nwhere you have a very defined structure, this problem can be easily solved. You can read more in\nthis series of 7 blog posts about it.\nEvery GraphQL/TypeScript definition was automatically generated with GraphQL-Code-Generator using\na single command call. There's no need to maintain the same thing twice if it already exists in\none way or another. This way you don't have to write TypeScript type definitions for your all your\nserver responses, you get ready-to-use — fully typed Angular services, GraphQL resolvers and\nGraphQL types.\nThe new version of Angular 7.2 was used with the Angular Material UI and Angular CLI 7.3.2 (and\nwe'll keep updating the tutorial with the latest versions)\nWe used TypeORM to correctly split the logic of the entities in the database and define the\nrelationships between them. ORMs are controversial these days, but they can help a lot in some\ncases, and we thought a good example could be valuable to the community.","what-to-expect#What to Expect?":"Basic authentication.\nImage uploading with Cloudinary.\nLive updates with GraphQL Subscriptions.\nZero latency even on the slowest network thanks to Apollo's Cache\n\nThe tutorial goes through every aspect of building the app, starting from the very basics. We will\nstart building a very simple server with a fake db, then we will introduce Authentication,\nSubscriptions, a real database backed by PostgreSQL and TypeORM plus advanced tooling like GraphQL\nCode Generator and GraphQL Modules.This can be extremely useful for those who have little to no background in one of the technologies\nin our dev-stack.","whats-next#What's Next?":"Right now we implemented a simple REST-based Passport authentication, but\nwe already have PRs for Accounts-JS based authentication\nwhich will use the GraphQL endpoint instead of traditional REST ones. An additional chapter about\nPagination is also expected, as well as a “Performance” chapter tackling the N+1 problem with\nGraphQL. Our backend has been designed to handle way more features than the ones currently\nimplemented, so be ready because features like the Whatsapp blue ticks are going to land on our\nclone very soon.","keep-up-to-date#Keep up to Date":"This tutorial was written using Tortilla — the Tutorial framework.This means that we will keep upgrading the tutorial with the latest versions of Angular and the\nother libraries, and instead of doing the same tutorial all over again, you will get a\ngit-diff\nof how to upgrade the existing tutorial! We care about your time as a developer.","influence#Influence":"We want to hear your opinions!Should we choose another library and technology over another? Could we write the code\nbetter/cleaner? Should we add a specific feature to the app? We want to hear it all!Please tell us now, so we could integrate your feedback on the tutorial itself!We keep evolving the stack and as the tutorial is based on git commits, we can create the same clone\nwith different tech-stacks and compare them on this real app using code diffs.Soon we will also release yet another version of the Whatsapp Clone, using\nIonic, Stencil and Web Components.If you are good at creating screencast and videos, we would love your help in creating videos for\nsome chapters.Everything is completely free and open source, and we want your help and (not financial)\ncontribution!Best place would be to open an issue or create a PR on the repositories:\nServer — Urigo/WhatsApp-Clone-Server\nClient —\nUrigo/WhatsApp-Clone-Client-Angular\n\nAgain, all types of feedback is welcome, write freely!See you in the tutorial!"}},"/blog/how-should-you-pin-dependencies-and-why":{"title":"How should you pin dependencies and why?","data":{"":"","what-is-pinning-and-why-is-it-so-important#What Is Pinning and Why Is It so Important?":"With the term pinning we are referring to the practice of making explicit the version of the\nlibraries your application is depending on. Package managers like npm or yarn use\nsemver ranges by default, which basically allows you to install a “range” of\nversions instead of a specific one.By freezing the dependencies we want to achieve repeatable deployment and make sure that every\ndeveloper is testing on the very same codebase.","why-did-package-managers-default-to-semver#Why Did Package Managers Default to Semver?":"The main reason is to automatically get updates every time we run npm install (assuming you're not\nusing a lock file, more on that later). This is done because we want to get security fixes as fast\nas possible. The theory behind that is that\nsemantic versioning should protect us against\nbreaking chances, while still getting the security fixes.","what-happens-when-semver-fails#What Happens When Semver Fails?":"Unfortunately semantic versioning is far from being infallible and breakage might occur. Since\nmultiple dependencies can be updated at once when that happens you will have to manually check which\none to blame, and then you will be forced to pin it to fix the issue.With pinning, you will have to make a PR to update your dependencies and thus get some feedback from\nthe automated tests. So you will know exactly which dependency is going to break your app before\nthat happens.","tests-can-fail-either#Tests Can Fail Either":"Truth is that tests are not perfect either and chances are you probably didn't read the release\nnotes looking for breaking changes before merging a green-light PR. Nevertheless pinning still has a\nbig advantage even when the failure is not caught in time: instead of randomly looking for which\ndependency broke your code, you will be able to\nbisect the issue very quickly. Git\nbisecting is a quick way to roll back to previous commits and find out which one introduced the\nregression. Instead of doing it manually a git bisect allows you to specify a good commit and a bad\ncommit, then it will pick up a commit in the middle and ask you if it's good or bad. Depending on\nyour answer it will divide the leftmost or rightmost interval and iterate the process until the\nguilty commit is detected. The whole process can be automated and it's usually very quick.","downsides-of-pinning#Downsides of Pinning":"","automation#Automation":"You may be asking who is going to PR the repo every time a new dependency gets released, because\nthis is a very tedious task to be done manually. Fortunately there are several tools you can use to\nautomate the process, like Renovate. Such tools will constantly check for\ndependency updates and take care of automatically PR your repo.","libraries#Libraries":"The biggest downside of pinning concerns libraries development. If you are publishing you own\nlibrary to npm, and you decide to pin the dependencies then the incredibly narrow range of versions\nwill almost certainly lead to duplicates in node_module. If another package pinned a different\nversion you will end up with both and your bundle size will increase (and thus the loading times).\nAccording to Rhys Arkins (the author of Renovate), even if both\nauthors are using a service like Renovate this is still not a good idea:Even if both projects use a service like Renovate to keep their pinned dependencies up to date with\nthe very latest versions, it's still not a good idea — there will always be times when one package\nhas updated/released before the other one, and they will be out of sync. e.g. there might be a space\nof 30 minutes where your package specifies foobar 1.1.0 and the other one specifies 1.1.1 and\nyour joint downstream users end up with a duplicate.It must be noted that despite our best efforts' duplication is a “characteristic” of yarn and a\nsimple yarn upgrade against an existing lock file does not mean that the whole tree gets shaken\nfor duplicates. You will need post-processing of lock files using\nyarn-deduplicate to superseed this issue.Obviously everything we said about duplication doesn't apply to Node.js libraries, because the\nbundle size doesn't matter on the server.We explained why package.json pinning is a bad idea, but you may still be wondering if it is wise\nto publish the yarn.lock file along with your library.When you publish a package that contains a yarn.lock, any user of that library will not be\naffected by it. When you install dependencies in your application or library, only your own\nyarn.lock file is respected. Lockfiles within your dependencies will be ignored.Since the library lock file will be ignored when it gets installed as a dependency, it won't produce\nany duplication.","upgrade-noise#Upgrade Noise":"Going through dozens of PRs each and every day can be annoying. Fortunately Renovate gives you\nseveral solutions to deal with the problem, like auto-merging (this may sound scary, but if you\ndon't have full coverage you could automatically merge patch updates while manually merging minor\nand major updates), branch auto-merging (it's basically the same, but the dependency are merged in a\ntest branch which can be periodically merged back into master), scheduling (which allows you to\navoid immediate notifications) and packages grouping (Apollo-Client and all it's related packages in\none PR).","how-to-pin-packages#How to Pin Packages":"","packagejson-and-the-sub-dependencies-problem#package.json And the Sub-Dependencies Problem":"Historically the most common way to pin dependencies was to specify an exact version in your\npackage.json, for example using the --save-exact parameter with npm install (you can make it\ndefault by adding save-exact=true to your .npmrc). With yarn you can use --exact / -E.Unfortunately pinning in package.json will protect you against breakage of a very small portion of\nyour packages. If fact even when you pin a package all of its dependencies will still be free to\nupdate: you will protect yourself against a single bad release, but you will still be exposed to\ndozens through subdeps.\n\nEven if we pin @angular/compiler-cli we would still be exposed to dozens of sub-dependenciesTo make things worse, chances that a sub-dependency will break your app increase with package.json\npinning compared to semver: you're going to use unpinned (and thus newer) subdeps with older pinned\npackages and that combo will probably be less tested.","lock-files-to-the-rescue#Lock Files to the Rescue":"Both yarn and recent npm versions allow you to create a lock file. This allows you to lock each and\nevery package you depend on, including sub-dependencies.Despite what some people think, if you have \"@graphql-modules/core\": \"~0.2.15\" in your\npackage.json and you run yarn install, it won't install version 0.2.18: instead it will keep\nusing the version specified in yarn.lock. That means that your packages will practically be\n“pinned” despite not actually pinning any of them in package.json.To upgrade it to 0.2.18 you will have run yarn upgrade @graphql-modulules/core (note that it\nwon't upgrade up to 0.4.2, because it will still obey package.json).If a package is already at the latest version you can still use yarn upgrade <package> to update\nits sub-dependencies.Unfortunately it won't also update package.json to reflect ~0.2.18 because technically there is no\nneed (we're already in range). But honestly a lock file provides way less visibility compared to\npackage.json, because it's not designed to be human-readable. So if you're looking for dependency\nupdates you will have a hard time figuring it out, unless you're using yarn outdated. It eases\nyour work by looking through the lock file for you and reporting all the available updates in an\neasy-to-read format.Even with a lock file an unexperienced user could simply run yarn upgrade and update all\ndependencies at once. As we discussed previously this is very bad to keep track of dependency\nupdates, and you could have hard times figuring out which package to blame for breakage.","why-not-both#Why Not Both?":"In theory, you could get the best of both worlds if you use --exact while still using a lock file:\na human-readable format, protection against all sources of breakage (including sub-deps), protection\nagainst unwanted mass-upgrades ( yarn upgrade won't update anything if package.json is pinned).You get the best of both worlds, but this solution has some downsides as well. If you ever used\ntools like Angular CLI and in particular commands like ng new or ng update you probably noticed\nthat some dependencies like zone.js, rxjs or typescript will get tighter ranges (like ~ which\nmeans patch versions only) compared to others. This is because the Angular team knows that some\npackages could easily break a certain version of the framework and thus suggest you to not upgrade\nover a certain version: if you want a newer version they advise you to upgrade Angular itself\nbefore. By pinning package.json you will loose such useful advices and, if your test coverage is not\noptimal, risk to catch some subtle issues.","conclusion#Conclusion":"The ideal solution would be to use Renovate with\nupdateLockFiles enabled and\nrangeStrategy set to bump.\nThat way package.json will always reflect yarn.lock to provide a human-readable format. At the\nsame time package.json won't be pinned, so theoretically you could be able to use it to instruct\nRenovate about which dependencies to\nautomerge. I said theoretically\nbecause I would love Renovate to automerge in-range dependencies if automated tests are passing,\nwhile still undergoing through manual confirmation if they are out of the range specified in\npackage.json. Unfortunately it is only possible to automerge either major, minor or patch\nversions, but not according to package.json ranges. If an in-range option was available you could\nuse package.json to specify how confident do you feel about auto-merging a specific package: if you\nfeel comfortable you could use ^, if you feel more cautious just a ~, while if you want to\nmanually approve every and each upgrade simply pin it with --exact.For example let's say I have the following entries in my package.json:\n\nCurrently, if you set automerge to “patch” when zone.js 0.8.27 gets released it will\nautomatically merge the PR and the same would happen for tslib 1.9.1. Unfortunately once tslib\n1.10.0 gets released it won't be automatically merged, unless you decide to set automerge to\n“minor” (but then zone.js 0.9.0 will be automatically merged, which is not what we want).Basically I'd like renovate's automerging policy to obey package.json: ^ means automerge “minor”\non current package ~ means automerge “patch” on current package pinned version means never\nautomerge the current package.It's a way to get a more fine-grained control on the automerging policy, because some packages can\nbe more risky than others.Since we are stuck with either major, minor or patch for automerge, the only compelling reason\nto avoid package.json pinning is if you're using tools like ng update and you don't want to loose\nupstream update policies. If that doesn't bother you, you should add package.json pinning on top of\nyour lock file.","an-important-note-about-libraries#An Important Note about Libraries":"Everything we said in the conclusion applies to normal applications, but not libraries. As we said\npreviously with libraries we want to use wider ranges to prevent duplication. Unfortunately the\nbump rangeStrategy basically\nforces you to always use latest and greatest version, which could create some duplicates.\nFortunately we also have the update-lockfile\nrangeStrategy which bumps the\nversion in the lock file but keeps the range unchanged unless the update is out of range (if you\nrange is ^1.9.0 and 2.0.0 gets released it will bump the range)."}},"/blog/better-type-safety-for-resolvers-with-graphql-codegen":{"title":"Better Type Safety for your GraphQL resolvers with GraphQL Codegen","data":{"":"If you use TypeScript to write your GraphQL schema implementation, you'll love the integration with\nGraphQL Codegen and typescript-resolvers plugin.This plugin allows you to easily have typings for your resolvers, with super flexible configuration\nthat allow you to integrate it easily to your existing code, types and models.That means that you can type-seal your code and have complete type-safety: your GraphQL resolvers\nwill be typed (parent type, args, inputs, return value, context type), and you can use your own\nTypeScript type models, so you can have type-safety all across your implementation, from API to\ndatabase.Having type check on your resolvers can help to improve your code quality, detect issues in build\ntime (instead of runtime), and improve developer experience.","getting-started#Getting Started":"If you are already familiar with GraphQL Code Generator, you\ncan skip this step.Start by installing GraphQL Codegen and the relevant plugins:\n\nNow, create codegen.yml file with the following, make sure to point to your schema location:\n\n\nGraphQL Code Generator uses graphql-tools so you can point to your\nschema files, or /graphql endpoint.\nTo run GraphQL Codegen, use: yarn graphql-codegen (or, create a script for it if you wish). This\nshould create a new file called resolvers-types.python in your codebase.","simple-resolvers-signature#Simple Resolvers Signature":"In this example, we'll use the following GraphQL schema and resolvers as reference.\nYou can find a working live-demo of this part here.\n\nThis is a naive implementation of a GraphQL API, and we'll see how more advanced use cases could be\nimplemented in the upcoming steps.To get started with the generated files, import Resolvers identifier from your generated file, and\nuse it to type your resolvers object, for example:\n\nNow, TypeScript engine will verify that object you returned, and you'll be able to see that if\nyou'll change one of the fields, it will be type checked immediately:\n\nAlso, if you'll change your schema types and re-run the codegen (or use\nWatch Mode),\nit will re-generate the matching types and check your code again.As your probably understood, the default behavior of typescript-resolvers is using the base type\ngenerated by typescript, that means, that your schema types and resolvers needs to match and have\nthe same signature and structure.But it's not always the case - because your GraphQL schema, in most cases, isn't the same as your\nmodels types - this is why we have mappers configuration.","use-your-model-types#Use Your Model Types":"Models types are the way your data is being stored or represented behind the scenes. Think about\nUser object from example - in most cases, the representation of User in your database (or any\nother downstream API) is different than the way your represent User in your API. Sometimes it's\nbecause of security considerations, and sometimes because fields are internal and used only by you,\nand not by the consumers.Those model types are the actual objects that you are usually using in your resolvers code. Those\ncan be created manually (with a simple TypeScript type, interface or class), or created\nautomatically from your downstream APIs, database or any other data-source that you use in your app.The way to tell codegen where are your models types are located is called mappers.To use mappers configuration, we need first to setup a real type safety, and have models types for\nour actual objects.Let's assumes that your backend is implemented this way, with some models types:\n\nIt means that now, your resolvers implementation needs to adjusted and handle the different data\nstructure:\n\nNoticed the errors? it caused by the fact that we don't have the appropriate mapping set yet. We\nneed to tell GraphQL codegen that our schema types are different than the model types.To do that, let's update codegen config with mappers and add a mapping between a GraphQL type to a\nTypeScript type (and the file it's located in):\n\nThis way, GraphQL Codegen will use your custom models types in the generated output, instead of the\ndefault types, and your resolvers' implementation will look like that:\n\nNote that now you'll get autocomplete, type safety and a better connection between your GraphQL\nschema and your GraphQL resolvers:","typed-context#Typed Context":"typescript-resolvers also supports replacing the context type of your resolvers' implementation.\nAll you have to do, is to add this following to your codegen configuration:\n\nThis will make sure to replace any with MyContextType, and you'll be able to access a\nfully-typed context object in your resolvers.","whats-next#What's Next?":"A few notes that worth mentioning:\nYou can use mappers on every GraphQL type, interface or a union.\nYour resolvers' arguments (args) are also fully-typed, according to your schema definition.\nThe parent value is also fully typed, based on your mappers.\nYou can import your types from a node module package (User: models-lib#UserType).\nYou can also map to built-in language types (DateType: Date)\nAliasing the imports is also possible (User: ./models#User as MyCustomUserType)\n\nYou can also modify the default mapper (defaultMapper) and allow partial resolution, this will\nallow you to return partial objects in every resolver\n(more info):\n\nFor more advanced use-cases, you can find\nthe complete plugin documentation here."}},"/blog/apollo-angular-12":{"title":"Apollo-Angular 1.2 - using GraphQL in your apps just got a lot easier!","data":{"":"Check what's new in Apollo Angular and how to get the full potential benefits of using Angular +\nGraphQL + TypeScript combined thanks to GraphQL-Code-Generator.We are very excited to announce a new version of Apollo Angular that dramatically improves and\nsimplifies the usage of GraphQL with Angular.This version also adds production and scale related features, that our large Enterprise and\nproduction users had been asking for just testing","tldr#TL;DR":"Code generation for Apollo Angular\nQuery, Mutation, Subscription as an Angular service\nApollo Angular Boost\nTesting tools","introducing-query-mutation-and-subscription-as-an-angular-services#Introducing Query, Mutation and Subscription as an Angular Services":"Through almost two years of using GraphQL in Angular we gained a lot of experience, and learned how\npeople use the library.With the current API, having query and watchQuery methods sometimes confused a lot of\ndevelopers. For people who use Apollo for long time it's obvious but we often get asked about\ndifferences between them and many newcomers are surprised.\nWe decided to add a new approach of working with GraphQL in Angular.\n\n\nThere are now 3 new simpler APIs: Query, Mutation and Subscription. Each of them allows to\ndefine the shape of a result & variables.The only thing you need to do is to set the document property, That's it, and now you use it as a\nregular Angular service:\n\nIn our opinion, the new API is more intuitive and documents feels now like a first class-citizens.\nBut it also opens up the doors for something wayyyyy cooler!","taking-it-to-the-next-level#Taking It to the Next Level":"As an Angular developer, you already understand how much power Typescript adds to your development —\nthe Angular community took those capabilities to the next level with code generation, through things\nlike schematics.The GraphQL community also took the concept of static type capabilities into new places — over the\nAPI and managing data automatically at runtime with the query language.While using GraphQL, Typescript and Angular and maintaining apollo-angular in the past 2 years we\nalways keep thinking how can we get all those technologies closer to create something that is more\npowerful than the sum of its parts.","graphql-code-generator-for-apollo-angular#GraphQL Code Generator for Apollo Angular":"We are pleased to announce a new set of tools that takes the GraphQL schema from the server and the\nquery from the Angular component and generate everything in the middle for you!Just by consuming a static GraphQL schema and defining the data you need and its structure in a\nGraphQL Query, there is no need for you to write any Typescript! You already defined it, why writing\nit again?We will generate a strongly typed Angular service, for every defined query, mutation or\nsubscription, ready to use in your components!","how-it-works#How It Works":"You create a .graphql file with a document that you want to use in a component:\n\nNext, you run the\nGraphQL Code Generator — Angular Apollo Plugin\nto generate types and angular services.Then you simply import and use it as a regular, Angular service.\n\n\nGraphQL Code Generator takes query's name, makes it PascalCased and adds GQL suffix to it. An\nexample, “myFeed” becomes “MyFeedGQL”.\nSee it here in action and play with it:\n\nTo play with code generator try to clone this repository:\n\nUsing Angular, Typescript and GraphQL in a coordinated way, gives us new level of simplicity and\npower for our developer experience:\nLess code to write — no need to create a network call, no need to create Typescript typings,\nno need to create a dedicated Angular service\nStrongly typed out of the box — all types are being generated, no need to write any Typescript\ndefinitions and struggle to keep them updated\nFull developer experience of tools and IDEs — development time autocomplete and error\nchecking, not only across your frontend app but also with your API teams!\nTree-shakable thanks to Angular 6","more-thanks-to-graphql#More Thanks to GraphQL":"We believe GraphQL is a game changer in how you plan and create your frontend apps.The vision that guides us is that you should be able to sketch a list of data types your backend can\nprovide, sketch components and their data dependencies — and all the rest of the plumbing can be\ngenerated for you.Once you'll write an app like that, you will ask yourself why did you write all the other\nboilerplate code by yourself before.But we've just talked about one new feature in apollo-angular. there is more:\nTesting utilities There were a lot of questions about testing Apollo components, so we decided\nto finally release something with a similar API to the one Angular's HttpClient uses.\nSergey Fetiskin wrote\nan article about it.\nApollo Angular Boost It's hard for newcomers to get started with Apollo Angular. Inspired by\nApollo Boost we decided to create an Angular version of it. Here's\nan interactive example.\nCreate Apollo on DI level There is now an extra way to create Apollo Client. Instead of using\nApollo.create inside of a constructor, you can provide settings on Dependency Injection level.\nRead the\n“Using Dependency Injection”\nchapter in docs.\nGraphQL Subscription outside NgZone Apollo.subscribe accepts now a second argument in which\nyou can enable running subscription's callback outside NgZone.\nAutomatic Persisted Queries for Angular It's now possible to use APQ with Angular's\nHttpClient, just install this package.\n\n\nQuery and Mutation as a service on\nStackBlitz and\nGitHub\nQuery and Mutation —\nStep by step tutorial\nExample:\nApollo Angular Boost on StackBlitz\nApollo Angular repository\nDocumentation"}},"/blog/building-graphql-servers-in-2022":{"title":"Building GraphQL Servers in 2022","data":{"":"Building GraphQL servers in 2022 couldn't be any easier thanks to GraphQL Yoga. This year at\nHasuraCon\nI discussed how Yoga started, how it evolved, and what we can expect from the future.For many years of building GraphQL servers in the Node ecosystem, our choices have been limited.\nApollo Server library has dominated the ecosystem. With its pairing client library, it was often a\ngood fit for a very long time. However, I believe there are more mature and battle-tested solutions\navailable today, thanks to the evolution of Yoga.GraphQL Yoga takes a different approach by providing enough bells and\nwhistles that make you production-ready, but builds itself on top of the core primitives of HTTP.\nYoga is runtime agnostic too, so if you're currently working with Cloudflare Workers, Vercel\nFunctions, AWS Lambda or something else, Yoga will fit right in.GraphQL Yoga comes with Envelop, and is the recommended way you should be\nusing Envelop today to extend your GraphQL server.\n\nIf you haven't used Yoga before, this is how easy it is to create a production-ready GraphQL server:\n\nIf you are interested in following along with me to build a server, add plugins and more, you can\nwatch the recording of the workshop:\n\nHopefully you find this talk interesting, and you learn more about building GraphQL severs with\nYoga!"}},"/blog/angular-cli-meteor-no-eject":{"title":"Angular CLI + Meteor — No more ejecting Webpack Configuration","data":{"":"Previously, we have to eject Webpack configuration generated by Angular CLI to modify module aliases\nfor Meteor's special import syntax such as meteor/meteor and meteor/mongo etc. However, this is\nnot required after the latest release of Meteor Client Bundler. Now, MCB can create stub modules for\nthese imports.","quick-start#Quick Start":"Check out the example in\nangular-meteor.","how-to-add-meteor-client-to-your-existing-project#How to Add Meteor Client to Your Existing Project":"After installation of meteor-client-bundler:\n\n\n\n\nAdd meteor-client.config.json with the necessary options:\n\n\n\n\nAfter that, don't forget to add generated meteor-client.js to angular.json:\n\n\n\n\nOptionally, you can add postinstall script to generate all modules in every node_modules\ngeneration; because yarn or npm may remove your generated modules from this directory.\n\n\n\n\nReady to use!\n\nThank you for reading my blog post about using Angular CLI with new MCB. I'd appreciate your claps\nto this post if you like it."}},"/blog/connecting-react-native-and-meteor":{"title":"React Native and Meteor backend w/o any 3rd party library in 2018","data":{"":"","what-was-the-problem-and-the-existing-solutions#What Was the Problem and the Existing Solutions?":"I was working on a project that has RN frontend and Meteor backend, but uses\nreact-native-meteor npm package in RN\nproject. I couldn't share any code between them without struggling aliasing module import names and\nthe other stuff.I wanted to share the code between client and server like many Meteor projects do, because I was\nworking on backend with a React Native developer who hadn't know Meteor a lot. And, my TypeScript\ncode will help him to write less error-prone code with type-checking feature of VSCode.Then, I searched on Google for any alternative that makes the code sharing\navailable.react-native-meteor package is quite useful, but is not able to share the code between\nclient and server which Meteor does for Web.I found a pretty old alternative called\nmeteor-native-packages . It is a set of\nmodified core packages of Meteor that replaces Browser API codes with React Native and NodeJS\ncompatible ones . This idea makes Meteor Client work when they are bundled via\nmeteor-client-bundler. However, all these need to be synced with Meteor's native API which is\nreally hard to maintain.Also, we have another problem; older meteor-client-bundler versions haven't supported use of\nexternal node modules in the client project's node_modules.To summarize, there were various libraries and 3rd party solutions to connect React Native to Meteor\nsuch as react-native-meteor and meteor-native-packages with the challenge in\nmeteor-client-bundler .","solution-browser-polyfills-for-official-meteor-client#Solution: Browser Polyfills for Official Meteor Client":"I've published a different package\nreact-native-browser-polyfills that\nshims necessary APIs of browser to make Meteor's official client compatible with React Native that\nis bundled by meteor-client-bundler .I also added some features such as generating stub modules in node_modules directory to make\nmeteor/PACKAGE_NAME syntax available, and support the use of external npm dependencies in the\nclient project's node_modules directory for the official meteor/react-meteor-data package\ninstead of using the replication version in npm which has the same name. You can see more on the\nrelated post about MCB;\n\nAs you know, Meteor has SockJS built-in which is compatible with both browser and NodeJS. So, the\nonly problem is the code that uses DOM API. Luckily, WebSocket has already been implemented by\nReact Native. There is another savior for the rest.react-native-browser-polyfills has been just released for polyfill DOM API including\nlocalStorage , navigator.connection , document.location and some other subsets that uses React\nNative API equivalent ones.AsyncStorage is used for localStorage , NetInfo is used for navigator.connection and\nLinking is used for document.location . But, the problem is that these APIs from React Native\nare asynchronous while they are synchronous in browser. As a workaround,\nreact-native-browser-polyfills waits for resolving their promises, then emits DOMContentsLoaded\nfor document which Meteor Client would be waiting for in order to initiate the connection between\nRN and Meteor backend.","also-we-have-facebook-twitter-and-google-login-on-react-native-and-meteor-stack#Also, We Have Facebook, Twitter and Google Login on React Native and Meteor Stack":"This was the most challenging one which is solved by another package\nreact-native-meteor-polyfills that\nextends react-native-browser-polyfills .I've released another package react-native-meteor-polyfills to polyfill window.open with\nLinking by extending react-native-browser-polyfills. However, this polyfill must be included to\nMeteor project as well to make it able to redirect to the RN app after a successful OAuth login.Thanks to this polyfill, you can use accounts-{SERVICE_NAME} packages without any extra native\nlibraries.","easy-start-with-boilerplate#Easy Start with Boilerplate":"Just check out this up-to-date boilerplate;https://github.com/DAB0mB/ReactNativeMeteorBoilerplate","how-to-add-all-these-to-your-existing-project#How to Add All These to Your Existing Project":"If you want to learn more to integrate all these features to your existing RN and Meteor projects\nstep-by-step;\nFirst, install react-native-meteor-polyfillsin both Meteor and RN projects.\n\n\n\n\n\n\nInstall meteor-client-bundler in your RN project\n\n\n\n\nAdd meteor-client.config.json ;\n\n\n\n\nAdd postinstall to your package.json of your RN project, because generated meteor-client.js\nand other stub modules might be deleted. This script will restore them after each node_modules\ninstall.\n\n\n\n\nFinally, run this script to generate those modules.\nAfter that do not forget to include react-native-meteor-polyfills/client and meteor-client in\nthe top of React Native entry file App.jsx or index.*.js etc.\n\n\n\nIf you never used Meteor with React before, check out Meteor's official documentation for\nreact-meteor-data package, and OAuth packages.And, YOUR NEW STACK IS READY TO RUN!","optional-facebook-twitter-and-google-login-support#Optional: Facebook, Twitter and Google Login Support":"If you want to make Meteor.loginWith work with React Native, you have to add custom URI scheme\nto your React Native project.\nThen, tell Meteor what your URI scheme is;","contribution#Contribution":"If you find any bugs, problems and issues, please open a new issue on GitHub. If you solve any of\nthem, please feel free to push a pull request.I'd appreciate your claps and comments for this post!","credits#Credits":"Special thanks to:\nEytan Manor\nUri Goldshtein"}},"/blog/graphql-codegen-java":{"title":"GraphQL Codegen adds new Apollo-Android and Java plugins","data":{"":"As you probably already know, GraphQL Code Generator has\nbecome the most popular GraphQL code generation tool in the community.We constantly improve the underlying tools and also create more generators and plugins.One thing that some people often miss about GraphQL Code Generator, is that its programming language\nagnostic.We have many plugins from the community to generate different language outputs like C#, ReasonML,\nDart and others.But today we want to announce something new — we now have 2 new official plugins for Java.A Apollo-Android generator and a\nJava backend resolvers signature\ngenerator.We've created those plugins because we needed them for some of our clients' production applications\nand the current tools in the ecosystem that are currently out there weren't sufficient enough for\nus.","apollo-android#Apollo-Android":"The new plugin allows you to generate Java code if your project is using Apollo-Android.It includes a query builder and a response builders (for converting the network response into a\ntype-safe classes), and it integrates with Apollo-Android runtime.The goal of the generated code is to let you use your GraphQL operations (query, mutation,\nsubscription and fragment) without the need to convert JSONs or deal with HTTP requests — you\njust need to write your operations, run the codegen and you'll get ready-to-use Java classes.The reason we decided to implement our own plugin was because now that we need to use it in large\nproduction apps, the current tools in the ecosystem weren't sufficient enough for us.We also think this is a good opportunity for the community to iterate faster because of all the\nawesome capabilities the generator already has.Using the GraphQL Code Generator infrastructure, we make sure that customization of the generated\ncode will be much easier, and fixing bugs and adding features will be simpler and faster.It also makes it much easier to load your schema from everywhere (either from a url, local file,\nintrospection, or directly from code files containing strings), customize your GraphQL Scalars and\nmap them to Java types, customize the names of the generated classes, the output path and more.The new plugin will be available today in beta using the following tag — 1.2.2-beta.01.","how-to-try-it-now#How to Try It Now?":"Next week we are also planning to make it easier to integrate the plugin by building a Gradle plugin\nthat wraps the execution of the Codegen, and integrates it with the Java ecosystem.On the stable release this Gradle plugin will be available, but for now, if you wish to try it now,\nyou'll need to configure it manually.Because the current GraphQL Code Generator package is released on NPM, you'll need to create a\nsimple package.json file with the following content:\n\nNext, create the codegen.yml config file with the following content:\n\nYou can use your GraphQL endpoint if your schema is not available locally.Next, you need to configure your Gradle build configuration by adding the following dependency to\nyour build.gradle:\n\nAlso, add a build step:\n\nNow, when you'll run your Gradle build, it will make sure to download the Codegen and it's plugins,\nand will generate the Java classes for you.The usage of the generated code is the same you had before, just follow\nthe instructions of Apollo-Android runtime.","java-backend-resolver-plugin#Java Backend Resolver Plugin":"The other plugin generates resolvers signature, that allow you to integrate your Java models classes\nto the generated signature, so you'll get a type-safe implementation of your resolvers.It's based on graphql-java and compatible with its implementation for\nDataFetchers.Follow the instructions above, but use this package.json:\n\nThen, for the following schema:\n\nAnd the following codegen.yml configuration, that maps your GraphQ types into your Java models:\n\nYou'll get a complete type-safe resolvers signature:\n\nNow you can use it as base interface for your DataFetcher implementation, and get a type-safe\nresolvers!","whats-next#What's Next?":"We are getting close to a stable release for those plugins and want your opinions on them.As mentioned, the stable release will also include a Gradle plugin to make it easier to integrate\nthe Codegen with the Java ecosystem.Please try it out today, and send us a feedback. Our goal is to make this plugin easy to use, and\neasy to customize, and you would see how quickly we manage, respond and solve issues on our open\nsource tools, which is something we are very proud of."}},"/blog/dependency-injection-library-in-graphql-modules":{"title":"Dependency Injection in GraphQL-Modules","data":{"":"","why-not-inversify--angular--nestjs#Why Not Inversify / Angular / NestJS?":"When designing GraphQL Modules, we tried different approaches to encapsulate modules safely. We\ncreated a solution where you won't need to use Dependency Injection when you start, but after you\nare getting to a certain scale, you can make use of our separate DI library to ease the separation\nand make the boundaries stricter, only at the point when it really makes sense and helps you. When\nyou get to that point, DI helps you mostly for ease of mocking providers for testing and\nencapsulation for less error-prone implementation.In the early stages of GraphQL-Modules, it used to have\nInversify internally for Dependency Injection in\nGraphQL-Modules. Inversify is a platform-agnostic Dependency Injection library written in\nJavaScript. Unfortunately, Inversify didn't fit our needs for modular DI (Dependency\nInjection) due to some critical reasons that we'll expand on this article.That's why, we implemented our own platform-agnostic Dependency Injection library called\n@graphql-modules/di which is independent from @graphql-modules/core, and it can be used by\nitself.It supports factory, class and value providers that can have Symbol, string, number,\nfunction and object tokens in a provide definition, and it can address constructable classes,\nfactory functions and constant values as injected values. It has some features that are similar to\nAngular's Dependency Injection that is mentioned in\ntheir documentation. In this article we'll explain the similarities and differences between those\nsolutions.Let's start with the principles we wanted to have in our DI logic, and we will finish with the\ncomparisons with Angular and NestJS.","encapsulation#Encapsulation":"While we were still using Inversify, we used to have a single GraphQLApp top module. Regular\nGraphQL Modules cannot import each other, but can be imported by that GraphQLApp object. Also\nthese modules didn't have an encapsulation, because all the providers, schemas and\nresolvers were getting concatenated without any encapsulation. After that, we decided to\nprovide complete Modular approach, and make everything module. Now Each module has its own injector,\nvalid schema and context which is independent from its parent modules. Also, each module is\nconstructed by using the imported modules' DI containers, schema contents and context builders.If you want to know more about encapsulation see the blog post about it;\n\nFor example, if you have a DatabaseModule in your application that has to be shared across the\nwhole application, and it needs to take a custom provider that will be defined by the user. What you\nwill do in those DI implementations is to create a provider by decorating it with a global scoped\nprovider; then put it in ApplicationModule. However, this would violate the\nencapsulation principle of the modular approach.To summarize; while your DatabaseModule is imported by other modules in the lower level and\nthat module will use a provider in its parent. It mustn't know what imports it.We handle this in a different way in GraphQL Modules by passing configuration by obeying the\nencapsulation rule;\n\nThe three benefits we have with this type of DI and modular system;\nAppModule is protected from an unsafe call without a valid configuration that is needed in the\ninternal process (DatabaseModule); thanks to configRequired .\nDatabaseModule is protected from an unsafe import without a valid configuration that is needed\nin the internal process (SomeDbProvider); thanks to configRequired again!\nOtherModuleThatUsesDb is protected from an unsafe call or import without a definition of a\nwell-configured DatabaseModule.","hierarchy#Hierarchy":"We also have another problem about the hierarchical approach of existing DI implementations. Let me\ngive an example;\nA DI Container has FooProvider\nB DI Container has BarProvider\nC DI Container has BazProvider\nD DI Container has QuxProvider\nA imports B\nB imports D\nB imports C\n\nFor example the following case will happen in our DI;\nFooProvider cannot be injected inside B while BarProvider can be injected by\nA; because the injector of B only have its providers and D's and C's\n(BazProvider and QuxProvider).\n\nAs you can see in the comparison with Inversify, Inversify can attach only one child DI\ncontainer in a parent DI container; and this wouldn't fit our hierarchy-based modular approach. For\nexample, you cannot make B extend both D and C by keeping D and C encapsulated.\nIf you merge all of them into the one injector like Angular does, D can access C's providers\nwithout importing C.","scoped-providers#Scoped Providers":"In contrast with client side application, your DI system wouldn't need to have different scopes like\nApplication Scope and Session Scope. In our implementation, we can define providers that have a\nlifetime during a single GraphQL Network Request and not the whole the application runtime; because\nsome providers needs to belong in a single client. Unfortunately, you need to find tricky ways to\nmanage scoped providers if you use existing DI libraries like Inversify.\nIn server-side applications, every client request has its own scope that we call `session\nscope`. We think this session scope should be able to have its own providers and DI logic\noutside the application scope.\nYou can read more about the different scopes that we have in GraphQL-Modules here:","comparisons-with-other-di-implementations-of-frameworks#Comparisons with Other DI Implementations of Frameworks":"","comparison-with-inversify#Comparison with Inversify":"To provide true encapsulation; we should have an injector/container with multiple children,\nand these children must not know each other and even its parent. In Inversify, they have\nsomething like that which is called Hierarchical DI. In this feature of Inversify,\ntheparent term can be misunderstood. because an injector seeks for its own providers then looks\nfor the other injector that is being defined as parent in that feature. But, we need is more than\nthat. We want to have multiple parent according to their logic.\nEvery module has its own injector together with its children's injectors. So, every module can\ninteract with its children's providers with its own injector.\nYou can read more about Hierarchy and Encapsulation in the beginning of this article.","comparison-with-angulars-di#Comparison with Angular's DI":"In Angular, there is one injector that is shared across all the application while there are\ndifferent encapsulated injectors belonging to each module in different scope.\nOur Dependency Injection implementation is more strict in terms of encapsulation than Angular's.\n\n\nThis is an example top module written in Angular. Let's assume FooProvider originally implemented\nand defined inside FooModule and used by BarModule . When FooProvider token is replaced by\nMyFooProvider in AppModule scope, BarModule also uses our MyFooProvider inside its logic.\nThis explicitly violates encapsulation in the modular approach, because Angular is supposed to send\nto BarModule FooModule 's FooProvider implementation instead of the one defined outside of\nBarModule ; because it shouldn't know what is defined in the higher level.\n\nHowever, GraphQL-Modules will send to BarModule the correct FooProvider , because BarModule\nimports FooModule not AppModule . So, MyFooProvider will be sent if the current injector is\ninside AppModule scope.In GraphQL-Modules, if A imports B and B imports C, A can access C's scope. But, C cannot access the\nscopes of B and A. This allows us to create a safely built GraphQL Application and reduces the error\nprone. You can read more about Hierarchy and Encapsulation in the beginning of this article.Angular doesn't care about that. it has a single injector for the all application. This may cause\nsome problems for debugging on a large scale backend application.\nThat ability is not so important for Angular applications; because they are running on the\nbrowser, not on the server. But still you can notice the similar behavior to GraphQL-Modules DI's\nif you load an Angular module lazily using router's loadChildren property.\nAnd Angular's DI library doesn't differentiate Application and Session scopes because it doesn't\nneed that. An Angular application has a lifetime until window is terminated by closing it or\nrefreshing page; the session and application runtime can be considered same in the client\napplication. That's why, our DI implementation is more complex than Angular's as it need to handle\nmultiple clients by running a single application. You can read more about\nScoped Providers in the beginning of this article","comparison-with-nestjs-di-implementation#Comparison with NestJS' DI Implementation":"NestJS is a server-side model-view-controller full-fledged framework that has all the principles of\nMVC Backend framework. exposing a GraphQL API is only one of its various features. Our goal with\nGraphQL Modules was to create a set of tools and libraries that answer needs for the GraphQL\necosystem, and can be (and should be) used by NestJS users as well.\nThe principles and approaches we're trying to apply in GraphQL Modules is not only for Dependency\nInjection but also for GraphQL Schemas and Context.\nIn comparison to Nest's goals, GraphQL-Modules is a platform-agnostic library that can be used even\nwith the plain graphqljs package without a server; because it was designed to work exactly\nsame in all GraphQL Server platforms such as Apollo, Yoga, graphql-express etc. For example, you can\nuse Apollo's data sources with graphql-express; because GraphQL Modules passes its own cache\nmechanism into the dataloaders thanks to our independent DI logic.\nThe result of a GraphQLModule is a context builder and a schema while NestJS' GraphQLModule is a\nNestJS module that exposes an API using Apollo.\nNestJS has its own dependency injection system which is similar to Angular's but more strict;\nyou can define both global (not by default like Angular) and encapsulated providers at the same\ntime. We preferred not to have global providers like Angular (you can see how it works above in the\nAngular comparison); because we consider it can be more error-prone, and it has to be done by\npassing configuration. You can read more with an example about passing configuration and keeping\nsafe boundaries between your modules in the\nEncapsulation article.Also, NestJS DI system doesn't share the important feature of defining providers that have the\nlife-time of the client request (we call it session scope). We think a backend system would need\nto differentiate DI containers according to these different scopes. You can read more about it in\nScoped Providers part of this article above.","working-together#Working Together":"We wanted to share the principles behind our implementation in order to get more background to our\ncommunity and get feedback from other library authors.That is also one of the reasons we created our DI library as a separate library, not only so it\nwould be optional to our users, but also to potentially share that implementation with other\nlibraries like NestJS and Inversify for example.","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/graphql-codegen-relay-compiler":{"title":"Optimizing Apollo Operations - GraphQL Code Generator & Relay Compiler","data":{"":"As a TypeScript developer, I love working with the\nGraphQL Code Generator. It is a very powerful code generation\ntool for both your frontend and your backend. Instead of having to manually create types for\nsomething your GraphQL Schema already provides, due to its type-safe nature, you can actually focus\non building the product.Currently, my favorite library for querying GraphQL backends is react-apollo. Supercharged with\nthe GraphQL Code Generator the library unleashes an almost unfair productivity boost compared to\nevery other data fetching stack I have used in my career as a software developer.Of course, I have heard of other libraries before, but until recently I never had the motivation of\nactually using another one.This, however, changed after watching the\nF8 presentation about the Facebook.com rewrite.I totally fell in love with the \"component specify their data requirements approach\", which is\nimplemented by utilizing GraphQL Fragments.As an Apollo user, I have used fragments before, but not in the same way Relay does.Let's take a look at the following Fragment:\n\nHow would you reuse this fragment with different values for the width and height arguments?Previously there have been two ways I would have tackled this:1. Write a new fragment with different parametersWell, just creating a new document for our avatar won't really solve the reusability issue.2. Use variables and rely on the query to have those definedActually, you can already use variables inside fragments. We just need to ensure that the query that\nuses the fragment also has those variables in the variable definition.Fragment Definition:\n\nQuery Definition:\n\nHowever, we now rely on having those parameters provided in each query that uses that fragment.This does not really make the fragment reusable. Imagine having a profile query of a with a friend\nlist. The profile picture should be bigger than the ones of the friends.\n\nIt is basically impossible to use a different width and height for the second usage of the fragment\nin that query.Furthermore, when using different fragments you have to be really careful with your variable names,\nbecause of variable name clashes.Given those limitations, it is pretty obvious that this “solution” does not scale well.I have experienced this limitation before and I am amazed how Relay solves itRelay simply uses custom GraphQL directives to address this issue.Defining Fragment Variables with @argumentDefinitions\n\nProviding Fragment Variables with @arguments\n\nPretty powerful, right?Unfortunately, you cannot simply use those fragments with your existing GraphQL Server.\n@argumentDefinitions and @arguments are some custom directives that need to be understood by the\nserver in order to process them.However, instead of implementing those directives on the serverside Relay went another route. The\nrelay-compiler removes those directives at build time. That means after our query has been\nprocessed it looks something like the following:\n\nPretty neat. This allows the query the be accepted by every GraphQL server (that, of course,\nprovides the correct schema), without relying on those custom directives.The relay-compiler is awesome!It comes with a lot more transforms. Some of those are specific to the relay-runtime (which as the\nname says is executed in the browser of the user like react-apollo), but others are definitely also\nbeneficial to non-relay users.Besides the so-called RelayApplyFragmentArgumentTransform there is a bunch of more useful stuff.E.g. the FlattenTransform can improve our query even more:\n\nI also built a relay-compiler REPL (use it for convincing\nyour team 😉).Of course, you can also read more about those in the\nOfficial Relay Documentation.Especially on big queries, that utilize many fragments, those transforms can drastically reduce the\nquery payload size, resulting in faster response times. For developers that cannot use persisted\nqueries (because they do not own the server), this is a must-have!After having seen all those benefits that Relay users can leverage I was convinced that I want to\nuse those as well.But unfortunately, I was still working with Apollo. 😅What if there was a way to use the relay-compiler with Apollo?I was already generating code with the GraphQL Code Generator.So maybe we can transform the queries before the GraphQL Code Generator outputs the generated\ncode?\n\nAfter some investigation in the Relay and the GraphQL Code Generator codebase, I had a working\nversion ready for use.Given those Relay superpowers, I now feel even more productive.For those curious, I also created a sample project:\nTodoMVC Apollo\n(Converted from the Relay Examples).Of course, you can also take a look at (and use!) the\nRelay Operation OptimizerExample configuration for a react-apollo project:codegen.yml\n\nI hope you enjoyed reading this! Are you already using Relay? Do you feel like you want to add the\nrelay-compiler into your GraphQL toolbox?Also, feel free to follow me on these platforms, if you enjoyed this article I ensure you that a lot\nmore awesome content will follow. I write about JavaScript, Node, React and GraphQL.\nDev.to\nMedium\nTwitter\nGithub\n\nHave an awesome and productive day!"}},"/blog/graphql-let":{"title":"graphql-let - A Webpack loader for GraphQL Code Generator","data":{"":"graphql-let is a wrapper tool that makes using\nGraphQL Code Generator smoother and easier. In this article, I'll explain what graphql-let is and\nhow it relates to GraphQL Code Generator.","what-is-graphql-let#What Is graphql-let?":"\"It's a webpack loader\" would be a simple explanation to start. It lets you directly import GraphQL\ndocuments and use GraphQL Code Generator's result as below:\n\nThe fastest way to try graphql-let is to use\nthe Next.js example from their official repository\nby hitting the following command.\n\ngraphql-let is made for enhancing the development pattern using TypeScript and GraphQL, the\nmost effective combination to solve many front-end problems in 2020. It heavily depends on GraphQL\nCode Generator, so in other words, if you don't use any of TypeScript and GraphQL Code Generator,\nyou don't need graphql-let either.graphql-let's configuration file, .graphql-let.yml, looks intentionally similar to codegen.yml\nof GraphQL Codegen. Next, I'll explain what graphql-let does by calling GraphQL Code Generator's\nAPI under the hood.","what-does-graphq-let-add-on-top-of-graphql-code-generator-api#What Does graphq-let Add on Top of GraphQL Code Generator API?":"GraphQL Code Generator is an awesome tool. It's an infrastructure to expand the possibility of\nGraphQL nowadays. graphql-let is in devDependencies as well as GraphQL Code Generator, so it does\nnothing in runtime-level too. graphql-let eases two pain points while you develop using codegen\ncommand of GraphQL Code Generator.With GraphQL Code Generator,\nYou need to point to the output path as import \"../../../__generated__/out.python\" everywhere\nYou need to run the graphql-codegen command manually every time you change the single file\n\nWith graphql-let,\nYou can directly import GraphQL source as import \"./news.graphql\" thanks to the webpack power.\nYou can process codegen in HMR too, thanks to webpack again.\nIt achieved the above by getting rid of the generates option, where graphql-let takes care of\ngenerated paths and lets you forget them.\n\nPlease note that there are limitations, mainly because graphql-let controls output paths. I'd\nrecommend you\nread the documentation\nonce to get the picture of how graphql-let and GraphQL Code Generator different.","other-features#Other Features":"There are other convenient features graphql-let provides to make it more practical.","import-syntax-support##import Syntax Support":"#import is useful to share fragments of GraphQL document, especially when your project codebase\nbecomes big. If you have a fragment file named partial.graphql like this,\n\nyou can share it from other places by importing it.","jest-transformer#Jest Transformer":"graphql-let exports graphql-let/jestTransformer that you can use in Jest testing. Please\nread the docs for more information.","babel-plugin-for-inline-graphql-documents#Babel Plugin for Inline GraphQL Documents":"It's still partial support, but graphql-let provides a babel plugin to allows developers to write\ninline GraphQL documents.\n\nIt generates .d.python files in node_modules/@types/graphql-let by default to apply overload\nsignatures on the function gql. Ideally, it should be available in both a babel plugin and the\nwebpack loader but there needs to be more effort.","why-i-made-graphql-let#Why I Made graphql-let":"I made this for front-end devs to adopt the TypeScript and GraphQL even more in their project😄When I actively maintained\nkriasoft/react-starter-kit a few years ago, I\nrealized it's so happy to use Apollo Server and Apollo Client. At the moment, though, Apollo\nprimarily supported HOCs instead of React Hooks, which leads to troublesome to match types of\nGraphQL operations and fetched data manually. Then, @graphql-codegen/typescript-react-apollo\nappeared and solved all the problems, except ones that graphql-let deals with later.The less setup process GraphQL development requires, the more people can adopt GraphQL I believe,\nsimply because GraphQL itself solves many problems web development has been struggling with without\nit for a decade. I couldn't be happier if a few of you get to know the power of GraphQL through\nusing graphql-let."}},"/blog/graphql-modules-scoped-providers":{"title":"Scoped Providers in GraphQL-Modules","data":{"":"We recently released a new version of GraphQL-Modules with a new feature called Scoped Providers in\nthe dependency injection system of GraphQL-Modules.Dependency injection in GraphQL-Modules is optional, and you can use it according to your\npreference. It provides a solution for writing Providers, which are just classes, you can use to\nwrite your business-logic, and this way to separate it from your API declaration, reuse it, and\ncommunicate between modules easily.This new feature allows you to define Providers to be used in different scopes;","application-scope#Application Scope":"If you define a provider in this scope which is default, the provider will be instantiated on\napplication-start and will be same in the entire application and all the following requests. The\nproviders in this scope can be considered as a shared state across all users' interactions with our\napplication. It's basically means that the instance will be treated as\nSingleton.For example, you have a provider called ExampleApplicationProvider , then this provider has a\ncounter in it;\n\nAnd let's assume that we have a module declaration something like below;\n\nFinally, let's try to call the following GraphQL Request in multiple times;\n\nIn first call, you will get 1 , but in the second call you will get 2 . And in every request\nthis value will be incremented; because Application-Scoped Providers are kept in memory until the\napplication is terminated; and the same instance of that provider will be used on each request.\nLet's see other types of providers to understand this one better.","session-scope#Session Scope":"When a network request is arriving to your GraphQL-Server, GraphQL-Server calls the context factory\nof the parent module. The parent module creates a session injector together with instantiating\nsession-scoped providers with that session object which contains the current context, session\ninjector and network request. This session object is passed through module's resolvers using\nmodule's context.In other words, providers defined in the session scope are constructed in the beginning of the\nnetwork request, then kept until the network request is closed. While application-scoped providers\nis kept during the application runtime, and shared between all the following network requests and\nresolvers inside these requests, this type of providers would not be shared between different\nrequests but in resolver calls those belong to same network request.Let's try the same thing in that scope by creating a new provider called ExampleSessionProvider .\n\nThen change our module declaration to use this provider;\n\nSo at this time, in every mutation call our Session-Scoped Provider's increment method will be\ncalled and its value will be returned as a result of that mutation.\n\nIn first call, you will get 1 , but in the second call you will get 1 again. But why? Because on\neach request ExampleSessionProvider is instantiated from scratch specifically for that network\nrequest which is called session in our DI system. But to see the point of the session scope, let's\nassume we have two more resolvers called multiply . First let's add another method called\nmultiply that takes one argument to be multiplied by our counter value;\n\nAfter that, let's use this new method in our new resolver;\n\nWhen we call the following GraphQL request,\n\nIn first call, the initial counter value 0 will be incremented . Then the result becomes 1 and\nthis value will be returned as a result of increment mutation, but on the same request we have\nmultiply as well. So the same counter value will be multiplied by 2 , and this value will be\nreturned as a result of multiply mutation.So, on every request the result will be:\n\nBut if the provider is in ApplicationScope, the result will be [3,6] in the second call.","request-scope#Request Scope":"If you have request-scoped providers in your GraphQL Module, these providers are generated in every\ninjection. This means a request-scoped provider is never kept neither application state, nor session\nstate. So, this type of providers works just like\nFactory. It creates an instance each time\nyou request from the injector.Let's assume we do the similar changes for RequestScope. The results will be like below on each\nrequest:\n\nBecause request-scoped providers are constructed on each injector.get call. They are kept in the\ncurrent function scope, they're not kept in any session or DI container. That's why, we can consider\nthem factory .As you can see the example and the results above, ExampleApplicationProvider is shared between\ndifferent network requests, while ExampleSessionProvider is shared between resolver-calls inside\nthe same network request. But, ExampleRequestProvider is only kept in the same resolver call.","new-modulesessioninfo-built-in-provider#New ModuleSessionInfo Built-In Provider":"Let's assume that you have a token required for your authentication process. And this token is\nprobably stored in request header. And GraphQL-Modules provides you access to network request in a\nbuilt-in provider called ModuleSessionInfo. This session object is the raw request/response\nobject passed by your HTTP Server. For example, if you're using Express, you will get something like\n{ req: IncommingMessage, res: Response } .Every GraphQL-Module creates a ModuleSessionInfo instance in each network request that contains\nraw Session from the GraphQL Server, SessionInjector that contains Session-scoped instances\ntogether with Application-scoped ones and Context object which is constructed with\ncontextBuilder of the module. But, notice that you cannot use this built-in provider.\n\nAs you can see, you cannot use ModuleSessionInfo in Application Scope, because application-scoped\nproviders belong to the whole application, and application-scoped providers are completely\nindependent of the network request.However, you can use onRequest hook to have ModuleSessionInfo in your Application-Scoped\nprovider which is called on each network request.","whats-next#What's Next?":"We are constantly trying to improve the set of tools provided by GraphQL-Modules, and we welcome\nyou to try it and share your experience and thoughts.","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/graphql-codegen-best-practices":{"title":"Integrating GraphQL Code Generator in your frontend applications","data":{"":"In this article we'll try to explain and demonstrate common patterns for frontend development with\nGraphQL and GraphQL Code Generator.Most patterns are general and can be applied to most popular frontend frameworks (React, Angular,\nVue, Stencil), and to popular GraphQL client libraries (Apollo / urql), due to extended support of\nGraphQL Code Generator, and it's flexibility.In this article, we'll cover the development workflow of frontend applications with TypeScript and\nGraphQL Code Generator, suggest best-practices for GraphQL development for frontend developers,\nand try to explain the idea behind it.","why-do-i-need-graphql-code-generator-in-my-project#Why Do I Need GraphQL Code Generator in My Project?":"Let's start by understanding the need for GraphQL Code Generator in your project.If you are using TypeScript for frontend development, you probably aim to get the most out of the\nTypeScript type-system, that means, that your preference should be to have typed variables all\nacross your application.It starts with the code you write - UI components, services and business logic. You can also have\ntype safety for your third-party libraries (some built-in, and some with @types/... packages).The idea behind type-safety is to make sure that your code can be statically analyzed and built,\nbefore running it. It's useful because this way your can detect potential bugs before they happen in\nruntime.","but-what-about-the-data-your-fetch-from-external-services#But What about the Data Your Fetch from External Services?":"So if you are already using GraphQL, you probably know that your GraphQL API is typed, and built as\na GraphQL schema.And it doesn't matter which language or platform is used to write your GraphQL API or schema - you\nfetch it the same way into your frontend application - with GraphQL operations (query / mutation\n/ subscriptions, and fragment) and probably over HTTP.So if your GraphQL schema is typed already, and your GraphQL operations allow you to choose specific\nfields from it (called Selection Set), why not leverage the schema and selection set and turn it\ninto TypeScript types?","basic-data-fetching-with-graphql#Basic Data Fetching with GraphQL":"Let's assume that we have the following simple GraphQL schema:\n\nAnd the client-side application consumes it with the following query:\n\nIf you client-side application only needs id, title and date from the Event type - you can\nexpect to have those fields in your GraphQL response.You can also use it in your component code:\n\nIn the example above we have a few issues that might be bugs in the future:\nWe don't know the type of listEvents - and we can't really know it without creating a type for\nit manually (but this could also break, because the API could change).\nWe can't be sure what are the actual types of id, title and date fields - it's any.\nWe can't count of the fields to be there because they GraphQL query can change, and it's not\nconnected to our code at all.\nIf you'll try to access location of the event - you'll just get undefined because it's not\npart of the selection set.\n\nWith GraphQL Code Generator, you can have a full type safety, based on your GraphQL schema and\nyour GraphQL operations, and that means:\nYou can tell what is the exact structure of listEvents, what could be null and enjoy\nauto-complete in your IDE.\nYou can tell what is the data type of all fields.\nIf your selection set changes, it being reflected automatically and you can detect issues while\ndeveloping or building (instead while running).\nTrying to access fields that are not defined in your selection set will show an error in build\ntime and in your IDE.\n\nSo those are the basic types that codegen can generate for your, and you can get those by using the\n@graphql-codegen/typescript and @graphql-codegen/typescript-operations plugins of GraphQL Code\nGenerator.But that's not all - you can generate much more - you can get React Hooks, Angular Services and\nmore.","how-do-i-start#How Do I Start?":"You can start by\ntrying GraphQL Code Generator plugin in the live-demo here and\nwith the\nGetting started with GraphQL Code Generator.","tips--best-practices-when-using-graphql-code-generator-and-typescript#Tips & Best Practices When Using GraphQL Code Generator and TypeScript":"Now that you understand why and how GraphQL Code Generator can help you, it's time to learn new\nconcepts that might simplify the way your consume GraphQL API, and improve your code quality.","watch-mode#Watch Mode":"GraphQL Code Generator also comes with a built-in watch mode. You can use it from the CLI:\n\nOr, set it in your codegen.yml file:\n\nThis way, each time you have changes for your GraphQL schema or GraphQL operations, GraphQL Code\nGenerator will be executed again and update the generated files.","generate-more-than-just-types#Generate More than Just Types":"GraphQL Code Generator can generate more than just TypeScript types. It can automate some of your\nGraphQL development workflow, generate common practices for data fetching, and add type-safety to\ncode you usually need to write manually.Beside TypeScript types, here's a list and examples of part of GraphQL Codegen capabilities:","dump-remote-schema-to-a-local-file#Dump Remote Schema to a Local File":"If your GraphQL schema is only available for you using an HTTP endpoint, you can always get a copy\nof it locally. This is useful for better IDE experience.You can do it with the @graphql-codegen/schema-ast plugin, and the following configuration:\n\n\n@graphql-codegen/schema-ast docs","save-local-graphql-introspection#Save Local GraphQL Introspection":"GraphQL schema can be represented in many ways. One of the is\nintrospection.You can save a local copy of your schema introspection using @graphql-codegen/introspection and\nthe following:\n\n\n@graphql-codegen/introspection docs","add-custom-content-to-output-files#Add Custom Content to Output Files":"I wish you to add custom content to the codegen output files, you can use @graphql-codegen/add\nplugin, and add your content this way:\n\n\n@graphql-codegen/add docs","react--apollo-generate-hooks#React & Apollo: Generate Hooks":"You can generate ready-to-use React hooks for your GraphQL operations, with the following\nconfiguration:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-react-apollo docs","react--apollo-generate-hoc-high-order-component#React & Apollo: Generate HOC (High-Order-Component)":"You can generate ready-to-use React HOC for your GraphQL operations, with the following\nconfiguration:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-react-apollo docs","react--apollo-generate-components#React & Apollo: Generate Components":"You can generate ready-to-use React data components for your GraphQL operations, with the following\nconfiguration:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-react-apollo docs","angular--apollo-generate-services#Angular & Apollo: Generate Services":"You can generate ready-to-use Angular Services for your GraphQL operations, with the following\nconfiguration:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-apollo-angular docs","react--urql-generate-hooks#React & urql: Generate Hooks":"If you are using urql as your GraphQL client, you can\ngenerate ready-to-use React hooks for your GraphQL operations, with the following configuration:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-urql docs\n\n\nThis plugin can also generate HOC or data Component, based on your preference ;)","vuejs--apollo-generate-composition-functions#Vue.js & Apollo: Generate Composition Functions":"If you are using Vue.js with @vue/apollo-composable your GraphQL client,\nyou can generate composition functions based on your GraphQL operations:\n\nAnd then use it in your code:\n\n\n@graphql-codegen/typescript-vue-apollo docs","apollo-type-safe-refetchqueries#Apollo: Type-Safe refetchQueries":"If you are using Apollo Client, and you wish to refetch a query when a mutation is done, you can do\nadd\n@graphql-codegen/named-operations-object\nplugin to your setup.It will generate a const object that contains a list of your GraphQL operation names, as found by\nthe codegen. This is useful because if you'll change the name of your operation, you'll know about\nit in build time, and you'll be able to update it:This is how to configure it:\n\nAnd then use it in your code:\n\n\nYou can use it with any other wrapper of Apollo-Client, such as apollo-angular or\nreact-apollo.\n\n@graphql-codegen/named-operations-object docs","apollo-auto-generated-fragmentmatcher--possibletypes#Apollo: Auto-Generated fragmentMatcher / possibleTypes":"If you are using Apollo-Client and your schema contains GraphQL union or interface, you'll need\nto provide fragmentMatcher to your Apollo store instance.This is needed in order to improve performance of Apollo store.\nYou can read more about this here.You can generate it using the following configuration:\n\nAnd then pass it directly to your Apollo instance:\n\n\n@graphql-codegen/fragment-matcher docs","name-your-operations#Name Your Operations":"It's highly important to name your GraphQL operations, because otherwise it will be difficult for\nyour GraphQL client to cache and manage it. It will also make it difficult for the codegen to create\neasy-to-use types, and it will fallback to Unnamed_Operation_.✅ Do:\n\n❌ Don't:\n\n\nTip: Duplicate NamesEnsure you have unique names for your operations.Libraries like Apollo Client will have issues and unexpected behavior if you re-use the same\noperation name, and GraphQL Code Generator will throw an error in case of name duplications.","write-your-operations-and-fragments-in-graphql-files#Write Your Operations and Fragments in .graphql Files":"You can manage your GraphQL operations in .graphql files, without worrying about loading it into\nyour application with Webpack loaders or anything else. Also, Most IDEs has better support for\nautocomplete inside .graphql files.GraphQL Code Generator plugins for frontend frameworks integrations (such as\ntypescript-react-apollo / typescript-apollo-angular) are automatically creates an executable\ncopy (DocumentNode) of your GraphQL operations in the generated code file, and it will\nautomatically include it withing your wrapper call.It will add that to the output file with Document suffix, and FragmentDoc for fragments.So you can maintain your operations in .graphql files, but import it from generated code file:\n\n\nTip: No need to handle importsIf you have a query that uses a fragment, you can just use the fragment spread as-is, without the\nneed to import it or maintain it in the same file.For example:\n\n\n\nAnd if you'll import UserQueryDocument from your generated file, it will have the fragment\nconcatenated automatically.","fragment-per-component#Fragment per Component":"If you wish to have a simple way to manage your application complexity with multiple queries and\nfragments, consider to have small fragments that defines the needs of your components.Consider the following structure for example (for a list and item implementation):\n\nThen, your GraphQL query files can just build it's self based on the nested fragments it needs:\n\n\n\nAnd then, GraphQL Code Generator will generate a matching TypeScript type per each component, based\non the fragment or query that it needs.So you can use the generated fragment type as the input for your components, and pass it directly\nfrom the parent component easily, with type-safety:\n\n\n\n\nPlease have some judgment before creating fragments, it should represent data structure that is\nspecific per component. Don't abuse this mechanism by creating fragments with a single field. Try\nto group it in a way that matches your components needs.","access-to-nested-generated-types#Access to Nested Generated Types":"If you are already familiar with plugins such as @graphql-codegen/typescript-operations output\nstructure, you probably already know that it's built on operations and fragments.It means that each GraphQL query and each GraphQL fragment that you have, will be converted into\na single TypeScript type.That means, that accessing nested fields in your generated TypeScript types might looks a bit\ncomplex at the beginning.Consider the following query:\n\nThe @graphql-codegen/typescript-operations plugin output for that query will be:\n\nAccessing the actual TypeScript type of user.profile.name.first might look a bit intimidating, but\nthere are several things you can do to simplify the access to it:\nBest solution: use fragments - if you'll use fragments for the User fields and for Profile\nfields, you'll break down the types into smaller pieces (see previous tip).\nUse TypeScript type system: type FirstName = UserByIdQuery['user']['profile']['name']['first'].\nYou can also do it with Pick:\ntype FirstName = Pick<UserByIdQuery, ['user', 'profile', 'name', 'first']>.\n\n\nTip: Hate Pick in your generated files?The @graphql-codegen/typescript-operations is the TypeScript representation of your GraphQL\nselection set. Just like selection set chooses fields from the GraphQL schema,\ntypescript-operations picks fields from typescript plugin (which is the representation of your\nGraphQL schema).If you wish to have simpler TypeScript output, you can set preResolveTypes: true in your\nconfiguration, and it will prefer to use the primitive TypeScript type when possible."}},"/blog/graphql-with-typescript-done-right":{"title":"GraphQL with TypeScript done right","data":{"":"Generics, and Mapped types,\nare key to build types on top of existing ones by making them configurable (Generics) or iterables\n(Mapped types).Advanced types give to your code and open-source libraries the power of providing an API that\nmanipulates data (your application objects) without breaking the “types chain”.\nThe best TypeScript configuration ensures that the “types chain” is continuous","the-typescript-types-chain#The TypeScript \"Types Chain\"":"TypeScript helps with typing data and following how the data is used and transformed by subsequent\nfunctions or method calls.The example below shows how easily this “types chain” can be broken:\n\nHow to break the TypeScript “types chain”\n(playground demo)Since React 16.8 brought ubiquitous functional components, a React application can be seen as a mix\nof functional components dealing with state and data in order to provide UI to the users.Like with plain JavaScript functions, the same rules of the “types chain” apply to your React\napplication that will look to something similar to the following:\n\nMost modern React applications have the following data setup: centralized data store passed down to\ncomponents through contexts, transformed by custom hooks down to UI components.Since React applications are built on top of data, we can conclude that:\nThe strength of your React application's types is based on the stability of your data types","the-flawed-handwritten-data-types#The Flawed \"Handwritten\" Data Types":"Most React projects type remote data (from APIs) manually, either at the component level with\ninterfaces or in a global dedicated .d.python file.\n\nExample of data-types definition and linked usage, common in many projectsManually writing and maintaining those type can lead to human errors:\noutdated typing (regarding the API current implementation)\ntypos\npartial typing of data (not all API's data has a corresponding type)\n\nAs we saw earlier, the strength of your React TypeScript types is based on your data types,\ntherefore, any mistake on your manually maintained data types will ripple in many of your React\ncomponents.\n\nIn our hypothetical application, the User type has some typos that will impact the stability of the\nassociated components at runtime, defecting the benefits of TypeScript.Fortunately, thanks to the GraphQL introspection feature, many tools arose to solve this problem by\nproviding data-types - and even more - generation tools.","robust-react-applications-types-with-graphql#Robust React Application's Types with GraphQL":"GraphQL Code Generator, given the mutations and queries used\nby the app and the access to the target GraphQL API, generates the corresponding TypeScript types.\n\nGraphQL Code Generator is doing all the heavy lifting by getting from the API the definitions of the\ndata types used by the React applications queries and mutations.Let's see an example with our hypothetical application Login component relying on the User type.","stronger-generated-typescript-types#Stronger Generated TypeScript Types":"First, let's create a queries.graphql file in a src/graphql folder:\n\nthen, the following GraphQL Code Generator configuration at the root of our project:\n\ncodegen.ymlAnd after running graphql-codegen CLI, we can refactor our <Login> component:\n\nsrc/components/Login.tsxThe configuration and refactoring were straightforward, directly impacting our data types, which are\nnow directly linked to the GraphQL API Schema, making our React application more stable!Contrary to the manually maintained data types, using the GraphQL Code Generator puts the data-types\nmaintenance on the GraphQL API side.Maintaining data types on the front-end side only consist of running the GraphQL Code Generator tool\nto update types according to the last GraphQL API version.Let's now see some more advanced configurations that bring more stability.","getting-the-most-of-your-graphql-code-generator-configuration#Getting the Most of Your GraphQL Code Generator Configuration":"When used with React Apollo Client, GraphQL Code Generator offers three main configuration modes:Generate TypeScript types definitionsThis is the configuration that we used in our previous example:\n\ncodegen.ymlThis configuration will generate a src/graphql/generated.python file that will contain:\nGraphQL document nodes\nTypeScript Query/Mutation Result types (return type of our GraphQL operations)\nTypeScript Query/Mutation Variables types (variables types of our GraphQL operations)\n\nHere an example of GraphQL Code Generator output given our previous currentUser Query:\n\nsrc/graphql/generated.tsWe already saw the benefits of these generated types on the <Login> component refactoring.However, we can agree that having to provide both the query TypeScript type\n(CurrentUserQueryResult) and the query GraphQL document node (currentUserDocument) to\nuseQuery() is cumbersome: useQuery<CurrentUserQueryResult>(currentUserDocument)Let's see how we can improve that in the next configuration mode.Generate Typed React HooksGraphQL Code Generator is capable of more than just generating TypeScript types, it can also\ngenerate JavaScript/TypeScript code.Let's see how we can ask GraphQL Code Generator to generate Typed React hooks, so we don't have to\nprovide the TypeScript types to useQuery() every time.Let's use the following configuration:\n\ncodegen.ymlThis configuration will generate a src/graphql/generated.python file that will contain:\nGraphQL document node\nTypeScript Query/Mutation Result types (return type of our GraphQL operations)\nTypeScript Query/Mutation Variables types (variables types of our GraphQL operations)\nOne custom hook for each defined GraphQL operation\n\nExample given our previous currentUser Query:\n\nsrc/graphql/generated.tsWhich will give us this updated version of our <Login> component:\n\nsrc/components/Login.tsxNice! Isn't it?Generate Typed DocumentsGraphQL Code Generator is providing another simple way to use typed GraphQL Query and Mutations,\ncalled TypedDocumentNode.With the following configuration:\n\ncodegen.ymlGraphQL Code Generator will generate the following file:\n\nsrc/graphql/generated.tsThis allows us the following refactoring of our <Login> component:\n\nsrc/components/Login.tsxIn my experience, it is more scalable to go for the\nTypedDocumentNode approach\ninstead of the hooks generation.The generation of one custom hook per GraphQL operation (Query/Mutation) can generate a LOT of\nhooks at scale along with a lot of imports, which is not necessary given the useMutation()\nuseQuery provided by Apollo Client.","tips-leverage-graphql-fragments-for-scalable-types#Tips: Leverage GraphQL Fragments for Scalable Types":"Now that we have many ways to generate **stable **data types, let's see how to make them easier to\nuse and maintain in time.Let's take a look at the following helper:\n\nHere, instead of using our currentUser query CurrentUserQuery[“me”] type, we would prefer to\nrely on a User type.We can achieve this with zero maintainability by leveraging GraphQL Fragments.When Fragments are provided, GQL Code Generator will produce the corresponding TypeScript types.Here is our updated src/graphql/queries.graphql:\n\nThe ...User indicates to GraphQL that we want to expand our User fragment here, similar to the\nobject spread syntax.In order to do so, we need to provide to GraphQL Code Generator the definition of the User\nfragment that we will place in a new src/graphql/fragments.graphql file:\n\nsrc/graphql/fragments.graphqlPlease note that a fragment needs to be defined against an existing type of the GraphQL API Schema,\nhere users.Here is our updated helper code:\n\nLeveraging GraphQL Fragments allows you to build your React app data types on top of the GraphQL API\ntypes.Please note that multiple fragments can be defined on a single GraphQL Schema type:\n\nsrc/graphql/fragments.graphqlA good practice is to ensure that all your Query and Mutations responses use fragment, this will\nensure that your React application can benefit from well-defined data types of different\nspecificity, ex:\nUser type carries the necessary base properties\nUserProfile type carries the minimum user info for display\nUserExtended type carries all the users properties","conclusion#Conclusion":"The TypeScript type system is powerful and valuable only if used properly.In React applications, most of the components rely on data, doing your data typing at the center of\nyour application stability.Thanks to GraphQL Code Generator and with a fast setup, you will be able to ensure the stability of\nyour React application data types, along with your application's global stability.If you decide to use GraphQL Code Generator, make sure to:\nmove all your gql definitions in dedicated .graphql files\nFavor the\nTypedDocumentNode\nconfiguration mode\nMake sure that all your Queries and Mutations relies on well-defined GraphQL Fragments"}},"/blog/graphql-codegen-and-apollo-client-3":{"title":"What's new with Apollo Client v3 and GraphQL Codegen","data":{"":"In recent weeks and months, we've been migrating many of our clients codebases, many at very large\nscale (over thousand developers on a single codebase), from Apollo Client 2 to Apollo Client 3.While doing all that work, we've improved many of the toolings we are maintaining and created a\nbunch of new ones.A lot of those improvements were fed back into GraphQL Codegen, and we are happy to share all those\nnew learnings and features with everyone in the community.\nWe've also found and fixed a lot of memory leaks in upstream Apollo Client, thanks\n@benjamn for the great corporation!\nWe hope you would use those new features and improvements to quickly improve your workflow,\ntype-safety and make your migrations easier.And as usual, we would love to hear your feedback and ideas on how we can further improve the\nexperience of using GraphQL and Typescript in general!If you are already familiar with GraphQL-Codegen and the plugins it offers, you probably know the\nfragment-matcher plugin.In Apollo-Client v3,\nthe structure for fragment matcher has been changed, and now it's called possibleTypes.The @graphql-codegen/fragment-matcher@2.0.0 now supports Apollo-Client v3 by default, and it\ngenerates type signature and the possibleTypes object automatically based on your GraphQL schema.Here's an example of using it with a codegen.yml file:\n\nThen, when you create your Apollo Client cache instance, use the generated variable:\n\nWithout this, you'll have to define and maintain the possibleTypes object manually, which might\nlead to an incorrect or invalid setup that might effect Apollo-Client runtime.","type-policies#Type Policies":"If you are using an\nadvanced configuration for your Apollo-Client cache,\nyou can customize the behaviour of your cache.The configuration you pass to Apollo depends on your GraphQL types and their fields, and instead of\nhaving an arbitrary object, you can have a fully-typed signature generated based on your GraphQL\nschema. That would make it much easier to customize, and you will catch errors in advance! (during\nbuild-time, instead during runtime)You can use @graphql-codegen/typescript-apollo-client-helpers plugin to generate that.\n\nThen, use the generated TypedTypePolicies to type your object:","typeddocumentnode#TypedDocumentNode":"Apollo-Client also supports TypedDocumentNode now natively (since v3.2,\nyou can read more about it here).You can use it to generate a fully-typed DocumentNode you can use with Apollo-Client, and it will\nautomatically type your variables and responses.You can use @graphql-codegen/typed-document-node with the following setup to get that:\n\nLater, in your code, you can just import the generated TypedDocumentNode objects from\ntyped-document-nodes (based on your GraphQL operations), and it will be automatically typed:","ready-to-use-hooks--hoc--components#Ready-To-Use Hooks / HOC / Components":"One of the most powerful features of GraphQL-Codegen is the ability to generate flexible code based\non your GraphQL schema and your GraphQL operations.We generate TypeScript types, but that's not all - we can also generate code for you.You can generate a fully-typed React Hooks:\n\nThen, just use it directly in your components:\n\n\nNote: This is an alternative for TypedDocumentNode.","more#More!":"You can also generate Svelte-Apollo,\napollo-angular types,\nVue-Apollo,\nStencil-Apollo and\nother view layers working with Apollo Client 3...You can find a list of all available plugins here,\nand\nhere you can find a list of tips for integrating codegen with your frontend applications."}},"/blog/introducing-graphql-eslint":{"title":"Introducing GraphQL-ESLint!","data":{"":"We are super excited to introduce a new development tool by The Guild!While working on very large codebases (hundreds of developers on a single codebase), we've noticed a\ngap in the current state-of-the-art development flow for GraphQL developers: it's very hard to\nmaintain standards in GraphQL schemas and GraphQL operations.Those could be standards that are specific for a single codebase or shared in the community. As the\nGraphQL ecosystem is growing quickly, we decided it's important to create a modern integration\nbetween GraphQL and ESLint, that supports all the modern needs of a GraphQL developer:\ngraphql-eslint.\nSpecial thanks to ilyavolodin for his work on a similar project.\nWe've joined forces to bring a new exiting tool for you!","tldr#TL;DR":"graphql-eslint in GitHub\nList of available rules (and\nplanned rules)\n\n\n🚀 Validates, lints, prettifies and checks for best practices across GraphQL schema and GraphQL\noperations.\n🚀 Integrates with ESLint core (as a ESTree parser).\n🚀 Works on .graphql files, gql usages in code files, and /* GraphQL */ magic comments.\n🚀 Lints both GraphQL schema and GraphQL operations.\n🚀 Extended type-info for more advanced use-cases and sophisticated validations\n🚀 Supports ESLint directives (for example: # disable-next-line)\n🚀 Easily extendable - supports custom rules based on GraphQL's AST and ESLint API.\n🚀 Integrates with graphql-config\n🚀 Integrates and visualizes lint issues in popular IDEs (VSCode / WebStorm)","what-it-does#What It Does?":"With graphql-eslint you can easily validate and lint your GraphQL schema and your GraphQL\noperations, enforce coding-style, best practices, and avoid runtime issues.\n\nIt can run as a syntax validation tool (without a GraphQL schema), or as a complete validation\nsolution for your GraphQL operations (with a schema loaded into it).graphql-eslint works on your .graphql files, but also on your code-files that uses gql\n(graphql template literal tag) or /* GraphQL */ magic comments.It is fully integrated with VSCode for visualizing the reported issues, and allows you to customize\nthe rules, and easily add new custom ones.","how-does-it-work#How Does It Work?":"This package acts as a ESLint parser, and a plugin with rules.The parser we wrote transforms the GraphQL AST into\nESTree structure, so it allows you to travel the GraphQL AST\ntree easily.If you wish to read more about\nhow it works, please refer to the docs' directory in the repo.","writing-your-own-rules#Writing Your Own Rules":"Since it's running as a real ESLint parser,\nyou can easily customize it and write your own rules,\nbased on your project's needs and preferences.If you are familiar with the GraphQL AST structure, you can write custom rules very quickly, since\nour solution comes with a wrapper that makes it easier to write and test new rules, and have full\nTypeScript support.Need a new custom rule? Just create a file in your project, and travel the AST to make sure it\nmatches your needs.Think that rule might be valuable for others?\nCreate a PR!","compared-to-similar-tools#Compared to Similar Tools":"There are other solutions that offer GraphQL linting. We decided to write a modern library that fits\nour clients' needs, integrates with IDEs and is easily customizable by anyone.\napollographql/eslint-plugin-graphql - offers a similar solution, but is designed in a different\narchitecture and unfortunately, it's not customizable and extendable, and doesn't work on some\nmodern solution.\ncjoudrey/graphql-schema-linter - works as a standalone tool (without ESLint) and offers rules\nfor linting GraphQL schemas only.","summary#Summary":"We hope GraphQL-ESLint becomes a central place for the community to collaborate on best practices\nand bring them into your team in an automated and easy way.We already use it in companies like Microsoft on a very large codebases, and it helped us share our\npractices across thousands of developers!"}},"/blog/graphql-modules":{"title":"GraphQL Modules  —  Feature based GraphQL Modules at scale","data":{"":"Today we are happy to announce that we are open sourcing a framework we've been using for the past\ncouple of months in production — GraphQL Modules!Yet another framework? well, kind of GraphQL Modules is a set of extra libraries, structures and\nguidelines around the amazing Apollo Server 2.0.You can and should use them as completely separate packages, each one is good for different use\ncases, but all together they represent our current philosophy of building large scale GraphQL\nservers.We would love to get feedback from the Apollo team and if they wish to use those ideas and integrate\nthem into Apollo Server we would love to contribute. That's why we've developed it as a set of\nindependent tools under a single monorepo.The basic concept behind GraphQL Modules is to separate your GraphQL server into smaller,\nreusable, feature based parts.A basic and initial implementation of a GraphQL server usually includes:\n\nA more advanced implementation will usually use a context to inject things like data models, data\nsources, fetchers, etc., like Apollo Server 2.0 provides us with:\n\nUsually, for simple use cases, the example above will do.But as applications grow, their code and schematic relationships becomes bigger and more complex,\nwhich can make schema maintenance a hard and agonizing thing to work with.Some of the more old school, MVC frameworks adds few more layers after the resolvers layer, but most\nof them just implement separation based technical layers: controllers, models, etc.We argue that there is a better approach of writing your GraphQL Schema and implementation.We believe you should separate your GraphQL schema by modules, or features, and includes\nanything related to a specific part of the app under a “module” — which is just a simple directory.\nEach one of the GraphQL Modules libraries would help you in the gradual process of doing that.The modules are being defined by their GraphQL schema — so we've taken the “GraphQL First” approach\nlead by Apollo and combined it together with classic modularization tooling to create new ways of\nwriting GraphQL servers!\n\nThe GraphQL Modules toolset has tools to help with:\nSchema Separation — declare your GraphQL schema in smaller pieces, which you can later move\nand reuse.\nTools designed to create independent modules — each module is completely independent and\ntestable, and can be shared with other applications or even open sourced if needed\nResolvers Composition — with GraphQL Modules you can write your resolver as you wish, and let\nthe app that hosts the module to wrap the resolvers and extend them. It's implemented with a basic\nmiddleware API, but with more flexibility. That means that you can, for example, implement your\nentire module without knowing about the app authentication process, and assume that currentUser\nwill be injected for you by the app.\nA clear, gradual path from a very simple and fast, single-file modules, to scalable\nmulti-file, multi-teams, multi-repo, multi-server modules.\nA scalable structure for your GraphQL servers — managing multiple teams and features, multiple\nmicroservices and servers and more advanced tools, which you can choose to include when your\nschema gets into massive scale:\nCommunication Bridge — We also let you send custom messages with payload between modules —\nthat means you can even run modules in different microservices and easily interact between them.\nDependency Injection — Implement your resolvers, and later, only when you see fit, improve\ntheir implementation by gradually introducing dependency injection. It also includes richer\ntoolset around testing and mocking.","a-basic-example#A Basic Example":"In the following example, you can see a basic implementation for GraphQL Modules server, with 2\nmodules: User and Chat. Each module declares only the part that is relevant to it, and extends\npreviously declared GraphQL types.So when User module is loaded, the type User is created, and when Chat module is loaded, the\ntype User being extended with more fields.\n\n\n\n\n\n\n\nYou can and should adopt GraphQL Modules part by part, and you can try it now with your existing\nGraphQL server.What does a “module” contain?\nSchema (types declaration) — each module can define its own Schema, and can extend other\nschema types (without explicitly providing them).\nThin resolvers implementation — each module can implement its own resolvers, resulting in thin\nresolvers instead of giant files.\nProviders — each module can have its own Providers, which are just classes/values/functions\nthat you can use from your resolvers. Modules can load and use providers from other modules.\nConfiguration — each module can declare a strongly-typed config object, which the consuming\napp can provide it with.\nDependencies — modules can be dependent on other modules (by its name or its GraphQLModule\ninstance, so you can easily create an ambiguous dependency that later could be changed).","graphql-modules-libraries#GraphQL Modules Libraries":"GraphQL Modules is built as a toolkit, with the following tools, which you should individually and\ngradually adopt:@​graphql-modules/epoxy\nThat will probably be the first tool you want to introduce into your server. The first step into\norganizing your server in a feature based structure\nEpoxy is a small util that manages the schema merging. it allow you to merge everything in your\nschema, starting from types to enums, unions, directives and so on.\nThis is an important feature of GraphQL Modules — you can use it to separate your GraphQL types to\nsmaller pieces and later on combine them into a single type.\nWe took the inspiration from\nmerge-graphql-schemas, and added some features\non top of it to allow custom merging rules to make it easier to separate your schema.\n\n@​graphql-modules/core\nResolvers Composition —\nmanages the app's resolvers wrapping\nContext building — each module can inject\ncustom properties to the schema, and other modules can use it (for example, auth module can inject\nthe current user, and other modules can use it)\nDependency injection and module dependencies management\n— when you start, there is no need of using DI is your server. but when your server gets big\nenough with a large number of modules which depends on each other, only then, DI becomes a very\nhelp thing that actually simplifies your code a lot. USE ONLY WHEN NECESSARY ;)\n\nYou can find more tooling at your disposal like:@​graphql-modules/sonar — a small util that helps you find GraphQL schema and resolvers files,\nand include them.@​graphql-modules/logger — a small logger, based on\nwinston 3, which you can easily use in your app.","get-started#Get Started":"First thing, don't go full in! Start by simply moving your code into feature based folders and\nstructures with your existing tools.Then head over to https://graphql-modules.com/ and check out our\ntools and use them only when you see that they solve a real problem for you! (for us it has)Also check out the repo's README and\na number of example apps.You probably have many questions — How does this compare to other tools, how to use those libraries\nwith X and so on.We will publish a series of blog posts in the coming weeks that will dive deep into each of the\ndesign decisions made here, so we want to hear your thoughts and questions, please comment here or\non the Github repository!Going to GraphQL Summit? I will be there\nand would love to get your questions and feedback on behalf of our team.All those tools were built by a passionate group of individual open source developers, otherwise\nknown as The Guild.Below there is a section of more deep dive thoughts that we will publish separate posts about in the\ncoming weeks:","core-concepts-and-deep-dive#Core Concepts and Deep Dive":"","modularizing-a-schema#Modularizing a Schema":"Everyone is talking about schema stitching and GraphQL Bindings. Where does that fit into the\npicture?Schema stitching is an amazing ability and concept, which helps you merge separated GraphQL servers\ninto a single endpoint and opens up a lot of exciting use cases.But, with all the excitement, we've missed something much more basic than that — sometimes we still\nwant to work on a single logical server, but we just want to separate the code according to\nfeatures.We want to be able to do most of the merging work at build time, and only if really necessary, do\nthe rest of the merging at runtime as a last resort.We want to split the code into separate teams and even create reusable modules which define their\nexternal APIs by a GraphQL Schema.Those modules can be npm modules, microservices or just separate folders inside a single server.Separating your schema to smaller parts is easier when you are dealing with typeDefs and\nresolvers— it's more readable and easy to understand.We also wanted to allow developers to extend only specific types, without creating the entire\nschema. With GraphQL schema, you have to specify at least one field under Query type, which is\nsomething that we did not want to enforce on our users.We see our approach as complementary to Schema Stitching and works together with it.","feature-based-implementation#Feature-Based Implementation":"One of the most important things in GraphQL Module's approach is the feature-based implementation.Nowadays, most frameworks are separating the layers based on the role of the layer — such as\ncontrollers, data-access and so on.GraphQL Modules has a different approach — separate to modules based on your server's features, and\nallow it to manage its own layers within each module implementation.It's easier to think about apps in a modular way, for example:Your awesome app needs a basic authentication, users management, user profiles, user galleries and a\nchat.Each one of these could be a module, and implement its own GraphQL schema and its own logic, and it\ncould depend on other modules to provide some of the logic.Here's a simple example for a GraphQL Schema as we described:\n\nBut if we think of apps in terms of features and then separate the schema by module, the modules\nseparation will look like so:\n\nThis way, each module can declare only the part of the schema that it contributes, and the complete\nschema is a representation of all merged type definitions. Module can also depend, import and extend\nand customize the contents on other modules (for example, User module, comes with Auth inside\nit)The result of course, will be the same, because we are merging the schema into a single one, but the\ncodebase will be much more organized and each module will have its own logic.","reusability-of-backend-modules#Reusability of Backend Modules":"So now that we understood the power of feature-based implementation, it's easier to grasp the idea\nbehind code reusability.If we could implement the schema and the core of Auth and User module as “plug-and-play” — we will\nbe able later to import it in other projects, with very minor changes (using configuration,\ndependency injection, or module composition).How could we reuse complete modules that hold part of a schema?For example, let's take a User type.Most of User type schemas will contain id, email and username fields. The Mutation type will\nhave login and the Query will have user field to query for a specific user.We can re-use this type declaration.The actual implementation might differ between apps, according to the authentication provider,\ndatabase and so on, but we can still implement the business logic in a simple resolver, and use\ndependency injector and ask the app that's using the module to provide the actual authentication\nfunction (of course, with a complete TypeScript interface so we'll know that we need to provide it\n;) ).Let's take it one step further. If we would like to add a profile picture to a user, we can add a\nnew module named UserProfile and re-declare the User and Mutation types again:\n\nThis way, GraphQL Modules will merge the fields from this User type into the complete User type,\nand this module will only extend the User type and Mutation type with the required actions.So let's say that we have the schema — how can we make this module generic and re-use it?This is how you declare this module:\n\n\nWe declare a config object, and the app will provide it for us, so we can later replace it with a\ndifferent logic for uploading.","scaling-the-codebase#Scaling the Codebase":"Now that we broke our app into individual modules, once our codebase grows, we can scale each module\nindividually.What do I mean by scaling a codebase?Let's say we start to have code parts we want to share between different modules.The current way of doing it in the existing GraphQL world is through a GraphQL context.This approach has proven itself to work, but at some point it becomes a big hassle to maintain,\nbecause GraphQL context is an object, which any part of the app can modify, edit and extend, and it\ncan become really big pretty quickly.GraphQL modules let each module extend and inject fields to the `context` object, but this is\nsomething that you should use with caution, because I recommend the `context` to contain the\nactual `context` — which contains data such as global configuration, environment, the current user\nand so on.GraphQL modules only adds one field under the context, called injector which is the bridge that\nlets you access your GraphQLApp and the application Injector, and it lets you fetch your module's\nconfig and providers.Modules can be a simple directory in a project or in a monorepo, or it could be a published NPM\nmodule — you have the power to choose how to manage your codebase according to your needs and\npreferences.","dependency-injection#Dependency Injection":"GraphQL Modules' dependency injection is inspired by .NET and Java's dependency injection which has\nproven itself to work pretty well over the years. With that being said, there were some issues with\n.NET and Java's APIs, which we've tried to list and go through. We ran into some pretty interesting\nconclusions.We've learn that it's not something that should be forced. Dependency injection makes sense in some\nspecific use cases and you should need to use it only when it's necessary and when it helps you move\nfaster. So this concept should come more and more in handy as we scale up, we can simplify things,\nmaintain our code with ease and manage our teams' contributions!Having GraphQL Modules deployed across all of our Enterprise customers while also being used on our\nsmaller applications, lead us to believe that we've found the optimal point of where you should use\nthe concept of dependency injection, and when not.We've also came with the optimal API for dependency injection. It's extremely easy to understand,\nand use.After a long research of the existing dependency injection solutions for JavaScript, we've decided\nto implement a simple Injector, that supports the needs of GraphQL-Modules ecosystem, and support\ncircular dependencies and more.We've simplified the Dependency Injection API and exposed to you only the important parts, that we\nbelieve that are necessary for a GraphQL server development.","authentication#Authentication":"Check out the related blog post we wrote about it:\n/blog/graphql-modules-auth","testing-and-mocking#Testing and Mocking":"On our Enterprise applications, when we started using dependency injection, we no longer had to\nmanage instances and bridge them together.We gained an abstraction that allowed us to test things easier and mock all http requests.Yes, mocking. DI really shines here.Thanks to mocking we can simulate many scenarios and check the backend against them.And when your codebase grows, you need to start thinking about managing dependencies between modules\nand how to avoid things like circular dependencies — unless you use DI which solves that problem for\nyou.With the power of dependency injection, you can easily create a loose connection between modules,\nand base this connection on a token and on a TypeScript interface.It also means that testing is much easier — you can take your class/function and test it as an\nindependent unit, and mock its dependencies easily.","summary#Summary":"We see GraphQL Modules as the framework that finally being built from the ground up on the new and\nexciting capabilities of GraphQL and Apollo, while combining it in the right way with good old\nsoftware best practices for scale like modularizations, strong typings and dependency injection.Now go and try it out","all-posts-about-graphql-modules#All Posts about GraphQL Modules":"GraphQL Modules — Feature based GraphQL Modules at scale\nWhy is True Modular Encapsulation So Important in Large-Scale GraphQL Projects?\nWhy did we implement our own Dependency Injection library for GraphQL-Modules?\nScoped Providers in GraphQL-Modules Dependency Injection\nWriting a GraphQL TypeScript project w/ GraphQL-Modules and GraphQL-Code-Generator\nAuthentication and Authorization in GraphQL (and how GraphQL-Modules can help)\nAuthentication with AccountsJS & GraphQL Modules\nManage Circular Imports Hell with GraphQL-Modules"}},"/blog/graphql-error-handling-with-fp":{"title":"GraphQL error handling to the max","data":{"":"","this-is-what-snlpais-tutorials-will-look-like#This is what snlp.ai's tutorials will look like":"Lorem ipsum dolor sit amet.Let's discover Docusaurus in less than 5 minutes.","getting-started#Getting Started":"Get started by creating a new site.Or try Docusaurus immediately with docusaurus.new.","what-youll-need#What you'll need":"Node.js version 16.14 or above:\nWhen installing Node.js, you are recommended to check all checkboxes related to dependencies.","generate-a-new-site#Generate a new site":"Generate a new Docusaurus site using the classic template.The classic template will automatically be added to your project after you run the command:\n\nYou can type this command into Command Prompt, Powershell, Terminal, or any other integrated terminal of your code editor.The command also installs all necessary dependencies you need to run Docusaurus.","start-your-site#Start your site":"Run the development server:\n\nThe cd command changes the directory you're working with. In order to work with your newly created Docusaurus site, you'll need to navigate the terminal there.The npm run start command builds your website locally and serves it through a development server, ready for you to view at http://localhost:3000/.Open docs/intro.md (this page) and edit some lines: the site reloads automatically and displays your changes.Code Hike will apply syntax highlighting to any code block\n\nIt works by default with many languages\n\nUse focus to show the code that's important to the reader\n\nYou can specify a list of line numbers\n\nAnd also columns\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.","lorem#Lorem":"Lorem ipsum dolor sit amet, consectetur adipiscing something about points, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.","ipsum#Ipsum":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in.","dolor-sit#Dolor sit":"Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu.","amet#Amet":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Venenatis cras sed felis eget velit. Consectetur libero id faucibus nisl tincidunt.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.","step-1#Step 1":"Lorem ipsum dolor sit amet, consectetur adipiscing something about points, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nNova in illis at dabat legi harundine non, ova miratur? Quid in sole aer\nad diffusa illis voluisti fidensque coniugiale laniata curam. Aras rivus\neripuit, qua fistula haec partus; serpens, negat.\nPraesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus.","step-2#Step 2":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in.Praesent elementum facilisis leo vel fringilla est ullamcorper eget.Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Nibh cras pulvinar mattis nunc sed. Luctus accumsan tortor posuere ac ut consequat semper viverra. Fringilla ut morbi tincidunt augue interdum velit euismod.Morbi quis commodo.","step-3#Step 3":"Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu.\nNisi lacus sed viverra tellus in\nNibh cras pulvinar mattis nunc sed\nLuctus accumsan tortor posuere ac\n\nUt consequat semper viverra. Fringilla ut morbi tincidunt augue interdum velit euismod.","step-4#Step 4":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Venenatis cras sed felis eget velit. Consectetur libero id faucibus nisl tincidunt.test.Sed blandit libero volutpat sed cras.\nNisi lacus sed viverra tellus in\nNibh cras pulvinar mattis nunc sed\n\nGravida in fermentum et sollicitudin ac orci phasellus egestas tellus. Volutpat consequat mauris nunc congue nisi vitae.","step-5#Step 5":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in.Praesent elementum facilisis leo vel fringilla est ullamcorper eget.Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat.Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Nibh cras pulvinar mattis nunc sed. Luctus accumsan tortor posuere ac ut consequat semper viverra.\nFringilla ut morbi tincidunt augue interdum velit euismod.\nLuctus accumsan tortor posuere ac ut consequat semper viverra.\n\nMorbi quis commodo.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Lorem ipsum dolor sit amet.\nConsectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget.\n\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident.","with-multiple-files#With multiple files":"Lorem dolor sit amet, javascript adipiscing elit, sed do eiusmod styles incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\n\n\n\n\n\nThis is how to use the <CH.Spotlight> component. Lorem ipsum dolor sit amet consectetur adipisicing elit. Quisquam, quia! Quidem, quisquam.\n\n\n\n\n\nChange focus\n\n\n\nOr change the code\n\n\n\nOr change the file","by-the-way#By the way":"you can\nput any\nmarkdown\nhere\n\n👍\n\n\n\nAdding a filename to the codeblock","tabs#Tabs":"To add more tabs, wrap multiple codeblocks with <CH.Code/>:","panels#Panels":"The editor can be splitted vertically in two panels using ---\n\n\n\n\n\nYou can use comments inside the code to make the focus relative.\n\nSame with other annotations like mark.\n\nYou can pass a string parameter to comment annotations","links-and-labels#Links and labels":"And now we introduce two more annotations: link and label\n\nThis is how to use the <CH.Spotlight> component. Lorem ipsum dolor sit amet consectetur adipisicing elit. Quisquam, quia! Quidem, quisquam.\n\n\n\n\n\nChange focus\n\n\n\nOr change the code\n\n\n\nOr change the file","by-the-way-1#By the way":"you can\nput any\nmarkdown\nhere\n\n👍\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.","step-1-1#Step 1":"Lorem ipsum dolor sit amet, consectetur adipiscing something about points, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nNova in illis at dabat legi harundine non, ova miratur? Quid in sole aer\nad diffusa illis voluisti fidensque coniugiale laniata curam. Aras rivus\neripuit, qua fistula haec partus; serpens, negat.\nPraesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus.","step-2-1#Step 2":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in.Praesent elementum facilisis leo vel fringilla est ullamcorper eget.Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Nibh cras pulvinar mattis nunc sed. Luctus accumsan tortor posuere ac ut consequat semper viverra. Fringilla ut morbi tincidunt augue interdum velit euismod.Morbi quis commodo.","step-3-1#Step 3":"Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu.\nNisi lacus sed viverra tellus in\nNibh cras pulvinar mattis nunc sed\nLuctus accumsan tortor posuere ac\n\nUt consequat semper viverra. Fringilla ut morbi tincidunt augue interdum velit euismod.","step-4-1#Step 4":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Venenatis cras sed felis eget velit. Consectetur libero id faucibus nisl tincidunt.Sed blandit libero volutpat sed cras.\nNisi lacus sed viverra tellus in\nNibh cras pulvinar mattis nunc sed\n\nGravida in fermentum et sollicitudin ac orci phasellus egestas tellus. Volutpat consequat mauris nunc congue nisi vitae.","step-5-1#Step 5":"Velit euismod in pellentesque massa placerat. Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in.Praesent elementum facilisis leo vel fringilla est ullamcorper eget.Id aliquet risus feugiat in ante metus dictum at tempor. Sed blandit libero volutpat sed cras. Sed odio morbi quis commodo odio aenean sed adipiscing. Velit euismod in pellentesque massa placerat.Mi bibendum neque egestas congue quisque egestas diam in arcu. Nisi lacus sed viverra tellus in. Nibh cras pulvinar mattis nunc sed. Luctus accumsan tortor posuere ac ut consequat semper viverra.\nFringilla ut morbi tincidunt augue interdum velit euismod.\nLuctus accumsan tortor posuere ac ut consequat semper viverra.\n\nMorbi quis commodo.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Praesent elementum facilisis leo vel fringilla est ullamcorper eget. At imperdiet dui accumsan sit amet nulla facilities morbi tempus. Praesent elementum facilisis leo vel fringilla. Congue mauris rhoncus aenean vel. Egestas sed tempus urna et pharetra pharetra massa massa ultricies.Contrary to REST, GraphQL does not use Status Code to differentiate a successful result from an\nexception. In REST, one can send a response with a appropriate status code to inform the caller\nabout the kind of exception encountered, e.g.:\n400: bad request (e.g. invalid inputs)\n401 or 403: unauthorized (need authentication) or forbidden (insufficient permission)\n404: resource not found\n500: internal server error\nand more.\n\nIn GraphQL, we manage errors in a different way. We'll see in this article how to:\nachieve a better error representation than the default offered by GraphQL\nget type safety using Typescript and GraphQL Code Generator\nhandle the errors from lower-level code up to the resolvers\nand finally get additional safety using a functional approach\n\nAll the code examples can be found in this\nrepository.","graphql-default-error-handling#GraphQL Default Error Handling":"In GraphQL, all requests must go to a single endpoint:\nPOST https://example.com/graphql\nA GraphQL API will always return a 200 OK Status Code, even in case of error. You'll get a 5xx\nerror in case the server is not available at all.The standard error handling mechanism from GraphQL with return a JSON containing:\na data key which contains the data corresponding to the GraphQL operation (query, mutation,\nsubscription) invoked and\nan errors key which contains an array of errors returned by the server, with a message and\nlocation.\n\n\n\nThis standard error handling is not satisfactory for the many reasons:\nit is not easily parseable, it is more meant for a human user to read\nit is not typed: you can add more information, e.g. an error code and other fields, but those are\nnot part of the schema\nit is not self-documented: by looking at the operation signature, you don't know what might fail\nit treats some domain results as errors / exceptions whereas they are just alternate results of\nthe operation. E.g. an entity not found for a given id and a user not having permission to access\nan entity belong to the domain model, whereas runtime exceptions such as the GraphQL server\nfailing to communicate with the database / external microservice, or an operation timing out\nbecause of slowness are real exceptions: we don't get any result that relates to domain model,\njust an unexpected runtime error.","better-modelisation-of-errors-using-union-and-interfaces#Better Modelisation of Errors Using Union and Interfaces":"GraphQL has support for Union types. We can take advantage of it and design our schema to specify\nall possible results: expected and unexpected / error cases.We can then do queries like the following:\n\nAnd get the expected result or properly typed alternative results in case of errors:\n\nLeveraging GraphQL Union types for error cases brings many benefits:\nType-safety: the errors are also typed\nThe consumer cannot ignore the errors (the must be handled using inline fragments)\nSelf-documented: the operation signature includes all possible cases (result and errors)\ntherefore less documentation is required to explain the possible error cases\nThe unexpected results are now just other possible results","implementing-union-types-based-error-handling#Implementing Union Types Based Error Handling":"Given the following Schema:\n\nIf something fails during the execution, we can:\nthrow an Error and use the default GraphQL error mechanism explained above\nreturn null: this is not satisfactory because we can't know the reason the operation returned\nnull\n\nLet's instead implement error handling using Union types with the following modifications:\n\nWe define a BaseError interface that all concrete Errors implement. Then, we define the query\nresult as a Union type of the expected result (an Entity) and the other possible results\n(NotFoundError, NotAllowedError, etc.). In this manner, we extensively describe all possible\nresults, with the added benefit that we can make our result type non-nullable (with the !\ncharacter).For a more detailed explanation, you can read these articles:\nBy Sasha Solomon:\n200 OK! Error Handling in GraphQL\nBy Laurin Quast:\nHandling GraphQL errors like a champ with unions and interfaces\nBy Marc-André Giroux:\nA Guide to GraphQL Errors\nWatch this video by @notrab:","handle-those-schema-changes-into-the-graphql-server#Handle Those Schema Changes into the GraphQL Server":"Since we changed the Schema, we also need to change the query, mutation and types resolvers.For simple cases, we can just return the correct object from the query resolver:\n\nSince we include the __typename and the fields match the Schema type definitions, there is no need\nto define type resolvers.For more details on this solution, you can read this article from\nLaurin Quast:\nHandling GraphQL errors like a champ with unions and interfaces.","typesafe-error-handling-on-the-client-side#Typesafe Error Handling on the Client-Side":"Let's now take it to the next level using Typescript and GraphQL Code Generator.GraphQL Code Generator is a tool developed by The Guild\nwhich generates type definitions which corresponds to the GraphQL schema. It has several plugins,\nand we'll use 3 of those:\ntypescript: generates the type\ndefinitions for Typescript\ntypescript-resolvers: generates\ntype definitions for all operations resolvers\nadd: append/prepend text to the generated type\ndefinitions file, it allows us to import some of our types into the generated file","specific-error-classes-for-all-graphql-schema-error-types#Specific Error Classes for All GraphQL Schema Error Types":"First we defined corresponding Error classes for the different error cases:","codegen-mapping#codegen Mapping":"GraphQL Code Generator is configured with a codegen.yml YAML file. In the mappers section, we\nmap every type of our GraphQL Union type to its corresponding Typescript type.\n\nThis codegen configuration generates the Typescript types from the Schema and the proper\nsignatures for the operations (query/mutation/subscription) and types resolvers. Now we have static\ntype safety and type inference and hints in the code editor.","help-the-graphql-engine-decide-which-type-to-return#Help the GraphQL Engine Decide Which Type to Return":"In the first version of the query resolver, we were returning objects that matched the GraphQL types\nand were tagged with the __typename so the GraphQL engine could just return those without the need\nto have type resolvers. But now, we are returning different objects that will be mapped to the\nproper GraphQL type. And those objects are not tagged with __typename. So how does the GraphQL\nengine know to map the value returned by the query resolver?In the codegen configuration, we have defined mappers between the GraphQL schema types and the\nTypescript types. But this is not used at runtime. This configuration is only used by GraphQL Code\nGenerator to generate the proper types and resolvers signatures so that you get compile-time type\nsafety and code editor hints.The type resolvers have a special field resolver for this purpose: __isTypeOf is a field resolver\nfunction on each of the GraphQL type resolver of the query union type result. This field resolver is\nexecuted on all types that form the query resolver's result Union type: when one returns true, the\nGraphQL engine will use this type resolver to generate the proper result object.","rewrite-the-resolvers-to-use-the-errors-types-and-__istypeof#Rewrite the Resolvers to Use the Errors Types and __isTypeOf":"Now that we have defined the proper mapping between the GraphQL schema types and the Typescript\ntypes, let's rewrite the resolvers:","query-fields-selection#Query Fields Selection":"Our query can now return several types, therefore we need to adapt the query fields selection and\nuse fragments:\n\nA good practice is to always have a fragment that matches the BaseError interface: it makes the\nclient code future-proof in case one more error is added to the Union result type.","even-safer-error-handling-using-functional-programming-paradigm#Even Safer Error Handling Using Functional Programming Paradigm":"The previous section was dedicated to showing how to get type safety and inference in resolvers and\nhow to generate the proper GraphQL type from a query resolver Union type value.The query resolver code above to get an Entity and check if User is allowed is oversimplified. In\nreal-life, we would probably get this data from one or two data sources (database, distributed\ncache) or even another external microservice with a REST or gRPC interface. Those data fetching\ncalls might throw errors, or return null.We want to handle those errors, transform meaningless and unsafe null values into meaningful\nerrors, while also being able to bubble up those errors to the query resolvers in a safe manner.","monads-to-the-rescue#Monads to the Rescue":"In order to make our throwing and unsafe APIs into safe data fetching functions, we'll use data\ntypes and techniques from the Functional Programming paradigm. In particular, we'll use the\nfp-python library (but you can choose the FP library of your choice,\ne.g. purify,\neffect, monio, and\nothers).fp-python exposes several useful data types and functions which allows to work on safe abstractions\nusing composable functions. In particular, we'll use:\nEither: represents the result of a computation that might fail\nOption: represents possible null/undefined values in a safe way\nTask: lazy Promise, represents the result of an async operation\nTaskEither: represents the result of an async operation that might fail (combination of Task\nand Either as its name implies)","make-the-apis-safer#Make the APIs Safer":"Let's consider a simple mock API for the purpose of this article. It represents a throwing API, such\nas a gRPC API.\n\nSince we have an async API that can throw, we'll use TaskEither to wrap those calls.\nEither<E, A> (and so TaskEither<E, A>) is parametrized by two types: E which represents the\nError and A which represents the type of the data if the call was successful. By convention, the\nleft side represents the failure, the right side the data type of the successful result.We can create an instance of it by using one of its basic constructors: of, left (to directly\ncreate an Error), right (to create a success) or one of its convenience constructors:\ntryCatch: if the function supplied throws, store a customized Error in the left side, else store\nthe successful result in the right side\nfromPredicate: if the predicate applied to the value is falsy, store a customized Error in the\nleft side, else store the value in the right side\nfromNullable: if the value is null or undefined, store a customized Error in the left side,\nelse store the value in the right side\n\nThis is now our safe APIs:\n\nNot only have we made our API safer code-wise, but also better from a documentation standpoint: now\nwe can also see which Errors the API returns, which was not the case when we were using Promise and\nreject (or try/catch).Now that we have dealt with the data fetching, let's consume this data. The first functionality we\nadd is checking the user permissions. In this simple example, we don't query an external service, we\ngot the data in the Entity and User types. We can create the checking function without worrying\nabout whether the user or entity is present since this will be handled by the monads (Either,\nTaskEither, Option). We can also decide to represent the absence of permission as an Error: in the\nsecond function, we use the Either.fromPredicate to transform the false value into a custom\nNotAllowedError:\n\nNow that both the Entity and User permission fetching calls are safer, we can combine them to create\nthe Entity fetching function with User permission check incorporated:\n\nWe fetch the User, then the Entity and when we have both, we check the User permission for this\nentity. Two things to note here:\nbecause the isUserAllowedForEntityAsError depends on both the User and the Entity and we\nfetched those separately, we have a nested pipeline (the nested pipe needs to close over the\nuser). We'll see next an alternate syntax to get rid of this nesting.\nthe chainFirst function allows us to execute computations in sequence but keep only the result\nof the first computation if the second computation is successful. Here what it does is:\nget the Entity (as a TaskEither)\nif it's a left (some Error), it won't execute the isUserAllowedForEntityAsError\nif it's a right (Entity), it executes the isUserAllowedForEntityAsError\nif it's a left (NotAllowedError), it returns the TaskEither holding this Error\nif it's a right (true), it ignores it and returns the result of the previous computation\n(the TaskEither holding the Entity)","avoid-nested-pipe-with-the-do-notation#Avoid Nested pipe with the Do Notation":"The Do notation is an adaptation of its native Haskell counterpart. It allows to build a context\nobject that keeps track of the unwrapped values produced by the different operations in the\npipeline. After its creation using the ADT Do or bind/bindTo functions, every subsequent\noperation in the pipeline has access to this context object, therefore eliminating the need for\nnesting.Let's rewrite our function using the Do notation:\n\nBecause the bind/bindTo functions return instances of ADTs (TaskEither here), we keep the\nfail-fast behaviour. In this example, if the getUser call returns a Left<NotFoundError>, we\nwon't call getEntity nor isUserAllowedForEntityAsError, it will return the TaskEither holding\nthe NotFoundError.","query-resolver#Query Resolver":"Now that we have a safe API, we can move on to the query resolver. We'll first validate the inputs\nand then query the data.","inputs-validation#Inputs Validation":"To validate the inputs, we'll also create a function that runs a validator on each input and returns\nan Either. By doing this we can integrate the result of the validation into the pipeline.\n\nThe validateIsNumber and validateIsUserId are functions that return\nEither<{ field: string; message: string }, TypeOfTheInput>. If the input fails the validation, we\nget an object of field name and validation message in the Left side, otherwise we get the input\nvalue in the Right side.The validate function takes a record of field to validator function and returns either an\nInvalidInputError or an object of input name to input value.","fetching-the-data-and-returning#Fetching the Data and Returning":"Once the inputs are validated, the next step in the pipeline is to fetch the data using\ngetEntityForUser. Because this call returns a TaskEither, we need to transform the previous\nEither into a TaskEither using TaskEither.fromEither. Of course, because of the fail-fast\nnature of the ADT, this won't be called if the inputs failed the validation.Finally, we exit the abstraction by using the TaskEither.fold (also called match) destructor:\nthis function does pattern matching on the TaskEither and executes the first callback if it's a\nLeft, or the second callback if it's a Right. At this point we want to return a WrappedError\nor an Entity from our query resolver, we do not want to return a TaskEither because we want\nsimple type resolvers that acts on the correct type. The ADT abstraction stays within the boundaries\nof our program and we consider the query (or mutation or subscription) resolver to be this boundary.","bonus-make-the-errors-type-resolvers-better-using-currying#Bonus: Make the Errors Type Resolvers Better Using currying":"Currying is the technique of converting a function that takes multiple arguments into a sequence\nof functions that each takes a single argument. It enables\npoint-free programming which allows for cleaner\ncallback or function composition in pipeline.We used above on several occasions:\n\nThe isUserAllowedForEntityAsError is a curried function: when called with the user input, it\nreturns a function that takes an entity input. If the function was not curried, we would have\nwritten:\n\nWith this knowledge, we can improve the repetitive type resolver code:\n\nThis code will be the same for all errors (with maybe a few additional field resolvers for some\nerrors). To make it better, we'll create a curried typeguard function and a curried field extraction\nfor the error:\n\nNow we can rewrite our error type resolvers like so:\n\nAnd since this code is common, we can extract it into a type resolver factory function:\n\nAnd rewrite our errors type resolvers like so:\n\nAnd if we have an error with more fields (e.g. we add a validations field to InvalidInputError),\nwe can still customize it by using the spread operator on the type resolver object:","wrapping-up#Wrapping Up":"GraphQL gives you the power to model your domain errors and deliver them to the caller in a\ndocumented and type-safe way. Using Typescript you get type safety for most of your code. Combined\nwith GraphQL Code Generator, you even get your resolvers functions fully typed. And finally with\npowerful functional programming concepts applied to your GraphQL resolvers, you can get the ultimate\nsafe handling of your unsafe APIs."}},"/blog":{"title":"Blog","data":{"":""}},"/blog/migrating-from-rest":{"title":"Migrating from Schemaless REST API to GraphQL without writing any code","data":{"":"GraphQL was originally created in order to easily provide a powerful API on top of existing code.\nThe current approach people are using today while migrating from REST API to GraphQL is to create a\nnew schema and use GraphQL as a proxy. That has a lot of benefits because it gives us an opportunity\nto rethink the API and improve it, without changing the underlining services.Let's first start with looking at that approach:","implementing-a-basic-proxy-graphql-backend#Implementing a Basic Proxy GraphQL Backend":"Let's say you have /user endpoint that does all CRUD operations for User entity with different\nHTTP methods, and you would need a GraphQL schema like below;\n\nAnd you would also need a thin business logic that proxies upcoming GraphQL requests to the REST API\nusing GraphQL resolvers like below;\n\nThis example assumes that you have /user/:id endpoint that gets a User entity with HTTP GET,\ndeletes user with HTTP DELETE and updates a User that has the given id with the given input.\nAlso /user endpoint creates a new User with the given input.But this implementation will be hard to maintain when the REST API is updated and become bigger.","using-graphql-mesh-instead-without-any-code#Using GraphQL Mesh Instead without Any Code":"GraphQL Mesh is a tool that handles multiple non-GraphQL data sources and generates an executable\nGraphQL schema on top of them with a simple configuration file.\nYou can check the announcement blog post to learn moreOn top of having handlers that automatically take care of sources with schema like -\nOpenAPI/Swagger, gRPC, SOAP, and others, it also has JSON Schema handler that generates a GraphQL\nSchema based on the given JSON schema files. This handler can also generate JSON Schema on runtime\nbased on the given sample request and response data.First you need to create a project using yarn on an empty directory:\n\nAfter that we need to install some dependencies of Mesh:\n\nCreate a .meshrc.yml which is a configuration file for GraphQL Mesh on our new project:\n\nAs you can see in the configuration, we defined our endpoints without a single line of code. After\ncreating this configuration file. We need to get sample request and response files by calling those\nendpoints on our local.With a single command, our new GraphQL endpoint is ready to serve;","not-only-as-a-gateway-but-also-a-completely-type-safe-sdk#Not Only as a Gateway but Also a Completely Type-Safe SDK":"Mesh is able to generate a type-safe SDK from generated GraphQL API because the generated GraphQL\nschema is a local GraphQLSchema that can be executed without binding an HTTP server.That means you can use GraphQL Mesh inside your existing services or clients,\nas an SDK, just as a simple dependency, without\nadding another box in your architecture."}},"/blog/how-not-to-learn-graphql":{"title":"How not to learn GraphQL","data":{"":"\"GraphQL is a front-end technology\", \"Federation is the only solution for unified graph and,\nservices orchestration\", \"GraphQL is a replacement of REST\" are common misconceptions that are\nmost likely linked to biased learning of GraphQL.Because of its rapid ecosystem evolution in the past years, learning GraphQL in 2022 is more\nchallenging than it used to be.For this reason, this article, greatly inspired by\n\"How not to learn TypeScript\" and\n\"How not to learn Rust\", will guide you to avoid\ncommon learning biases and misconceptions around GraphQL.","mistake-1-graphql-is-a-front-end-technology#Mistake #1: GraphQL Is a Front-End Technology":"Yes, is it true that GraphQL was first popularized as a technology solving issues on the client-side\n(mobile/web apps) by:\nreducing the number of roundtrips with the API(s)\nreducing the size of fetched data by requesting only the necessary fields\nremoving the overhead of fetching and crunching data from multiple endpoints\n\n\n\nIn short, GraphQL gave the control back to the data consumers (mobile apps, web apps).","graphql-as-an-innovative-solution-to-microservices-orchestration#GraphQL as an Innovative Solution to Microservices Orchestration":"However, starting in 2018, the GraphQL ecosystem started to grow, especially on the back-end side,\nwhere new horizons of GraphQL were developed.Many open-source actors started to propose solutions for unified schema/services orchestration, to\nname the major ones: GraphQL Tools,\nApollo Federation, Hasura,\nGraphQL Mesh.\n\nRapidly, some companies started to offer enterprise solutions such as SaaS/PaaS to manage GraphQL\nschema at scale: Apollo Studio,\nAWS AppSync, Hasura Cloud.","graphqls-path-on-back-end-use-cases#GraphQL's Path on Back-End Use-Cases":"Not limited to services orchestration, GraphQL continued its goal to become the go-to language for\ndata.Recent projects such as GraphQL Mesh or products such as\nHasura Cloud proved that GraphQL has a purpose beyond the simple\nfront-end/mobile apps fetching challenges.Other actors, such as Neo4J, a historical graph database actor,\nannounced support for GraphQL as\na data query language.","mistake-2-design-graphql-apis-like-rest-apis#Mistake #2: Design GraphQL APIs like REST APIs":"When designing a GraphQL Schema, many projects decide to keep a 1-1 relationship with the underlying\ndata schema (database or other microservices).Marc-André Giroux covered this subject in the\n\"GraphQL Mutation Design: Anemic Mutations\".\nThe term Anemic refers to a design where a Mutation (or Query) only contains data, not behaviors.A good GraphQL Schema design should:\nsimplify the usage by providing the proper abstractions (ex: aggregated fields, atomic mutation\nacross multiple microservices)\nprovide specialized mutations that represent specific behaviors instead of CRUD mutations directly\nlinked to an underlying data-schema\n\nFor example, for a schema exposing a query to update a User type as follows:\n\nA “data-driven” GraphQL Mutation for updateUser would be the following:\n\nAs explained in Marc-André Giroux's article, the above mutations expose a lot of optional fields,\nmaking the typing of the mutation obsolete (and also the self-documentation).\nBy removing any nullability constraints on the input fields, we've pretty much deferred all this\nvalidation to the runtime, instead of using the schema to guide the API user towards proper usage.\nGraphQL Mutation Design: Anemic Mutations.A better, behavior-driven, design would be the following:\n\nWe now offer specialized mutations where the end-user developer won't have to guess which fields are\nrequired and will get better static validations of the mutations arguments.Remember that a GraphQL Schema is neither a back-end nor front-end owned technology; it is a\ntechnical part of the stack that both parts must shape.Whether you build a product API or gateway of microservices, the goal of a GraphQL API is to provide\na simplified abstraction of a set of business logic.","mistake-3-learning-graphql-only-through-apollo#Mistake #3: Learning GraphQL Only through Apollo":"The Apollo company has been one of the leading early contributors of GraphQL and still is a\nprominent actor of the ecosystem.However, while most Apollo projects still keep a good share of usage and overall SEO presence, it is\nworth mentioning that new equivalent projects and alternatives rose in the past years.","browser-graphql-clients#Browser GraphQL Clients":"Regarding web-based client GraphQL Client, apollo-client is no longer the only viable solution.urql came as a solid and different vision of a GraphQL\nclient design, not just as an alternative, with:\nFlexible cache system\nExtensible design (easing adding new capabilities on top of it)\nLightweight bundle (~5x lighter than Apollo Client)\nSupport for file uploads and offline mode\n\nIn the React ecosystem, React Query (especially when\nused with GraphQL Code Generator) brings a lightweight and agnostic solution for GraphQL.React Query is a great candidate if you are looking for an easy-to-use and lightweight multipurpose\nclient (GraphQL-capable) that provides essential features such as:\nPowerful cache (background refresh, window-focus refreshing)\nAdvanced querying pattern (parallel queries, dependent queries, prefetching)\nUX patterns: optimistic updates, scroll restoration\nGreat dev tools\n\nFinally, when it comes to building simple applications that might not need caching or optimistic UIs\ncapabilities, the famous graphql-request library\nis a perfect companion!This lightweight library comes with the essential features to query a GraphQL API:\nMutations validation\nSupport for File upload\nBatching\nPromise-based API\nTypeScript support","server-graphql-libraries#Server GraphQL Libraries":"The same trend applies on the server-side, where many libraries are now widely used.Due to its historical presence and leading solutions for Apollo-powered technologies such as\nFederation, Apollo server still has a significant usage share.However, many new companies and projects prefer more opinionated or lightweight alternatives.Nest.js is an excellent alternative for GraphQL APIs building for Angular design and\nDDD lovers.\nNest.js comes with:\nFully-typed resolvers building experience\nStrong structuring patterns such as repositories, services, etc\nLogging system\nSupport for Apollo Federation\n\nNest.js is a great choice if you look into an opinionated and structured way to build your GraphQL\nAPIs.On the other hand, other non-opinionated libraries such as\nGraphQL Yoga focus on bringing the best developer\nexperience in building extensible GraphQL servers.GraphQL Yoga comes with a performant HTTP server that provides:\nsubscriptions over HTTP (SEE)\nsupport for @defer and @stream\nout of the box uploads and CORS capabilities\nExtensible design with\nthe Envelop plugins system\nApollo Federation support\nEasy integration with Next.js, Svelte Kit, Cloudflare workers, and more!","a-new-learning-path#A New Learning Path":"As we can see, GraphQL offers\nmultiple solutions from front-end, back-end, databases to SaaS.If you start learning GraphQL, an excellent place to start is\nhowtographql.com, where you'll be able to test multiple frameworks and\nfind the ones that best fit your stack and product/project.","mistake-4-throwing-errors-from-resolvers#Mistake #4: Throwing Errors from Resolvers":"For most new adopters (especially coming from REST APIs), having GraphQL APIs returning 200 OK on\nerrors seems like a flaw.However, while this design choice is entirely legit (GraphQL is bringing back the real purpose of\nHTTP status code that REST hijacked), another aspect of error handling in GraphQL is not.Most GraphQL resolvers implementation handle errors as follows:\n\nDoing so returns the following response:\n\nAs explained by Laurin from The Guild in\nthis article,\nusing this error pattern is a bad habit since:\nErrors need to be parsed on the client-side (we \"guess\" the error by parsing the error message)\nErrors are not colocated while Queries are designed to shape data on the UI","elegant-graphql-errors-with-union-types#Elegant GraphQL Errors with Union Types":"A more elegant way to emit error in GraphQL is to use Union types for expressing expected errors as\nfollows:\n\nAllowing us to write the following query:\n\nNow, the fetched response reflects the correct errors in a type-safe and colocated way:\n\nMore details are available in the\nHandling GraphQL errors like a champ with unions and interfaces\narticle.Note: Error masking is also an excellent approach that does not require updating the schema:\nhttps://graphql-yoga.com/docs/features/error-masking.","mistake-5-federation-is-the-only-viable-way-to-compose-schemas#Mistake #5: \"Federation Is the Only Viable Way to Compose Schemas\"":"","federation-is-opinionated-stitching#Federation Is Opinionated Stitching":"Apollo's Federation is commonly brought as the solution to compose schemas or build a\nmicroservices' architecture with GraphQL.While Federation has been\nbrought under a new name as a distinct solution to Stitching,\nthe reality is actually quite different.Stitching is a design that consists of a single GraphQL gateway schema that composes multiple\nunderlying GraphQL services.It can be achieved with 3 approaches: Federation, Modern Stitching and, Schema Extensions.Taking the following subschemas:\n\nLet’s see 3 distinct Stitching approaches to add the User.posts sub-query:","federation#Federation":"Federation architecture is actually stitching. It stitches subschemas (via an Apollo Gateway) by\nproviding a set of Type Merging directives (@requires, @key, @external).Each \"entity type\" must originate by a single service and can be extended by using a mix of schema\nextensions (extend type) and the Federation's SDL directives.To add the User.posts sub-query, the following schemas would be required:","modern-stitching#Modern Stitching":"Modern Stitching\n(GraphQL Tools v7+) is\nrelying on a programmatic approach where each subschema is totally independent.Only the gateway must provide type merging information to indicate who must resolve fields shared\nacross multiple services.After simply adding the posts: [Post!]! field to User, in the \"posts\" subschema:\n\nand adding the following gateway configuration will be required:\n\nThe final stitched schema could also be built similarly to Federation by using type merging\ndirectives (@merge, @canonical):","schema-extensions#Schema Extensions":"Schema extensions, similar to the initial Stitching proposals, is a different approach where\nindividual subschemas are only exposing their own types.The gateway becomes responsible for merging and enriching the final schema by using Schema\nExtensions:","modern-stitching-architecture#Modern Stitching Architecture":"Schema Stitching (a component\nof GraphQL Tools[v6 and under]) got a bad rap when it was famously\nabandoned by Apollo in favor of\ntheir Federation architecture some years back.\nHowever, Stitching came under the stewardship of The Guild and friends in 2020, and they've\nsince overhauled it with numerous automation and performance enhancements. Seemingly out of\nnowhere, Schema Stitching has reemerged as something of a nimble hummingbird racing alongside the\nstallion that is Apollo Federation.\nhttps://product.voxmedia.com/2020/11/2/21494865/to-federate-or-stitch-a-graphql-gateway-revisitedWhile initial Schema Stitching implementation (similar to Schema Extensions) had verbose\nconfiguration and performance issues (lack of batching), the Modern Stitching\n(GraphQL Tools v7+) relies on\nType Merging that provides great performance and developer experience.Let's review the main features of Modern Stitching and how it differentiates from Federation.","explicit-fields-resolutions-via-queries#Explicit Fields Resolutions via Queries":"Modern Stitching does not require types to have an origin (like Federation entities).All subschemas, being independent, can define types that might exist in other sibling services.The only requirement to allow GraphQL Tools to merge types together is that each subschema must\nexpose a query to resolve a type, as follows:\n\nHere, our \"Posts\" subschema adds a field to the User type (User.posts).To be able to resolve the User type on the following query:\n\nWe need to add the postsByUserId(userId: ID!) query to resolve the User type on the \"Posts\"\nservice.As explained in the\nGraphQL Tools v7+ documentation,\nhere is the merging flow performed when processing the UserPosts operation:\n\nModern Stitching's Type Merging approach follows the initial design of GraphQL resolvers but for\ntypes sharing fields across multiple subschemas.Such design leaves your subschemas independent (working on a schema only requires local knowledge)\nand built using vanilla-GraphQL (without a framework-specific mental model) while the stitching\nconfiguration is done at the gateway level.","improved-performance-with-automatic-batching#Improved Performance with Automatic Batching":"The main reproach made to the old Stitching approach was around performance.Modern Stitching brings fast Type Merging with 2 features:BatchingLet’s say that we execute the following operation on a new users query added to the Users service:\n\nIn order to resolve each user's posts, Modern Stitching will have to call postsByUserId Query on\nthe Posts service many times.Fortunately, if we transform the existing postsByUserId by the following:\n\nand properly configure our gateway, Modern Stitching will group the User.posts resolutions into a\nsingle postUsersByIds query to the Posts service.Query batchingThe same logic is applied by Modern Stitching at a higher level.If an operation needs to call a service multiple times, all those operations will be merged as one.\nFor example, on a hypothetical Products schema, the following queries:\n\nWill be transformed to the following unique operation that will be sent to the Products service:\n\nThose two features\n(Batching and\nQuery batching) significantly improve the\nperformance of a Modern Stitching architecture at scale.","the-flexibility-of-server-implementations-no-subscriptions-limitation#The Flexibility of Server Implementations: No Subscriptions Limitation":"When used with the Modern Stitching programmatic API (without the @merge and @canonical\ndirectives), building subschemas is achieved with vanilla GraphQL.It means that each subschema can be built with any technologies, framework, and libraries and\nrequire no compatibility work (while Federation requires subschemas to use a Federation-compatible\nGraphQL server).It is also true for the gateway server.Modern Stitching is a set of utilities that let you choose your own GraphQL-compatible HTTP\nserver/library (JavaScript):\nGraphQL Yoga\nNest.js\nGraphQL Helix + Express\nApollo Server\n\nFinally, Modern Stitching allows you\nto support GraphQL Subscriptions in a composed schema\n(over WS or SEE).","you-might-not-need-stitching#You Might Not Need Stitching":"Today, the most popular solutions for composing a unified GraphQL layer are done over the network\n(stitching with remote schemas or via Apollo Federation gateway).The main reason for doing that is the separation in development and deployment workflows and\nallowing teams to have ownership over the schema.However, such a setup creates performance issues due to the network overhead.While Apollo\nworks on a software solution to gap the gateway latency,\na solution might reside at the organization level.Another popular trend in the JavaScript ecosystem is monorepo.Thanks to the evolutions of tools (lerna,\nyarn workspaces) and from the GitHub platform\n(code owners system), monorepo is a viable and frequent pattern for teams to work together on a\ncomplex stack.The separation in development and deployment workflows and allowing teams to have ownership over the\nschema can also be achieved by merging the subschemas at build time and deploying it as a gateway\nthat runs local modules, with no network overhead.\n\nUsing a monorepo with schema merging at build time solves the incompressible performance issue while\npreserving the ownership of the subschemas and guaranteeing that deployed subschemas are compatible."}},"/blog/styled-components-encapsulation":{"title":"New encapsulation method for Styled-Components with Babel","data":{"":"","tldr-use-private-class-names-instead-of-a-dedicated-component-experimental#TL;DR: Use Private Class Names Instead of a Dedicated Component. Experimental":"Styled-Components has brought something new to the table when in\nwas first introduced and is one of the most popular CSS-related libraries out there with over 20k\nstars on GitHub. Style encapsulation has always been an issue in the web world, and people tried to\nsolve it in many ways, of which\nShadow DOM and\nAngular's emulated view encapsulation.I like the approach of Styled-Components, mostly because it's compatible with React which seems to\nbe the leading UI library in the echo system as for now, but also because of how nicely it sits in\nthe virtual DOM tree.For those who aren't familiar with Styled-Components, here's a quick example of how you would apply\nstyle on a React.Component:\n\nHowever, as good as it is, there are some major drawbacks for creating a dedicated component for\neach styled element:\nIt's longer to write than defining a class.\nIt's less efficient, because it has to go through the rendering phase of React.\nIt breaks the HTML naming conventions and we can't differentiate between a regular element and a\nReact.Component anymore.\nIMHO, combining multiple styles with Styled-Components mixins is less elegant and not as easy as\nspecifying multiple classes per single element (see\nissue on GitHub as reference).\n\nWhen I was writing the WhatsApp-Clone I used\na different approach to overcome the problems mentioned above. Instead of creating a dedicated\ncomponent for each styled element, I used a container that has all the CSS rules with private\nclasses. By private classes I mean, classes which start with an underscore (e.g. _my-class). This\nway I'm less likely to collide globally defined CSS rules:\n\nAs much as I love this approach, it doesn't achieve full encapsulation. A nested child component\nwhich has a similar class selector as its parent will result in a merged style, which is not\nnecessarily what we want. Each component should leave independently of its ancestors, which is what\nStyled-Components are all about.","introducing-babel-plugin-scoped-styled-components#Introducing babel-plugin-scoped-styled-components":"Indeed, this problem is solvable with a transpiler. Not only we can achieve full encapsulation this\nway, but it's also highly efficient due to its independence from a runtime library.So by loading a single plug-in, the recent code snippet I just showed you would be transformed into\nthe following code:\n\nI also thought of creating a runtime wrapper around Styled-Components where I basically iterate\nthrough props.children and edit their class names, but there are some advantages for using an AOT\ncompiler over a runtime solution:\nYou don't have to import a library different than styled-components and it's easily integratable\nwith existing projects.\nIt's more efficient.\nEncapsulation can be done based on the module you're currently at and not based on the virtual DOM\ntree. This behavior is not craved in stone as it can be easily modified by specifying certain\nattributes, but at-least the option is there.\nIt's more strict and declarative.\n\nThe source code is available on\nGitHub, or it can be downloaded\nvia NPM (or Yarn):\n\nOnce you install it, be sure to load it in your .babelrc:\n\nI'm aware that there are certain limitations to that approach as for now, but I would like to see\nmore interest and contribution before I continue any further with the development. Please share your\nthoughts everyone, let me know what do you think by commenting below or by\nopening an issue on GitHub."}},"/blog/scalable-apis-with-graphql-server-codegen-preset":{"title":"Scalable APIs with GraphQL Server Codegen Preset","data":{"":"A GraphQL server is usually a central system where teams need to be able to develop features whilst\nnot blocking other teams. Each team can have varied standards and practices. So, if the GraphQL\nserver is not set up in a structure to allow concurrent contribution, development slows down, and\nmore time is spent on admin tasks rather than delivering new features.This blog post explores some of the common problems GraphQL servers encounter at scale and\nrecommends how to solve them.","the-easy-problem-code-ownership#The Easy Problem: Code Ownership":"","problem-how-to-manage-code-ownership#Problem: How to Manage Code Ownership?":"Sharing a single codebase across many teams without clear structure and guidelines is a recipe for\ndisaster. The first team in the codebase usually establishes a structure that works for them. When a\nsecond team joins, they most likely follow the structure already there. The same story happens for\nevery team thereafter. After a few more rounds, development slows down. One may review the structure\nand find themselves staring down a codebase structured by one team, for one team.Teams want their members to be notified of changes related to their domain, but not every Pull\nRequest (PR). If you were ever notified of a change unrelated to your team, chances are the codebase\nneeds to be set up to support many teams working on it.In the example below, Team A is the first to set up the server. They manage User and Auth\ndomains, so they create datasources and resolvers folders for these files:\n\nThen, Team B comes into the codebase. They manage Book domain, so they add their files following\nthe same structure:\n\nWhile this works at a small scale with low communication overhead, it cannot scale. When there are\ntens or hundreds of datasources and resolvers, it would be hard to know who owns what. A simple\nsolution is to assign files to owners using GitHub's CODEOWNERS or similar features. But it has to\nbe done on every file because files are split into category folders, e.g. resolvers,\ndatasources, etc.It is tempting to split this structure up into folders, each named after the team that manages it:\n\nThis is already a significant improvement as ownership is defined, but organisational problems\nremain. For example, what happens when Team A changes what they own, splits into smaller teams or\nchanges its name? All these scenarios need admin work: renaming the folder in the best case and\nmoving files around in the worst. Admin work like this creates no value for end users.On top of that, all datasources and resolvers must be put together into the GraphQL server. It is\nthe server.python file in this example. Who owns this file and other server maintenance such as\npackage updates, security patches, codegen.yml etc.?","solution-split-into-modules#Solution: Split into Modules":"It is common to see teams change their name, divide as teams scale, or combine as structure and\npriorities change. Yet, the thing that generally remains stable over long periods is the business\ndomain. If we split our schema based on the business domain and assign teams accordingly, it becomes\nmuch more scalable. If a team needs to hand over a domain to another team, they only need to update\nthe CODEOWNERS file.It is best to have a small group of dedicated maintainers for server maintenance. This could consist\nof one member from each team in the codebase, and its membership can rotate. Alternatively, some\ncompanies may choose to assign this responsibility to a dedicated team. Having a dedicated group -\nlet's call them the Maintainers - helps reduce noise and cognitive load for the rest of the teams,\nallowing them to focus on delivering features.Using the same example before, we can identify 3 main domains: User, Auth and Book, each\nhaving CODEOWNERS set up to notify appropriate teams of changes. The Maintainers own server.python and\nother configs like codegen.yml (We all use\nGraphQL Codegen, right? 😉).","the-hard-problem-best-practice-alignment-at-scale#The Hard Problem: Best Practice Alignment at Scale":"Splitting schema into modules is usually easy to get teams to agree on. Then we start to see the\nhard problems: how to enforce best practices to the teams while reducing the time Maintainers need\nto spend on server maintenance.","1-how-to-enforce-best-practices-for-all-teams#1. How to Enforce Best Practices for All Teams":"Bad practices and conventions spread like bushfire on a hot summer day in Australia; it is the\nworst! I used to be part of a Maintainers team. We had guidelines on various topics, one being\nresolver naming convention. On one occasion, a developer incorrectly used pascal case instead of\ncamel case. The following day I woke up with more than half of the resolvers in pascal case. 😱OK, I am exaggerating here, but the experience was very traumatising.Guidelines are only good if people follow them. Standards start to slip without explicit and\nautomatic enforcement, and bad practices begin to spread.We need automated tools to enforce guidelines effectively. Luckily, these days we have an extensive\nrange of tools to help with GraphQL server best practices:\nGraphQL Codegen with\ntypescript and\ntypescript-resolvers\nplugins for type-safe GraphQL server development in TypeScript\nGraphQL ESLint for validation, linting, and checking\nfor best practices and conventions (like all resolvers must be camel case!!! 💀).\n\nHowever, there are areas to improve.For example, the guideline for one of the GraphQL servers I am working on is to use generated types\nfrom GraphQL Codegen. Some team members, particularly those new to the codebase, may have yet to be\naware of this. Luckily, other team members or the Maintainers catch these issues at PR review time.\nBut it would save everyone time and effort if we had tools to enforce this guideline automatically.","2-how-to-minimise-noise-to-the-maintainers#2. How to Minimise Noise to the Maintainers":"Maintainers usually need to manage these aspects of a GraphQL server:\nCore server logic: resolver map, schemas, CI/CD, etc.\nConfig files: .graphqlrc, codegen.yml, etc.\n\nChanging anything in the Maintainers' domain should notify them. Unfortunately, this happens\nregularly in routine workflows. Maintainers also have their team's work and general package and\nsecurity updates to worry about. So, being notified of unrelated PRs quickly leads to burnout.For example, if a new resolver is added, it must be manually added to the resolver map. So,\nMaintainers are notified of every new resolver. It may look like this if you are using\nGraphQL Yoga:\n\nThere is a way to mitigate this issue: each schema module exports an object of resolvers, and they\nare passed into resolvers as an array. Internally, the resolvers are merged using\nmergeResolvers from @graphql-tools/merge.\nThis means the Maintainers are notified on every new module instead of every new resolver:\n\nHowever, mergeResolvers has a caveat: it is simply merging plain JavaScript objects at runtime.\nThus, there is a risk of someone accidentally overriding others' resolvers. This issue is hard to\nfind in large codebases with hundreds of resolvers and modules.\n\nAnother commonly used feature is\nmappers.\nThis feature allows resolvers to return custom mapper objects instead of GraphQL output types.The problem with mappers is that we need to update codegen.yml every time we need to create one:\n\nThis is a problem for the Maintainers because these changes are based on team requirements. Whether\na team uses mappers or not is the team's choice and should not concern the Maintainers. Yet, the\nMaintainers are notified because they own the codegen.yml file.","solution-use-graphql-server-codegen-preset#Solution: Use GraphQL Server Codegen Preset":"To solve the above problems, I am working on a codegen preset for GraphQL server:\n@eddeee888/gcg-typescript-resolver-files.\nThe aim is to move from guidelines/config to conventions. All changes happen inside teams' modules,\nso feature work does not notify the Maintainer.This works for any GraphQL server implementation, such as GraphQL Yoga, Apollo Server, etc.Here's how to get started:\n\nThen, you can add the following config:\n\nNote that this preset includes @graphql-codegen/typescript and\n@graphql-codegen/typescript-resolvers under the hood, so you do not have to set that up manually!Now, all we have to do is to set up schema modules like this:\n\nGiven the following content of schema files:\n\nWhen we run codegen:\n\nWe will see the following files:","generated-files#Generated Files":"Shared schema and resolver TypeScript types: types.generated.python. This is generated by\n@graphql-codegen/typescript and @graphql-codegen/typescript-resolvers plugins. This can be\nignored in Git or removed from CODEOWNERS because it is entirely generated.\nResolver map: resolvers.generated.python. This puts all other resolvers together statically,\nready to be used by the GraphQL server. This can be ignored in Git or removed from CODEOWNERS\nbecause it is entirely generated.\n\n\n\n\nOperation resolvers:\nsrc/schema/user/resolvers/Query/user.python\nsrc/schema/book/resolvers/Query/book.python\nsrc/schema/book/resolvers/Mutation/book.python\n\n\n\n\n\n\nObject type resolvers:\nsrc/schema/user/resolvers/User.python\nsrc/schema/book/resolvers/Book.python\n\n\n\n\n\nResolvers are generated with developer experience in mind:\nAutomatically typed: you can go straight into implementing resolver logic.\nLocation in the schema matches the generated location on the filesystem: you can easily jump to a\nresolver file. For example, user Query logic can be found in Query/user.python.\n\n\n\nThe resolver files are not overwritten when codegen runs again. However, there are some smarts\nbuilt-in to ensure resolvers are correctly exported. For example, if we rename User resolver to\nWrongUser in src/schema/user/resolvers/User.python, and then run codegen, the file will be updated\nwith a warning:\n\nSome of these features are inspired by gqlgen so check it out if you need a\nGolang GraphQL server implementation.","other-graphql-types#Other GraphQL Types":"These other types are also supported by the preset:\nUnion: A file is generated for every Union type.\nScalars:\nIf the Scalar name matches one in graphql-scalars, it\nis automatically imported from graphql-scalars into the resolver map. Make sure to install it:\n\n\n\n\nIf the Scalar name does not exist in graphql-scalars, a file is generated for every Scalar\ntype.\n\n\n\nFor other currently non-supported types, we can declare them using the externalResolvers preset\nconfig.","mappers-convention#Mappers Convention":"Mappers can be added by exporting types or interfaces with Mapper suffixes from .mappers.python\nfiles in each module. For example, UserMapper will be used as User's mapper type.","gradual-migration-supported#Gradual Migration Supported":"If you have an existing codebase in a modularised structure but cannot migrate all at once, the\npreset has whitelistedModules and blacklistedModules options to support gradual migration.","customisable-conventions#Customisable Conventions":"All mentioned conventions are customisable! Check out the documentation for\nmore options.","differences-between-server-preset-and-graphql-modules#Differences between Server Preset and graphql-modules":"So far, the preset may sound similar to graphql-modules as\nthey both split schemas into modules. Yet, they solve different problems.graphql-modules is a modularisation utility library that allows each module to maintain schema\ndefinitions and resolvers separately, whilst serving a unified schema at runtime.The preset focuses on conventions (such as file structures, types, integrations with other\nlibraries, etc.). However, it does not force schema modularisation upon the user. In fact, the\ndefault modules mode is recommended for its scalablility and simplicity. The preset also has a\nmerged mode to generate files in a monolithic way that may suit some teams and organisations.This also means there could be a mode in the preset to support graphql-modules in the future.","summary#Summary":"In this blog post, we have explored the problems likely to occur if your GraphQL server is not\nprepared for scale:\nunclear ownership\nignored best practices\nnoisy maintenance\n\nWe can solve these problems by following the outlined recommendations:\nmodularise the codebase based on business domains\nuse the GraphQL server codegen preset\n@eddeee888/gcg-typescript-resolver-files\n\nAt SEEK, we are experimenting with this preset and getting positive\nfeedback. Let me know on Twitter if it works for you too!"}},"/blog/react-hooks-system":{"title":"Under the hood of React's hooks system","data":{"":"","looking-at-the-implementation-and-getting-to-know-it-inside-out#Looking at the Implementation and Getting to Know It inside Out":"We've all heard about it. The new hook system of React 16.7 has made a lot of noise in the\ncommunity. We've all tried it and tested it, and got really excited about it and its potential. When\nyou think about hooks they're kind of magical, somehow React manages your component without even\nexposing its instance (no use of this keyword). So how the heck does React does that?Today I would like to dive into React's implementation of hooks, so we can understand it better. The\nproblem with magical features is that it's harder to debug a problem once it happens, because it's\nbacked by a complex stack trace. Thus, by having deep knowledge regards React's new hook system, we\nwould be able to solve issues fairly quick once we encounter them, or even avoid them in the first\nplace.\nBefore I begin I would just like to say that I'm not a developer/maintainer of React and that my\nwords should be taken with a grain of salt. I did dive very deeply into the implementation of\nReact's hooks system, but by all means I can't guarantee that this is how React actually works.\nWith that said, I've backed my words with proofs and references from React's source code, and\ntried to make my arguments as solid as possible.\n![](/medium/bca747b6dd5992e26b78942e8ba4f071.png 'A rough schematic representation of React's hooks\nsystem')First, let's go through the mechanism that ensures that hooks are called within React's scope,\nbecause you'd probably know by now that hooks are meaningless if not called in the right context:","the-dispatcher#The Dispatcher":"The dispatcher is the shared object that contains the hook functions. It will be dynamically\nallocated or cleaned up based on the rendering phase of ReactDOM, and it will ensure that the user\ndoesn't access hooks outside a React component (see\nimplementation).The hooks are enabled/disabled by a flag called enableHooks right before we render the root\ncomponent by simply switching to the right dispatcher; this means that technically we can\nenable/disable hooks at runtime. React 16.6.X also has the experimental feature implemented, but\nit's actually disabled (see\nimplementation).When we're done performing the rendering work, we nullify the dispatcher and thus preventing hooks\nfrom being accidentally used outside ReactDOM's rendering cycle. This is a mechanism that will\nensure that the user doesn't do silly things (see\nimplementation).The dispatcher is resolved in each and every hook call using a function called\nresolveDispatcher(). Like I said earlier, outside the rendering cycle of React this should be\nmeaningless, and React should print the warning message: “Hooks can only be called inside the body\nof a function component” (see\nimplementation).\n\nNow that we got that simple encapsulation mechanism covered, I would like us to move to the core of\nthis article — the hooks. Right of the bet I'd like to introduce you to a new concept:","the-hooks-queue#The Hooks Queue":"Behind the scenes, hooks are represented as nodes which are linked together in their calling order.\nThey're represented like so because hooks are not simply created and then left alone. They have a\nmechanism which allows them to be what they are. A hook has several properties which I would like\nyou to bare in mind before diving into its implementation:\nIts initial state is created in the initial render.\nIts state can be updated on the fly.\nReact would remember the hook's state in future renders.\nReact would provide you with the right state based on the calling order.\nReact would know which fiber does this hook belong to.\n\nAccordingly, we need to rethink the way we view the component's state. So far we have thought about\nit as if it's a plain object:\n\nBut when dealing with hooks it should be viewed as a queue, where each node represents a single\nmodel of the state:\n\nThe schema of a single hook node can be viewed in the\nimplementation.\nYou'll see that the hook has some additional properties, but the key for understanding how hooks\nwork lies within memoizedState and next. The rest of the properties are used specifically by the\nuseReducer() hook to cache dispatched actions and base states so the reduction process can be\nrepeated as a fallback in various cases:\nbaseState - The state object that would be given to the reducer.\nbaseUpdate - The most recent dispatched action that created the baseState.\nqueue - A queue of dispatched actions, waiting to go through the reducer.\n\nUnfortunately I haven't managed to get a good grasp around the reducer hook because I didn't manage\nto reproduce almost any of its edge cases, so I wouldn't feel comfortable to elaborate. I will only\nsay that the reducer implementation is so inconsistent that even one of the comments in the\nimplementation\nitself states that “(it's) not sure if these are the desired semantics”; so how am I supposed to be\nsure?!So back to hooks, before each and every function Component invocation, a function named\nprepareHooks()\nis going to be called, where the current fiber and its first hook node in the hooks queue are going\nto be stored in global variables. This way, any time we call a hook function (useXXX()) it would\nknow in which context to run.\n\nOnce an update has finished, a function named\nfinishHooks()\nwill be called, where a reference for the first node in the hooks queue will be stored on the\nrendered fiber in the memoizedState property. This means that the hooks queue and their state can\nbe addressed externally:\n\nLet's get more specific and talk about individual hooks, starting with the most common of all — the\nstate hook:","state-hooks#State Hooks":"You would be surprised to know, but behind the scenes the useState hook uses useReducer and it\nsimply provides it with a pre-defined reducer handler (see\nimplementation).\nThis means that the results returned by useState are actually a reducer state, and an action\ndispatcher. I would like you to take a look at the reducer handler that the state hook uses:\n\nSo as expected, we can provide the action dispatcher with the new state directly; but would you look\nat that?! We can also provide the dispatcher with an action function that will receive the old\nstate and return the new one. This isn't documented anywhere in the\nofficial React documentation (as\nfor the time this article was written) and that's a pity because it's extremely useful! This means\nthat when you send the state setter down the component tree you can run mutations against the\ncurrent state of the parent component, without passing it as a different prop. For example:\n\nLastly, effect hooks — which made a major impact on a component's life cycle and how it works:","effect-hooks#Effect Hooks":"Effect hooks behave slightly differently and has an additional layer of logic that I would like to\nexplain. Again, there are things I would like you to bear in mind regards the properties of the\neffect hooks before I dive into the implementation:\nThey're created during render time, but they run after painting.\nIf given so, they'll be destroyed right before the next painting.\nThey're called in their definition order.\n\n\nNote that I'm using the \"painting\" term and not \"rendering\". These two are different things, and\nI've seen many speakers in the recent React Conf use the wrong term!\nEven in the official React docs they\nsay “after the render is committed to the screen”, which is kind of like \"painting\". The render\nmethod just creates the fiber node but doesn't paint anything yet.\nAccordingly, there should be another an additional queue that should hold these effects and should\nbe addressed after painting. Generally speaking, a fiber holds a queue which contains effect nodes.\nEach effect is of a different type and should be addressed at its appropriate phase:\nInvoke instances of getSnapshotBeforeUpdate() before mutation (see\nimplementation).\nPerform all the host insertions, updates, deletions and ref unmounts (see\nimplementation).\nPerform all life-cycles and ref callbacks. Life-cycles happen as a separate pass so that all\nplacements, updates, and deletions in the entire tree have already been invoked. This pass also\ntriggers any renderer-specific initial effects (see\nimplementation).\nEffects which were scheduled by the useEffect() hook - which are also known as “passive effects”\nbased on the\nimplementation\n(maybe we should start using this term within the React community?!).\n\nWhen it comes to the hook effects, they should be stored on the fiber in a property called\nupdateQueue, and each effect node should have the following schema (see\nimplementation):\ntag - A binary number which will dictate the behavior of the effect (I will elaborate soon).\ncreate - The callback that should be ran after painting.\ndestroy - The callback returned from create() that should be ran before the initial render.\ninputs - A set of values that will determine whether the effect should be destroyed and\nrecreated.\nnext - A reference to the next effect which was defined in the function Component.\n\nBesides the tag property, the other properties are pretty straight forward and easy to understand.\nIf you've studied hooks well, you'd know that React provides you with a couple of special effect\nhooks: useMutationEffect() and useLayoutEffect(). These two effects internally use\nuseEffect(), which essentially mean that they create an effect node, but they do so using a\ndifferent tag value.The tag is composed out of a combination of binary values (see\nimplementation):\n\nThe most common use cases for these binary values would be using a pipeline (|) and add the bits\nas is to a single value. Then we can check whether a tag implements a certain behavior or not using\nan ampersand (&). If the result is non-zero, it means that the tag implements the specified\nbehavior.\n\nHere are the supported hook effect types by React along with their tags (see\nimplementation):\nDefault effect — UnmountPassive | MountPassive.\nMutation effect — UnmountSnapshot | MountMutation.\nLayout effect — UnmountMutation | MountLayout.\n\nAnd here's how React checks for behavior implementation (see\nimplementation):\n\nSo, based on what we've just learned regards effect hooks, we can actually inject an effect to a\ncertain fiber externally:\n\nSo that was it! What was your biggest takeout from this article? How are you going to use this new\nknowledge in your React apps? Would love to see interesting comments!"}},"/blog/taking-over-merge-graphql-schemas":{"title":"The Guild is taking over maintenance of merge-graphql-schemas","data":{"":"How stitching, federation and modules all fit together?","tldr#TL;DR":"After many years of supporting the community, the OK-GROW! Team is transferring ownership and\nmaintenance of merge-graphql-schemas to The\nGuild\nmerge-graphql-schemas will be added to the\nexisting Schema management tools already created by\nThe Guild\n(GraphQL-Toolkit,\nGraphQL Modules,\nGraphQL Inspector and\ngraphql-code-generator)\nThis is a continuation of making order in the schema management tools across the ecosystem\nIf you are at GraphQL-Conf this week, come say hi\n\nmerge-graphql-schemas is a popular library in the\nGraphQL Ecosystem.It's one of the first tools people encounter once they went through their first GraphQL\nimplementation and start to wonder how to organize their GraphQL server code.The OK-GROW! Team has been maintaining that library for years, filling a needed gap in the\necosystem.At the same time, The Guild has been working on\nsimilar tools around GraphQL schema and module management.Today we are happy to announce that we are joining forces and merging our efforts to create open\nsource, easy and scalable solutions for GraphQL servers.In a couple of days of work we've refactored the underlying implementation of\nmerge-graphql-schemas to use\nGraphQL-Toolkit under the hood, we can close around\n90% of the open issues on the library while making sure all existing tests are passing!We are happy to announce a new beta release (1.6.0-beta) is out!If you are a user of merge-graphql-schemas please\ngive the new version a try before we make a full release.","whats-next#What's Next?":"The Guild has been busy for a while creating scalable GraphQL solutions around schema and modules\nmanagement for large teams.The main issue we see today in the ecosystem is that there is no clear overview of which tools solve\nwhich problem area.In order to make sure we solve the right issues in the right place, we need clear boundaries between\nthe different libraries and solutions.Let's try to break down the different areas of solutions needed when splitting GraphQL schemas:\nBuilding and executing GraphQL according to spec — The Engine\nStructuring multiple building blocks of the same server into a single executable schema —\nGraphQL Tools and Frameworks\nStructuring multiple servers instances into a single executable schema — Federation\n\nNow we can gather all use cases from the community, put them as tests on the right library and make\nsure we solve each one of them.","the-engine#The Engine":"The Engine (in the Javascript world the most popular one is\ngraphql.js) should be responsible for taking a ready schema\nand resolvers, validate the objects, introspecting them and executing documents against them at\nruntime.That GraphQLSchema input must be strictly valid according to the GraphQL Spec.That's why manipulating a ready GraphQLSchema object can be hard. GraphQLSchema object should be the\nfinal object to input the engine.The Engine should not care or help you create that final schema or resolvers.","graphql-management-tooling#GraphQL Management Tooling":"We can think of the Engine like a Web Browser — It is responsible for taking a spec (Javascript and\nHTML) and execute it in a consistent way.But the browser doesn't care about how you create that Javascript and HTML bundle.That means that like we use babel, Typescript or frameworks for manipulating code to generate\nspec-compliant output, we can do the same for GraphQL with\ngraphql.js as our target “browser”.Those tools should help you organize and manage your code in your preferred way, without needing to\nbe bound by what graphql.js expects.One of the main things that those tools can provide us is an easy way to split the code and the\nschema into small chunks and later merge them with different merging strategies.Just like Javascript frameworks, using those tools can get you very far and make it easy to handle\nhuge codebases with many different teams.","federation#Federation":"In some scenarios you would want to run completely different servers and merge them somehow into a\nsingle GraphQL gateway.Schema stitching and\nschema federation are\nattempts to make that work less manual.There are some use cases where you might want those types of solutions, but they also add a lot of\ncomplexity, so it's important to understand very well why you really can't handle your use case in a\nbuild-tool type of solution, and to know if Federation is an end goal or a stepping point to get you\nfurther.","breaking-it-all-down#Breaking It All Down":"After years of working with GraphQL, from small applications to managing schemas across huge\ncorporations, creating open source tools and best practices around those, we want to share it all\nwith the community.In the next few weeks we will publish articles about each solution type, the tools around and when\nyou should use what.Things like why you should split your schemas, why not, what are the existing solutions out there\nand when to use each one.We will also add examples of all those use cases into our\nmain tutorial.We need you to send us your questions, use cases and ideas — we want to make sure we cover as many\nuse cases as possible across our libraries and other libraries we\ncontribute too as well (some things\nmight fit into graphql.js or Apollo for example).You can comment here or submit issues into any of\nour repositories.","thank-you-ok-grow#Thank You OK-GROW!":"I want to personally thank the OK-GROW! Team and specifically Paul for being a very early adopter\nand supporter of the GraphQL community.The work you have done so far has been amazing and valuable and we are dedicated to continue to\nsupport our community in the best way possible."}},"/blog/runtime-jsx":{"title":"Implementing a runtime version of JSX","data":{"":"","learning-how-to-think-like-a-jsx-parser-and-building-an-ast#Learning How to Think like a JSX Parser and Building an AST":"JSX is one of the most commonly used syntax extensions out there. Originally JSX was parsed via a\nFacebook fork of Esprima — a JavaScript syntax parser\ndeveloped by jQuery. As it gained momentum, Acorn took things to\ntheir hands and decided to make their own version of the parser which ended up being 1.5–2x faster\nthan Esprima-fb, and is now being used by officially Babel.It definitely went through an evolution, but regardless of its phase, all parsers had a similar\noutput — which is an AST. Once we have an AST representation of the JSX code, interpretation is\nextremely easy.Today we're going to understand how a JSX parser thinks by implementing one of our own. Unlike\nBabel, rather than compiling, we're going to evaluate the nodes in the AST according to their types,\nwhich means that we will be able to use JSX during runtime.Below is an example of the final product:\n\nBefore we go ahead and rush to implementing the parser let's understand what we're aiming for. JSX\nsimply takes an HTML-like syntax and transforms it into nested React.createElement() calls. What\nmakes JSX unique is that we can use string interpolation within our HTML templates, so we can\nprovide it with data which doesn't necessarily has to be serialized, things like functions, arrays,\nor objects.So given the following code:\n\nWe should get the following output once compiling it with Babel:\n\nJust a quick reminder — the compiled result should be used internally by ReactDOM to differentiate\nchanges in the virtual DOM and then render them. This is something which is React specific and has\nnothing to do with JSX, so at this point we have achieved our goal.Essentially there are 3 things we should figure out when parsing a JSX code:\nThe name / component of the React element.\nThe props of the React element.\nThe children of the React element, for each this process should repeat itself recursively.\n\nAs I mentioned earlier, it would be best if we could break down the code into nodes first and\nrepresent it as an AST. Looking at the input of the example above, we can roughly visualize how we\nwould pluck the nodes from the code:\n\nAnd to put things simple, here's a schematic representation of the analysis above:\n\nAccordingly, we're going to have 3 types of nodes:\nElement node.\nProps node.\nValue node.\n\nLet's decide that each node has a base schema with the following properties:\nnode.type — which will represent the type name of the node, e.g. element, props and value.\nBased on the node type we can also determine that additional properties that the node's going to\ncarry. In our parser, each node type should have the following additional properties:\n\n\n\n\nnode.length —which represents the length of the sub-string in the code that the node occupies.\nThis will help us trim the code string as we go with the parsing process so we can always focus on\nrelevant parts of the string for the current node:\n\n![](/medium/7ba5847a0000df3ef06a6913a79346f2.png 'Any time we parse a small part of the string, we\nslice the part we've just parsed.')In the function that we're going to build we'll be taking advantage of ES6's tagged templates.\nTagged templates are string literals which can be processed by a custom handler according to our\nneeds (see\nMDN docs).So essentially the signature of our function should look like this:\n\nSince we're gonna heavily rely on regular expression, it will be much easier to deal with a\nconsistent string, so we can unleash the regexp full potential. For now let's focus on the string\npart without the literal, and parse regular HTML string. Once we have that logic, we can implement\nstring interpolation handling on top of it.","starting-with-the-core--an-html-parser#Starting with the Core — an HTML Parser":"As I already mentioned, our AST will be consisted of 3 node types, which means that we will have to\ncreate an ENUM that will contain the values element, props and value. This way the node types\nwon't be hardcoded and patching the code can be very easy:\n\nSince we had 3 node types, it means that for each of them we should have a dedicated parsing\nfunction:\n\nEach function creates the basic node type and returns it. Note that at the beginning of the scope of\neach function I've defined a couple of variables:\nlet match - which will be used to store regular expression matches on the fly.\nlet length - which will be used to store the length of the match, so we can trim the JSX code\nstring right after and accumulate it in node.length.\n\nFor now the parseValue() function is pretty straight forward and just returns a node which wraps\nthe given string.We will begin with the implementation of the element node, and we will branch out to other nodes as\nwe go. First we will try to figure out the name of the element. If an element tag opener was not\nfound, we will assume that the current part of the code is a value:\n\nUp next, we need to parse the props. To make things more efficient, we will need to first find the\ntag closer, so we can provide the parseProps() method the relevant part of the string:\n\nNow that we've plucked the right substring, we can go ahead and implement the parseProps()\nfunction logic:\n\nThe logic is pretty straight forward — we iterate through the string, and each time we try match the\nnext key->value pair. Once a pair wasn't found, we return the node with the accumulated props. Note\nthat providing only an attribute with no value is also a valid syntax which will set its value to\ntrue by default, thus the / *\\w+/ regexp. Let's proceed where we left of with the element\nparsing implementation.We need to figure out whether the current element is self-closing or not. If it is, we will return\nthe node, and otherwise we will continue to parsing its children:\n\nAccordingly, we're going to implement the children parsing logic:\n\nChildren parsing is recursive. We keep calling the parseElement() method for the current substring\nuntil there's no more match. Once we've gone through all the children, we can finish the process by\nfinding the closing tag:\n\nThe HTML parsing part is finished! Now we can call the parseElement() for any given HTML string,\nand we should get a JSON output which represents an AST, like the following:","leveling-up--string-interpolation#Leveling up — String Interpolation":"Now we're going to add string interpolation on top of the HTML string parsing logic. Since we still\nwant to use the power of regexp at its full potential, we're going to assume that the given string\nwould be a template with placeholders, where each of them should be replaced with a value. That\nwould be the easiest and most efficient way, rather than accepting an array of string splits.\n\nAccordingly, we will update the parsing functions' signature and their calls, and we will define a\nplaceholder constant:\n\nNote how I used the Date.now() function to define a postfix for the placeholder. This we can be\nsure that the same value won't be given by the user as a string (possible, very unlikely). Now we\nwill go through each parsing function, and we'll make sure that it knows how to deal with\nplaceholders correctly. We will start with the parseElement() function.We will add an additional property to the node called: node.tag. The tag property is the component\nthat will be used to create the React element. It can either be a string or a React.Component. If\nnode.name is a placeholder, we will be taking the next value in the given values stack:\n\nWe also made sure that the closing tag matches the opening tag. I've decided to “swallow” errors\nrather than throwing them for the sake of simplicity, but generally speaking it would make a lot of\nsense to implement error throws within the parsing functions.Up next would be the props node. This is fairly simple, we're only going to add an additional regexp\nto the array of matchers, and that regexp will check for placeholders. If a placeholder was\ndetected, we're going to replace it with the next value in the values stack:\n\nLast but not least, would be the value node. This is the most complex to handle out of the 3 nodes,\nsince it requires us to split the input string and create a dedicated value node out of each split.\nSo now, instead of returning a single node value, we will return an array of them. Accordingly, we\nwill also be changing the name of the function from parseValue() to parseValues():\n\nThe reason why I've decided to return an array of nodes and not a singe node which contains an array\nof values, just like the props node, is because it matches the signature of React.createElement()\nperfectly. The values will be passed as children with a spread operator (...), and you should see\nfurther this tutorial how this well it fits.Note that we've also changed the way we accumulate children in the parseElement() function. Since\nparseValues()returns an array now, and not a single node, we flatten it using an empty array\nconcatenation ([].concat()), and we only push the children whose contents are not empty.","the-grand-finale--execution#The Grand Finale — Execution":"At this point we should have a function which can transform a JSX code into an AST, including string\ninterpolation. The only thing which is left to do now is build a function which will recursively\ncreate React elements out of the nodes in the tree.The main function of the module should be called with a template tag. If you went through the\nprevious step, you should know that a consistent string has an advantage over an array of splits of\nstrings, since we can unleash the full potential of a regexp with ease. Accordingly, we will take\nall the given splits and join them with the placeholder constant.\n\nOnce we join the string we can create React elements recursively:\n\nNote that if a node of value type is being iterated, we will just return the raw string, otherwise\nwe will try to address its node.children property which doesn't exist.Our JSX runtime function is now ready to use!If you wonder how did I structure this tutorial so nicely with steps and beautiful diffs — check out\ntortilla.academy by Uri Goldshtein.Lastly, you can view the source code at the official\nGitHub repository, or you can download a Node.js package\nusing NPM:"}},"/blog/typed-document-node":{"title":"TypedDocumentNode: the next generation of GraphQL and TypeScript","data":{"":"// Examples are in: https://codesandbox.io/s/quizzical-browser-1em9r?file=/index.pythonUsing GraphQL and Typescript on the client just became a lot easier!The GraphQL Code Generator project has been around for 3\nyears, and we are constantly keep working on it and listening to your feedback!As we were working and thinking about\nthe next major version of the codegen,\nwe came up with a really awesome tool which didn't require any breaking change!So today, after successfully integrating this feature into few of our largest clients, we can\nproudly share it with you -\nTypedDocumentNode.A new and easier way to enjoy and integrate GraphQL and Typescript on the client.TypedDocumentNode is a development tool for creating fully typed DocumentNode objects. It means\nthat just by passing the GraphQL query/mutation/subscription/fragment to a supporting GraphQL client\nlibrary, you'll get fully-typed result and variables objects.This is made possible by\nTypeScript type inference.","tldr#TL;DR":"TypedDocumentNode is a great\nsolution for having pre-compiled (DocumentNode) GraphQL operations with built-in support for\nTypeScript types.\nNo need to specify types manually in your application code, all types are inferred automatically\nfrom your operation object.\nYou can easily extend any GraphQL client library to support it, even without changing the library\ncode.\nYou can integrate it to your project\nusing these instructions","client-side-applications-typescript-and-graphql#Client-Side Applications, TypeScript and GraphQL":"The integration of GraphQL and TypeScript in client-side applications has evolved in recent times:","2016-manual-typings#2016: Manual Typings":"We started with manually writing TypeScript types for our operations. It worked, but it didn't\nscale. It needed maintenance to make sure our types matched the exact selection set we are fetching.","2017-generated-types#2017: Generated Types":"We moved to generated TypeScript types, with the power of\nGraphQL Code Generator - using @graphql-codegen/typescript\nand @graphql-codegen/typescript-operations plugins.It's simpler (no need to maintain the types manually) but it requires us to manually specify the\ntypes each time we use the query.","2018-generated-code#2018: Generated Code":"The next step of that evolution was to generate code - that means that we can generate React Hooks\n(@graphql-codegen/typescript-react-apollo or @graphql-codegen/typescript-urql), Angular Services\n(@graphql-codegen/typescript-apollo-angular) and much more. We can even generate a pre-compiled\nDocumentNode instead of dealing with Webpack loaders.This generated code takes GraphQL and TypeScript to the next level - because we are getting\nready-to-use code that has TypeScript types built-in and allow us to use it directly from our\napplication code without the need to specify the types or GraphQL document manually:","2020-new-typeddocumentnode#2020: New TypedDocumentNode":"Generating code is nice, but we don't always need to wrap hooks, services or similar code with more\ncode. With the power of TypeScript, we can pre-compile the GraphQL operation into a DocumentNode,\nand add burn-in the TypeScript types.With the support of the client-side libraries, we get automatic type inference and auto-complete -\nwithout generating additional code:","live-demo#Live Demo":"You can try it live here;\nnote the autocomplete and automatic type inference for the result variable.","how-does-it-work#How Does It Work?":"This project works in the following way:\nYou write your GraphQL operations (query / mutation / subscription / fragment) in any way\nyour prefer (for example - in a .graphql file).\nGraphQL Code Generator will generate a TypedDocumentNode\nfor your operations (which is a bundle of pre-compiled DocumentNode with the operation result\ntype and variables type).\nInstead of using your .graphql file, import the generated TypedDocumentNode and use it with\nyour GraphQL client framework.\nYou'll get automatic type inference, auto-complete and type checking based on your GraphQL\noperation.\n\nThe definition of TypedDocumentNode is super simple - it's all about the python generics:","can-i-use-it-now#Can I Use It Now?":"This library is already available to use, but it requires you to setup it in your project, since\nTypedDocumentNode isn't supported automatically in all GraphQL client libraries.That's why we used patch-package to patch existing declarations, and added support to other\nlibraries without effecting it's runtime.You can find a list of all supported GraphQL clients here\nand\na short getting started tutorial here.If you are using a library that isn't supported yet,\nyou can always add support to it manually using method overloading.","whats-next#What's Next?":"GraphQL client libraries\ncan easily add support\nfor TypedDocumentNode, without breaking any API, allowing developers to have direct support for\nthat, without the need for the supporting libraries.And, maybe, one day, it will part of the\noriginal GraphQL DocumentNode interface\n;)"}},"/blog/whats-new-on-meteor-client-bundler":{"title":"Meteor Client Bundler — React Native support, handling Meteor imports","data":{"":"","introduction-to-new-features-of-mcb#Introduction to New Features of MCB":"Meteor Client Bundler is a solution for packaging Meteor's official client packages into a single\nmodule in order to use your projects not using Meteor CLI. Until last version, it is not possible to\nuse MCB on non-browser projects without some tricks such as React Native, Electron etc…","new-features-on-mcb#New Features on MCB":"Generate stub modules for meteor/[PACKAGE] if you cannot use module-aliasing somehow. It is\nreally challenging situation on Angular CLI and React Native CLI.\nUse external NPM modules from your client project's node_modules directory instead of adding it\nto the Meteor Client Bundle; this is required not to duplicate react for React Native projects.\nPossibility not to add __meteor_runtime_config , if you want to add it by yourself in your\nproject. Especially, if you want to separate production and development URLs for Meteor backend\n\nThese features allow you to use directly Angular CLI and React Native CLI without the need of\nejecting any configuration file.Also, there is other specific post about React Native CLI integration of Meteor without using 3rd\nparty libraries such as react-native-meteor or react-meteor-data which are copies of official\nclient libraries. The most important disadvantage of using these extra libraries is lack of code\nsharing between Meteor and React Native project. Otherwise, Client Bundle generated by MCB allows\nthis.","related-posts#Related Posts":"You can access React Native integration post from this link.\n\n\n\n\nAnother post explains Angular CLI with MCB is here;","examples#Examples":"These are direct links to the example projects using MCB;\nAngular CLI Example;\nhttps://github.com/Urigo/angular-meteor/tree/master/examples/AngularCLI\nReact Native CLI Example w/ Expo;\nhttps://github.com/DAB0mB/ReactNativeMeteorBoilerplate\n\nSpecial thanks to Urigo for this great tool, and allowing me to modify the code to add these\nfeatures."}},"/blog/whats-new-in-graphql-cli-4.1.0":{"title":"What's new in GraphQL CLI 4.1","data":{"":"GraphQL CLI is your one-stop shop for developing full-stack GraphQL\napplications in Node.js. With GraphQL CLI you can create and run a new GraphQL application in just a\nfew seconds! Just declare your GraphQL schema, and you can perform code generation, schema\nvalidation, introspection and more through intuitive CLI commands.GraphQL CLI aggregates multiple community projects giving developers the best getting started\nexperience. Tools included in the CLI are mature and developed over the years based on Guild's\nexperience in pushing production ready GraphQL solutions and also through collaboration with Red Hat\ncommunity projects.This post covers a number of enhancements added in GraphQL CLI 4.1, which will further improve your\nGraphQL development experience. Check out our previous post\nGraphQL CLI is back! for a full overview of the library and its\nfeatures.","graphback#Graphback":"All the templates are configured with Graphback, for both runtime and\ngeneration purposes. Graphback 1.0 has recently been released, check out their blog post\nAnnouncing the Release of Graphback 1.0\nthat goes into deeper details of Graphback's features and capabilities.To generate your schema and documents with Graphback, run graphql generate from your application\nroot. See the generate command docs for a thorough explanation\nof this command and usage guides.","serve-command#Serve Command":"The serve command is now powered by graphql-serve,\nletting you start up an in-memory GraphQL server and playground in seconds - perfect for mocking and\ntesting!\n\nCheck out the serve command docs for installation and usage guides!","init-command-templates#Init Command Templates":"The init command is your gateway to creating your new GraphQL application with GraphQL CLI. You\nwill be guided through some questions and after a few seconds a tailor-made starter application will\nbe created!There are several improvements to all of our templates to make them cleaner and more\nproduction-ready. Additionally, we had added two new starter templates: a plain MongoDB template and\na MongoDB template with out-of-the-box data synchronization support.To start using these templates, use the init command:","other-updates#Other Updates":"We've built a new website to host the GraphQL CLI documentation! Check it out at\ngraphql-cli.com.GraphQL CLI 4.1 has been updated to use the latest versions of\nGraphQL Code Generator and\nGraphQL Inspector, which are included as recommended, best practice\nworkflows for developing production-ready GraphQL applications.","try-it-out#Try It Out":"Start using GraphQL CLI today to create your GraphQL application in just a few steps!The easiest way to get started is to initialize your new application with npx:\n\nGraphQL CLI will guide you through some steps and in a few seconds your project will created and\nready to use. Happy coding!As always, we want your feedback! We would love to hear your suggestions and ideas to help make\nGraphQL CLI even better. Reach out to us through GitHub or\njoin our Discord community server."}},"/blog/tag/[tag]":{"title":"Blog","data":{"":""}},"/blog/unleash-the-power-of-fragments-with-graphql-codegen":{"title":"Unleash the power of Fragments with GraphQL Codegen","data":{"":"There is no doubt that Relay is the most advanced JavaScript GraphQL Client out there. However, at\nthe same time, the learning curve and adoption is yet very sparse compared to other popular\nalternatives such as Apollo Client, urql, or GraphQL Request.As a consequence, many people don't even know about all the benefits and patterns used within (and\nso far being exclusive to) Relay. The Guild gathered and worked on projects whose GraphQL client\nusage spans across all the available solutions today. In our opinion, the most important parts of\nRelay are the concepts of building and scaling applications. These patterns are actually applicable\nto any GraphQL Client, you just need the right code generation tool for the job.On a high level these benefits are the following:A fragmentized component tree. Instead of writing a single GraphQL operation document per\nvisible component or extracting the component properties from a single query operation document\ntype, which is often cumbersome), multiple fragment definitions can be composed up to a single query\noperation that is sent to the server. This reduces the amount of concurrent requests and together\nwith @defer and @stream is an actual improvement in the performance of the application\n(compared to batching GraphQL operations).\n\nColocate GraphQL documents with the component code. Instead of writing GraphQL operations in a\ndedicated file, the operations are written within the component code. Have you ever deleted\ncomponent code and forgot to delete the corresponding operation or fragment definitions that are in\nsome other field? We encountered this issue over and over again generating a lot of dead code.\n\nData (fragment) masking. Ensure that a component can only access the data defined in its\nfragment definitions in order to keep the component a self-contained building block that can be\nre-used.\nWe are happy to announce that we now have a preset for bringing the above Relay patterns to your\nexisting projects, no matter what client library you are currently using, without having to switch\nover and commit to the Relay ecosystem.","a-new-graphql-code-generator-preset#A New GraphQL Code Generator Preset":"The new preset serves as a drop-in replacement for all the plugins that generate hooks for existing\nclients such as urql and apollo-client.\n\n\n\nInstead of generating the hooks for the existing clients, the preset works with function signature\noverloading and TypedDocumentNode) for inferring the correct GraphQL\noperation and variables type.\nYou can learn more about TypedDocumentNode in\ngraphql.wtf episode #41.\nIn your application code you will now effectively write the following code.\n\nBecause the client has built in support for TypedDocumentNode, it will extract the correct operation\nand variables type from the document passed to useQuery.Head over to the GraphQL Code Generator documentation\nfor more details.\nThis is now our recommended way of using GraphQL Code Generator for front end development.","describe-component-data-needs-via-graphql-fragments#Describe Component Data Needs via GraphQL Fragments":"Instead of writing one big GraphQL Operation for our whole page and passing that down to the\ncomponents, start with describing the component's data dependencies through a GraphQL fragment. This\nway, you are making the data-dependency of your component colocated and explicit in the same way\nthat some would colocate the TypeScript definitions or CSS if you are using the styled components\npattern.","restrict-data-access-with-fragments#Restrict Data Access with Fragments":"By utilizing the useFragment hook we ensure that the component can only access the properties of\nthe data that are declared directly within the fragment selection set. The other data declared\nthrough the additional fragment spread(Avatar_UserFragment) cannot be accessed within the\nUserListItem .The following example would raise a TypeScript error, as the avatarUrl field is not selected\nwithin the UserListItem_UserFragment fragment.","compose-fragments-for-ui-components#Compose Fragments for UI Components":"As we compose simple visual UI components into bigger functional UI components we can also compose\nthe fragments of the consumed UI component.","compose-fragment-components-for-your-top-level-route-or-view#Compose Fragment Components for Your Top-Level Route or View":"We can now further compose our components till we reach those components that select the root Query\nobject type.\n\nEarlier, we declared the Avatar component with the Avatar_UserFragment fragment. We can now\nre-use this Avatar in a different context by again spreading the fragment and then passing the\nrelevant data to the Avatar component user property.\n\nNow, we have two UI components that require data from the root Query type, FriendList and\nUserProfileHeader .","compose-all-query-fragments-into-a-single-query-operation#Compose All Query Fragments into a Single Query Operation":"Finally, we can spread all our fragments into a single GraphQL Query operation that fetches all the\ndata on our route component. This allows us to efficiently fetch all the data required for the route\nin one server roundtrip.\n\nFinally, we have the following component tree as mentioned before.","conclusion#Conclusion":"This pattern allows you to re-use and scale your components to the maximum while having a clear and\nsane data dependency flow from the top route down to the ends of the UI component trees.You can start adopting this pattern within your existing GraphQL application with any GraphQL client\nthat supports TypedDocumentNode through our new and battle-tested GraphQL Code Generator preset\nclient-preset.All the following clients are supported with ANY framework (React, Vue, Angular, etc.)\nurql\nApollo Client\n\"Vanilla\" Node.js\ngraphql-request\n(we recently added support)\n\nYou can start quickly without much configuration by following\nthe preset documentation.Maybe this even inspires you to dig deeper into the optimizations the Relay client runtime does on\ntop of these patterns and convince you to use Relay within your next project. You can learn more\nabout those on relay.dev.We, as The Guild, want you to find the right tool for your expertise and the application you are\nbuilding. The most important thing is the patterns that are applicable anywhere!","not-having-enough#Not Having Enough?":"I also talked about this topic recently at the GraphQL Berlin meetup!"}},"/blog/subscriptions-and-live-queries-real-time-with-graphql":{"title":"Subscriptions and Live Queries - Real Time with GraphQL","data":{"":"Subscriptions are the go-to solution for adding real-time capabilities to a GraphQL-powered\napplication. At the same time the term GraphQL Live Query floats around and can often be found in\nthe context of subscriptions.While\nGraphQL Subscriptions have been a part of the GraphQL Specification\nfor some time, GraphQL Live Queries are not part of the specification and further there is no RFC\ngoing on.However,\ndiscussion about GraphQL Live Queries started way back when GraphQL Subscriptions were designed.So let's take a recap of GraphQL Subscriptions, take a look at existing Live Query Solutions today\nand compare the differences between the two solutions for real-time.","subscription-recap#Subscription Recap":"The\nGraphQL Subscription RFC was merged back in March 2017.\nThe first major and wide-adopted transport implementation was (and probably is)\nsubscriptions-transport-ws. It was\ndeveloped by Apollo, but unfortunately they seem to have abandoned it since then. Fortunately, we\nnow have a successor graphql-ws.A subscription operation looks similar to this.\n\nIn contrast to a GraphQL query operation, a subscription operation is only allowed to select a\nsingle field on the GraphQL Subscription root type.Furthermore, executing a subscription operation represents a stream of results where executing a\nquery operation only results in a single result.Let's take a quick look at the graphql-js reference implementation!Since promises cannot represent multiple values over time, the graphql-js reference\nimplementations uses AsyncIterator, which\nis a native structure similar to Observables (which one might already know by having dug a bit\ndeeper into the most-widely adopted GraphQL clients).Each subscription root field must provide a subscribe function that returns an AsyncIterator and\noptionally has a resolve function for mapping the published events.When a subscription operation is executed, the subscribe function of that field resolver is called\nand the AsyncIterator returned by it will be used as the source for the stream of events returned\nto the client.Once the AsyncIterator publishes a value (the payload or event), the optional resolve function\non the selected subscription root field is called with the value. All subsequently executed\nresolvers in the resolver/type tree behave like normal query resolvers.The most basic implementation for a counter would look similar to this:\n\nThe above subscription will count up to the number provided via the toNumber argument (while\nhaving a delay of one second between each message) and then complete.Of course, in a real-world application we would like to subscribe to other event sources instead of\nsome static, pre-defined events.The most common used (but not best maintained) library for such a PubSub engine in the GraphQL\ncontext is graphql-subscriptions. There\nare also adapters available for more distributed systems (where all GraphQL API replicas must be\nnotified about the event) e.g. over Redis.If there is not need for scaling horizontally the graphql-subscriptions package can be omitted and\nbe replaced with the Node.js native events module:\n\nA (type-safe) PubSub implementation in 21 lines of code. We will use this for the example below.In my opinion the different pub sub implementations should rather be based on EventEmitter instead\nof graphql-subscriptions. A PubSub can but musn't be used together with GraphQL. By choosing the\nname graphql-subscriptions it gives the impression that the logic is specific to GraphQL and\nreduces other possible contributions from people that need a similar event abstraction.Therefore, I hope the next generation/iteration of Node.js PubSub implementations is less specific.Having said that, let's take a look at a more \"real-world\" like example of using subscriptions with\nPubSub:\n\nUntil now, we only took a look at the resolvers. Let's also quickly check the subscribe function\nexported from graphql-js, which can be used for executing subscriptions.\n\nThe subscribe function returns either a AsyncIterable that publishes multiple ExecutionResults\nor a single ExecutionResult in case the setup of the subscription somehow fails.The interesting thing is that we can use any transport for delivering the results to client. The\nmost popular implementation (as mentioned before) is subscriptions-transport-ws. Unfortunately,\nsince it is poorly maintained, the GraphQL Working Group came up with a new implementation over\nWebSockets, graphql-ws.But we are not forced to use WebSockets at all.\nServer Side Events)\nmight be a more lightweight solution for both our server and client.It is actually a shame that the default express-graphql reference HTTP transport implementation\ndoes not come with a built-in subscription solution.Fortunately, we now have libraries like\nGraphql Helix, which, in my humble opinion, should\nreplace express-graphql as the reference HTTP implementation since GraphQL Helix is also not tied\nto any web server framework.For public GraphQL APIs, I am convinced that Server Sent Events is the future as there is less work\nrequired for implementing the protocol.I also built\nmy own transport over Socket.io,\nwhich uses WebSockets by default and HTTP polling as a fallback.As you can see, with GraphQL subscriptions, we are free to choose the best transport for our\napplication requirements!Now that we took a look at how GraphQL Subscription resolvers are implemented on the server-side,\nlets also check out how we can consume the GraphQL API on the client-side!Usually we will have a network interface that is called by our favorite GraphQL client. Every single\nclient has a different name and implementation. Apollo calls them links, Relay calls them fetcher\nfunctions, and urql calls them exchanges.All of them have one thing in common. They are working with observable-like data structures, which\nbasically means for consuming subscriptions, all major GraphQL client-libraries decided to use\nObservables, instead of AsyncIterators (which are still not part of the ECMA Spec as of October\n2020).Like an AsyncIterator, an Observable can represent multiple values. As already mentioned, each\nclient library and transport have slightly different interfaces. I will use graphql-ws with\nrelay-runtime as an example.The example is taken straight from the graphql-ws section.\n\nWith this configuration, Relay can now execute subscription operations. Because the graphql-ws\nprotocol is way more complex than the GraphQL over HTTP protocol, we use the client exported from\nthe graphql-ws package instead. This results in some additional bundle-size. As mentioned before SSE\nmight be a better, lightweight alternative.That aside, let's start with a basic subscription that should update one of our components.Our PostRender already shows some content.\n\nAs a new feature requirement, the like count of the post should get updated once someone hits the\nlike button.We could choose different ways of implementing such a subscription.\nGeneral Subscription for changed post\n\n\n\n\nSpecific Subscription\n\n\n\nBoth solutions have different implications.\nGeneral Subscription for changed post\n\nThis approach is not limited to notifying whether the totalLikeCount of the post likes have\nchanged; in the future we could adjust the selection set on the post field as it also returns a\nPost type similar to our already existing Query.post field. It will automatically update the\npost record already in the cache as the Relay store (similar to other clients) can identify the post\nobject via the id field. The drawback is that we could potentially send too much data over the wire.\nE.g. if we also wanted to subscribe to title changes all additional selected fields are sent to the\nclient each time the underlying event is emitted, even if only the totalLikeCount value has\nchanged.\n\n\nSpecific Subscription\n\nThis subscription is specifically designed for only an update of the totalCount. However, the\nsubscription result returns no Post type. Therefore, we cannot make use of the automatic cache\nupdates via the id. We have to additionally define a handler for updating the post in the cache.\n\nObviously, for this example, no sane person would actually want to choose the second solution over\nthe first one.But as our business requirements might get more complex we might need to do manual cache updates.A very good example for this is lists. Imagine us having a set of data in which a single item\nchanges. The \"easy to implement\" solution would be to just refetch the complete list every time a\nsingle item is added/removed/changed. However, For a list containing hundreds of items only sending\nthe changed item to the client might be the smarter and faster solution...This can be implemented via a union type.\n\nThe corresponding code, including handling the cache updates:\n\nAs our application grows the manual cache update code can become so complex and confusing that I\nhave considered switching back into simply refetching the queries in some applications.Fortunately, Relay contributors have\nworked on some nice query directives that allow\nreducing such cache update code. It won't cover all cases though.In all of the above examples we responded (more or less implicitly) to data change events.Subscriptions can be used to apply data changes on the client. But they are probably not the best\ntool for that.Before taking a look of what could be a better tool, let's look at another usage example for\nsubscriptions.\n\nThe difference here is that we are not manipulating our existing data but rather executing a side\neffect.Subscriptions can also be used for side effects that should not alter or touch any data in the\ncache.","live-queries#Live Queries":"What is a live query? Well, there is no specification for that so the term is ambiguous. Today,\nthere are several solutions one could describe as live queries.All those solutions have one thing in common: Trying to keep the client state in sync with the\nserver.Which can be paraphrased as observing data.Before we take a look at how all of those implementations, let's break down what we should or can\nexpect from a live query implementation.Automatically update the clientsThis is one is pretty obvious. The live query implementation should keep the client state as close\nto the server state as possible.Efficiently update clientsIf only a part of our data has changed we don't necessarily need to send the complete execution\nresult over the wire. Only sending the changed parts might be more efficient. In general the network\noverhead should be minimal.FlexibilityIdeally a solution should not be tied to a specific database or coupled with some SaaS service that\nwon't be around next year.AdoptabilityIn case we already have some kind of GraphQL schema or server implementation, the live query\nsolution should be adobtable without changing everything and starting new.","polling-a-query#Polling a Query":"The easiest solution for implementing live queries would be to poll a query in intervals. Most\nGraphQL clients have such a feature already implemented.\n\n\nAutomatically updates clients. No. ❌\n\nDepending upon the use-case, this could be a valid solution, but for true real-time applications\nthat require instant feedback, this is not precise enough due to the delay caused by the poll\ninterval.\nEfficiently updates clients. No. ❌\n\nThe whole execution result is sent over to the client for every single time the operation is\nre-executed. A lot more data than necessary is transported over the wire to the client even if\nnothing has changed from the last poll interval.\nFlexibility. High. ✅\n\nStraight forward, as this does not rely on any changes on the server and only slight changes on our\nfrontend.\nAdoptability. High. ✅\n\nStraight forward, again almost no changes required.","live-queries-over-subscriptions#Live Queries over Subscriptions":"We already had a \"live query over subscription\"-like example above.\n\nLet's ditch the PostQuery completely and instead use a PostSubscription that always emits an\ninitial event.\n\nA server resolver implementation could look similar to this:\n\nWe replace two operations with a single one!A similar approach is used by\nHasura and also\nPostGraphile.The obvious drawback of both platforms is the lock-in into using a specific database. Of course that\nmight not be a problem for most people, but having a general solution that works with any data\nsource would be nice as more complex schema could fetch from different database types or other third\nparty APIs.Those implementations keep track of all the resources in the execution result and re-execute the\nsubscription operation once any of those resources changes.The resolver implementation above only responds to emitted post changes. In order keep track of all\nthe resources defined in an operation's selection set, we will have to come up with a smart\nabstraction.Another drawback of subscriptions for live queries is the limitation of only selecting one root\nsubscription field, which is defined by the GraphQL subscription specification. Furthermore, we must\nalso redeclare our query type fields to the subscription type.There is a workaround we can apply for re-exporting the whole Query type via a sub-field in the\nsubscription type.\n\nThis approach would allow us to query everything on the query object type via the live field on the\nsubscription object type, without having the limit of only being able to query one resource or\nhaving to redeclare every resource field resolver on the subscription type. Neat!\n\nOkay, now we can select everything we could have selected with our query operation!\nAutomatically updates clients. Yes. ✅\n\nWhen using services like PostGraphile and Hasura that is the case. However, for any additional\nresolvers that are added on top of the service schema, we cannot implement an invalidation\nmechanism. In user-land we will have to come up with an implementation of resource tracking by\nourselves.\nEfficiently updates clients. No. ❌\n\nThe whole execution result is sent over to the client for every single time a live query is\ninvalidated.\nFlexibility. Low. ❌\n\nBoth Hasura and PostGraphile are tightly coupled to a python database. For any custom resolvers, we\nhave to come up with the mechanism for resource tracking and invalidation ourselves.\nAdoptability. Low. ❌\n\nSwitching to a server powered by PostGraphile or Hasura with an already existing GraphQL schema is\nno easy task.","graphql-live-queries-over-subscriptions-with-json-patch#GraphQL Live Queries over Subscriptions with JSON Patch":"Ideally, we only want to send a patch to the client that provides instructions on how to get from\nthe previous execution result to the next. The lack of these instructions has been a big flaw in the\nprevious two implementations.The RFCs and implementations for the @defer and @stream introduced ways of sending (delayed)\npartial results to clients. However, those \"patch\" operations are currently highly limited to a\n\"replace at path\" and \"append to list\" operation.A format such as JSON Patch might be a better alternative for\nlive queries.graphql-live-subscriptions tries to solve\nthat with Subscription.live field that exposes both a Query and a JSON patch field.Schema Types for graphql-live-subscriptions\n\nA live query operation can be declared similar to our PostSubscription document above.\n\nThe difference is that the type returned by the live field has two fields instead of a single one.\nThe query field, which selects the selection set from Query type and a patch field which is a\nJSON Patch operation. When executing the given operation against the server the initial result will\nhave the data selected by the query field selection set included. All following values will have\nno query value (null), but instead an array of patch operations that describe the changes for\nupdating the last result to the next result.Initial result\n\nPatch result (increase totalLikeCount)\n\nThe clients must then implement the logic for\napplying the patch operation to their client cache\nor for applying the patches on the initial result in the network/fetcher/link layer.The server implementation uses an event emitter and an immutable state tree for detecting changes\nthat must be sent to clients. The patch is automatically generated from the next immutable state\nthat is compared against the last which got emitted via an EventEmitter.While the idea is quite nice, the implementation is obviously meant for backends that already use\nreactive or immutable data structures. Having to rewrite our existing GraphQL layer to support live\nqueries is a big trade-off. Furthermore, the library is not maintained that well. I've made PRs to\nmake the library compatible with recent GraphQL versions, but these have yet to be merged. Using\nunions and interfaces is not possible. Having to patch a library with patch-package before even\nbeing usable is generally a bad sign.\nAutomatically updates clients. Yes. ✅\n\nWhen implementing our schema conform to the library, this library delivers precise results once the\nimmutable state has changed.\nEfficiently updates clients. Yes. ✅\n\nInitially a result tree is sent to the client. Afterwards, only JSON patches that must be applied to\nthe initial result are sent to the client.\nFlexibility. Kind of. ✳️\n\nWe don't rely on any third party services, however, we forced into immutability to some extend.\nAdoptability. It depends. ✳️\n\nAdding an immutable layer to our existing schema might be a pretty big change. Furthermore, the\nlibrary does lack support for some GraphQL features such as Interfaces and Unions.","graphql-live-queries-via-the-live-directive#GraphQL Live Queries via the @live Directive":"There are companies out there, like Facebook, that are\nalready using this approach. There is also a GraphQL framework available in Go that supports live\nqueries out of the box! Check out thunder here.The idea behind the @live directive is that it is used to mark that the client is interested in\nkeeping that query execution result as up to date as possible. The implementation, however, is up to\nuser-land.\n\nThe idea of just making any query without additional overhead a live query is very appealing from\nthe view of a frontend developer. From a backend perspective, however that raises new questions.\nJust adding a directive on the operation on frontend won't make the whole backend reactive.After having built an example app with graphql-live-subscriptions from scratch, studying the flaws\nof that library and being uncomfortable with the vendor lock-in of services such as PostGraphile and\nHasura, I decided to approach the problem of live queries in a more pluggable way, by using the\n@live directive.","n1ru4lgraphql-live-query-a-common-definition-and-set-of-utilities-for-determining-of-a-live-query#@n1ru4l/graphql-live-query A Common Definition and Set of Utilities for Determining of a Live Query":"This module provides two things.\nGraphQLLiveDirective that can be added to any schema.\n\n\n\n\nisLiveQueryOperationDefinitionNode\n\nThis is a simple function that takes a OperationDefinitionNode and returns true if it is a live\nquery document.These utility functions can be found here on GithubThose functions alone might not seem that helpful alone, but they are a contract live query\nexecution engines could built on. Such as the package we are talking about next 😇.","n1ru4lin-memory-live-query-store-keep-track-and-invalidate-resources-selected-by-a-live-query-in-an-efficient-but-generic-way#@n1ru4l/in-memory-live-query-store Keep Track and Invalidate Resources Selected by a Live Query in an Efficient, but Generic Way":"The InMemoryLiveQueryStore.execute function is a drop in replacement for the execute function\nprovided by the graphql package.When encountering a query operation that is marked with the @live directive it will return a\nAsyncIterator instead of a Promise that can be used for sending multiple results to the client.\nSimilar to how subscribe (or defer/stream) works.Internally, the store keeps track of the resources selected in the live query operation selection\nset. That means all root query field coordinates (e.g. Query.post) and global resource identifiers\n(e.g. Post:1). The store can then be notified to re-execute live query operations that select a\ngiven root query field or resource identifier via the InMemoryLiveQueryStore.invalidate method\nwith the corresponding resource identifier or field coordinates. A resource identifier is composed\nout of the type name and the actual resolved id value separated by a colon, but this behavior can be\ncustomized. For ensuring that the store keeps track of all our query resources we should always\nselect the id field on our object types. The store will only keep track of fields with the name id\nand the type ID! (GraphQLNonNull(GraphQLID)).\n\nWhen using an ORM such as Prisma, we can simply add a middleware for automatically invalidating\nresources.\n\nUse Prisma middleware for resource invalidation\n\nIn case we have multiple server replicas some PubSub implementation can be used for distributing the\nevents.PubSub with Redis\n\nThe transports graphql-ws (GraphQL over WebSocket), graphql-helix (GraphQL over SEE) and\n@n1ru4l/socket-io-graphql-server (GraphQL over Socket.io), support providing a custom execute\nfunction that is allowed to return AsyncIterables (thanks to the recent changes required for\n@defer and @stream). All we have to do is to pass the InMemoryLiveQueryStore.execute to our\nserver factory!Example with graphql-ws\n\nThe best thing is you can start playing around with it today! The fully functional implementation is\navailable as\n@n1ru4l/in-memory-live-query-store on Github.\nFeel free to create any issues regarding missing features or documentation. Let's shape the future\nfor GraphQL live queries together!","n1ru4lgraphql-live-query-patch-optional-json-patch-middleware-for-smaller-payloads-over-the-wire#@n1ru4l/graphql-live-query-patch: Optional JSON Patch Middleware for Smaller Payloads over the Wire":"GraphQL's execution result payloads can become quite huge. Sending those over the wire can be\nexpensive at some point. Especially when they are sent often for fast updating state. JSON patch is\na handy standard for only sending change instructions over the wire which can potentially reduce\nsuch huge payloads.Instead of having JSON patches enabled by default, it is a totally optional module, that can be\napplied on the client and the server for deflating (create patches on the server) and inflating\n(apply patches on the client) the execution results. Smaller projects might even be better off not\nusing JSON patch at all, as the patch payload might be bigger than the whole query result.The patches are created by comparing the latest execution result with the previous execution result.\nThat means the server will always have to store the latest execution result as long as the live\nquery is active.Here are some example execution results after applying the patch generatorInitial result\n\nPatch result (increase totalLikeCount)\n\nOn the server adding the patch generation middleware is easy function composition:\n\nOn the client we now need to build an execution result out of the initial result and the patch\nresults, because our clients do not understand the graphql live query json patch protocol!Applying the middleware is pretty easy as well!\n\nThe library is optimized for network interfaces that return AsyncIterables. We can easily wrap out\nfavorite network interface (that uses observable style sinks) in an AsyncIterable with\n@n1ru4l/push-pull-async-iterable-iterator!Example with graphql-ws\n\nThe whole package can be found\n@n1ru4l/graphql-live-query-patch on GitHub.\nIt is also usable and feedback is highly appreciated. It currently has its flaws with list diffing,\nso further thoughts and ideas are highly appreciated.Note: We now seperated the json-patch package into a separate\n@n1ru4l/graphql-live-query-patch-json-patch package. @n1ru4l/graphql-live-query-patch now only\nincludes common logic shared between patch payload implementations. The reason for this is that\nthere are more efficient patch formats available, such as jsondiffpatch, which generate smaller\npatches for list changes. The latter is now available as the separate package\n@n1ru4l/graphql-live-query-patch-jsondiffpatch.So let's take a look at this modular implementation approach regarding the aspects we used before.\nAutomatically update the clients. Yes. ✅\n\nThe approach of pushing the invalidation responsibility to the server might at first seem like a\ndrawback, but a smart abstraction (such as a ORM middleware), can result in pretty responsive\napplications.\nEfficiently updates clients. Yes. ✅\n\nIn case our execution result payloads are getting too big we can easily enable JSON patches by\nadding a middleware. Furthermore, the middleware is totally live query implementation independent!\nThat means if our projects requires a different implementation of the live query engine, the\nmiddleware can still be applied as long as the execution result is compatible with the live query\nexecution result format.\nFlexibility. High. ✅\n\nAny database or third-party API can be used as long as we can somehow invalidate the resource (via\nsome PubSub system etc.). As all incorporated libraries are pretty pluggable only a few can be used\nand others be replaced by something that might make more sense for a specific project.\nAdoptability. High. ✅\n\nThis library can be added to any existing GraphQL.js schema without any hassle if you use transport\nthat allows full control over the schema creation and execution phase, such as graphql-helix or\ngraphql-ws which you are hopefully already using! Resource invalidation code can be added to the\nmutation resolvers over time gradually to reflect the needs of the frontend. The possibilities of\nresource invalidation are endless and the logic for those can be added incrementally. E.g. via an\nORM middleware, in our mutation code or maybe even on our GraphQL gateway.","whats-next#What's Next?":"Summed up this could be the start of a pluggable live query ecosystem that is flexible enough to be\ncompatible with a wide range of databases, graphql transports and schema builders instead of\nfocusing too much on a niche. In general, instead of having less flexible and bulky servers that try\nto be too opinionated and restrictive in their schema -> execution -> transport flow, GraphQL\ntooling should become more modular. At the same time this, however, should not imply that there is\nno need for opinionated framework-like approaches (as long as they give enough flexibility, e.g. by\nbeing composed out of modular packages).I hope that more people will start exploring the possibilities of GraphQL live queries and also\nGraphQL in general! Eventually, we could even come up with an official live RFC for the spec!There is a lot more to think about such as\nPartial query re-execution (e.g. by building ad-hoc queries that only select affected resources)\nMechanisms for batching similar query operations (e.g. for preventing execution of same operation\nmultiple times after invalidation)\nBetter list diffing/format for live query patches (as JSON patch performs rather poorly on list\ndiffs) (Solved by introducing\n@n1ru4l/graphql-live-query-patch-jsondiffpatch)\nWhat ever is bothering you while reading this article! 😄\n\nIf you are a enthusiastic tinkerer and plan to build something with the libraries above, share it\nwith me and everyone else, so we can get more insights into different use-cases and requirements for\nall kind of applications!Let's continue the discussion on Discord, Slack or\non GitHubHere are some more resource for you to thinker around with:GraphQL Live Query libraries and example todo app that sync across all connected clients.Experimental GraphQL Playground that implements RFC features (defer/stream) and live queries.More information on how the InMemoryLiveQueryStore keeps track of resources.Further thoughts on how the Relay Spec could help backing a live query system."}},"/":{"title":"GraphQL Tools","data":{"":""}},"/blog/graphql-mesh":{"title":"GraphQL Mesh - Query anything, run anywhere","data":{"":"We are excited to announce GraphQL Mesh — a powerful open\nsource library enabling developers to leverage the power of GraphQL without requiring changes to the\ntechnologies your servers already use.We've been using this tool to significantly improve our clients stacks — improving the areas that a\nclassic GraphQL gateways would have left untouched","the-basics#The Basics":"GraphQL Mesh takes any source schema (openapi/Swagger, json-schema, SOAP, gRPC, python, Mongoose,\nGraphQL, Federated GraphQL, queue systems, and others) and let you query it as GraphQL without\nchanging the source service\nChoose the fields you want, in the shape you want them\nGet full type-safety for remote APIs\nSchema unification/Stitching for any source\nGraphQL Mesh runs anywhere. As a standalone gateway, as a datasource, or run as a local,\ndistributed GraphQL SDK to simplify service-to-service communications\nEach step of the transformation is fully customizable\nAbility to provide your API consumers the GraphQL experience without the operational overhead","intro#Intro":"GraphQL Mesh allows you to use GraphQL query language to access data in remote APIs that don't run\nGraphQL (and also ones that do run GraphQL).It can be used as a gateway to other services, or run as a local GraphQL schema SDK (data source)\nthat aggregates data from remote APIs.The goal of GraphQL Mesh is to let developers easily access services that are written in other APIs\nspecs (such as gRPC, OpenAPI, Swagger, oData, SOAP, GraphQL and even python) with GraphQL queries,\nmutations and subscriptions.GraphQL Mesh gives the developer the ability to modify the output schemas, link types across schemas\nand merge schema types. You can even add custom GraphQL types, resolvers, links and more.It allows developers to control the way they fetch data, and overcome issues related to backend\nimplementation, legacy API services, chosen schema specification and non-typed APIs.Here are some use cases and how GraphQL Mesh can be used to support them:\nQuerying legacy/non-typed APIs with an easy query language that is fully type-safe\nAggregate, transform and link data across multiple APIs\nProxy and have a simple way to access data from various API specifications without the need to\nlearn each one specifically\nAccess and fetch data across microservices (a merged Data Graph) without adding a central failure\npoint to your deployment architecture\n\n\n\nThe way GraphQL Mesh works is:\nCollect API schema specifications from services, registries or simple files\nCreate a runtime instance of fully-typed SDK for each service\nConvert the API specs of each service to GraphQL schema\nApplies custom schema transformations and schema extensions\nCreates fully-typed, single schema, GraphQL SDK to fetch data from your services.\n\nGraphQL Mesh is acting as a proxy to your data, and uses common libraries to wrap your existing API\nservices. You can use this proxy as an SDK in your service by running the GraphQL schema locally\n(with GraphQL execute), or you can deploy this as a gateway layer to your internal service.\nNote: Our goal with GraphQL Mesh is to create an easy-to-use GraphQL proxy to your own data\nand services. You may want to consider implementing another layer to expose your data publicly.","a-short-break--who-are-we#A Short Break — Who Are We":"GraphQL Mesh was created by the open source group called The Guild.We currently maintain the following libraries:\n\nWe love what we do and are fulfilled by that, but if you wish to support us, here are some possible\nways:\nWork with us - The best way to support us is to let us work with you :) We work with clients\nfrom all over the world and in the process learn from them how to make our libraries better. We\nwork with companies from fortune 50 to small startups with different types of engagements. We help\nenhance developer teams, making individuals more productive and help to develop themselves.\nReach out directly for a free meeting, even just for a fun chat to\nshare ideas and get feedback!\nTell people about us — Many people who use our libraries, don't know who we are and don't know\nabout all the other libraries we've created. Help us spread the word!\nContribute — Better docs -> answer issues -> Reproduce bugs and create tests — we can't stress\nhow valuable this would be and we would love to support your journey into open source! Also, as\nThe Guild is distributed, create your own new libraries under your own name and share it with us,\nwe'll help you promote and maintain it if you want!\n\nWe have a large community as well which you can join by\nfollowing the repositories and our\nDiscord channel. We are having our first new monthly Guild\ncommunity meeting very soon!","use-cases-3-example-use-cases#Use Cases (3 Example Use Cases)":"","1--the-simple-use-case-graphql-data-source-per-endpoint#1 — the Simple Use Case (GraphQL Data Source per Endpoint)":"So you got yourself a new GraphQL server!It sits between your frontend and your former REST backends. And you got the benefits of having type\nsafety over the network.But what about the services and data sources you query from your resolvers?In your resolvers you still call regular REST endpoints? They might not be typed and might not\nreturn the shape of response you want them to return.\n\nWouldn't it be nice if you could use those data sources as GraphQL sources?One option would be to migrate those services to GraphQL or build a GraphQL wrapper for each, which\nmight not be so feasible, or would take too long for the following reasons:\nIn most large companies, wrapping each service in GraphQL or adding a GraphQL implementation to\neach service is not a realistic option. The service maintainers need to learn, agree and add\nnew tasks for their already busy backlog.\nThe capabilities the GraphQL engine brings us (orchestration, restructuring) are very powerful but\nusually runs on the provider. That means that each service will now behave differently on\ndifferent consumers. In many Enterprise architectures, that behaviour can be harder to cache and\nputs a burden on the service team that might not be the right responsibility for them.\nIt might not always be a good idea to dictate a single protocol for all your services to use. It's\na bit like dictating a single programming language for all your services in the organization.\n\nCan we use the benefits of GraphQL without rewriting our services and moving execution burden to\nthem?That way we could get type safety and querying abilities (you don't really care about less data over\nthe network between services).That's a first place where GraphQL Mesh can help you — simply input any schema file (For example\nSwagger definitions), from any source to the Mesh config, and we'll generate a fully typed GraphQL\nSDK, take would make it look like those sources exposed GraphQL themselves.That SDK can run locally on your GraphQL server without affecting the underlining services at all.","2--the-merging-use-case#2 — the Merging Use Case":"Great! So now you have a lot of “GraphQL endpoints” that simplify and automate a lot of the work you\nneeded to do in your resolvers.But maybe some of those services could be combined into a single entity Graph?The second place GraphQL Mesh can come in handy is that it lets you stitch together those converted\nGraphQL endpoints into a single endpoints and a Graph.schema stitching for any source!So now you can delegate a lot of logic from your manual GraphQL server into GraphQL Mesh.","3--the-service-mesh-use-case#3 — the Service Mesh Use Case":"So you've done all that work on your GraphQL gateway.But there are other services in your network that might need to query other services that only\nexpose an HTTP/SOAP/gRPC endpoints.They still need to orchestrate those calls, validate them and shape them to the structure they need\n(a good example might be a ML service that crunches data from many other services).One of the interesting things about Mesh is that it doesn't impose any changes to the services and\nthat it can run as an SDK anywhere.So now each service can get an SDK of the full Graph, which it can run locally in a distributed way,\ninstead of having all services calls going through a central gateway.","usage#Usage":"Check out all the examples on our repoTo get started with GraphQL Mesh, create a simple .yaml file that points to your existing API\nservices spec — your Swagger file, .proto files or your GraphQL service, and choose the correct\nhandler for it.Here's a simple example for fetching and aggregating data across multiple external services. It uses\n2 independent OpenAPI data sources, and links them together.Before:\n\nCode isn't typed, and it requires you to write code that fetches and merges it manually. It also\nmeans that your code deals with request-response and the next time you'll need to fetch data from\nthose sources, you'll need to duplicate code and apply those merging logics again.It also means that your code should be fully aware of what APIs it fetches from, and what data they\nreturn.After:First, you can configure GraphQL Mesh to load your remote services, as following:\n\nThe data aggregation logic can be moved into a custom GraphQL resolver:\n\nWe are using city parent value, which is being fetched by the Cities API, and fetch data from the\nweather API based on the city location.And your data fetching function can use GraphQL to query for the data, and GraphQL Mesh will\ngenerate the corresponding method getCityAndWeather for you:\n\nThis way, the implementation of the getCityAndWeather is being generated as a typed function, and\nthe GraphQL query is agnostic to the services it fetches data from.The logic linking those API services is now part of your GraphQL engine — you only need to deal with\nwriting a GraphQL query to fetch the data you need.","graphql-mesh-as-a-local-schema#GraphQL Mesh as a Local Schema":"The output of GraphQL Mesh is a generated code, so you can import it directly from the generated\ndirectory. You can load the schema and use GraphQL execute to run queries and mutations.Using this method, the query and the mutation will be executed locally in your application, and the\nGraphQL engine will be in charge of running the actual data fetching, using the source APIs.This method brings the GraphQL schema management closer to the developer, and allows you to modify\nand manage the GraphQL schema according to your application needs.","graphql-mesh-as-a-gateway#GraphQL Mesh as a Gateway":"You can use the generated schema and run it on its own server, as a gateway to your data fetching.\nYou can share a single gateway with multiple applications — it means that changing and manipulating\nthe schema is being managed by the gateway itself, and not the consuming applications.Using GraphQL Mesh output as a gateway means that the consuming applications will execute GraphQL\nover the network to the gateway, and from the gateway to the source APIs.","querying-data-from-mesh#Querying Data from Mesh":"Because the output of GraphQL Mesh is a GraphQL schema, you can choose how to execute and query it,\naccording to your needs and preference:\nYou can use simple GraphQL queries and mutations directly, and fetch data from the generated\nschema.\nYou can use GraphQL queries and mutations with GraphQL Code Generator, in order to generate a\nready-to-use SDK based on your GraphQL operations. It will also make sure that your result types\nare types according to your GraphQL selection set.\nYou can use any other GraphQL client (graphql-request, apollo-client, gqless).","how-does-it-work#How Does It Work?":"This is a short version, In the upcoming week we'll write more in depth article about each layer of\nthe architecture and our thoughts and choices while implementing the library — Spec conversions,\ncode-generation vs. runtime, type safe SDKs, schema transformations, merging types, caching, data\nloaders and optimizations","converting-apis-specification-to-graphql#Converting APIs Specification to GraphQL":"GraphQL Mesh initially loads your existing services' APIs specification — either from a remote\nsource (where introspection/reflection is available) or from local files.It then attempts to convert your specification into a GraphQL schema, in an optimal way.Converting APIs specifications to GraphQL schema it not always simple — some of the traditional API\nspecification uses a request-response approach (each endpoint or method has a type for it's request\nand a type for it's response, and it's not necessarily shared), compared to GraphQL, which uses\ntype-based schema that allow links and re-use of types (hence the graph).Erik Wittern, Alan Cha, and Jim A. Laredo from IBM wrote a very interesting\narticle about the difficulties of converting REST-like API to a GraphQL schema.\nThose concepts are implemented in openapi-to-graphql\nlibrary, which is being used by GraphQL Mesh and we are contributing to. We apply similar approach\nto other API specifications.Aside from wrapping the service API with a GraphQL layer, GraphQL Mesh also allow you to easily\nextend or modify the converted schema, all with a fully-typed SDK, tailored specifically to the API\nservice you are usingIt also means that creating new fields or links between the schemas is easier, and you can always be\nsure it's using the correct object structure.","schema-transformations-extensions-merging#Schema Transformations (Extensions, Merging)":"GraphQL Mesh allows you to do manipulations on schemas. You can either manipulate the schema before\nunifying it (for example, prefix all types, change a type name, delete a field) or after unifying\nall schemas (link field across schemas or merge types).All phases of Mesh are customizable and pluggable — Which means you can adjust it with any strategy\nthat works for you.One benefit is that we can now choose between Schema Stitching and Federation!In our Schema Stitching example, we use graphql-tools-fork and it's powerful schema-stitching\nimplementation to create new merge types on the output schema.In our Federation example, we used Apollo Server's Federation and Gateway libraries, together with\nthe graphql-transform-federation library,\nwhich let us add the Federation metadata to existing GraphQL schemas. So we use Federation as a\nlocal merging strategy, together with its query planner executor.We can now compare those two strategies next to each other and show the benefits and downsides of\neach approach for many different use cases.","python-as-a-source#python as a Source":"Right before we decided to open source the library, we had a thought — why only focus on API\nprotocols.There are many inspiring projects out there that convert database schemas to python.So why not integrate those schemas as well?So we decided to do a POC using the amazing\nPostgraphile project!Check out our\nexample for merging Geo DB with GitHub!\nWe would love to hear and help you integrate with more databases and sources!","summary#Summary":"GraphQL Mesh has been a huge upgrade for us and our clients. But we believe this is only the start\nof the conversation around GraphQL and other protocols, merging remote schemas and execution. Try it\nout today and contact us with all the questions, use cases and feedback you might have!Our repositories,\nDiscord channel and newsletter."}}}